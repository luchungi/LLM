{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "939879bc",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b3f288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "VOCAB_SIZE = 2000  # Size of the vocabulary\n",
    "CONTEXT_LENGTH = 256  # Fixed context length for chunks\n",
    "BATCH_SIZE = 256  # Batch size for training\n",
    "TOKENIZER_FILE = \"./data/tinystories-tokenizer\"\n",
    "CHUNK_FILE = \"./data/chunked_stories\"\n",
    "SAMPLE_LIMIT = None  # Set to None to process the entire dataset\n",
    "DICT_LABEL = 'seq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ba92886",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import mlx.optimizers as optim\n",
    "import mlx.data as dx\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "from llm.modules import SmallLanguageModel, loss_fn, create_causal_mask_triu\n",
    "from llm.data import chunk_story, data_to_array_of_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aa72f0",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a15263a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SmallLanguageModel(vocab_dim=VOCAB_SIZE, embed_dim=4, n_head=2, num_layers=1)\n",
    "x = mx.random.uniform(high=VOCAB_SIZE, shape=(32, 4)).astype(mx.int32)\n",
    "# create mask to prevent attention to future tokens\n",
    "mask = create_causal_mask_triu(x.shape[1])\n",
    "output = model(x, mask)  # Forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc076921",
   "metadata": {},
   "source": [
    "# Merge dataset to txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c7c37fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "# ds = load_dataset(\"roneneldan/TinyStories\")\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcfffceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = ds['train']\n",
    "# print(f'Train data shape: {train_data.shape}')\n",
    "# valid_data = ds['validation']\n",
    "# print(f'Validation data shape: {valid_data.shape}')\n",
    "# print('\\n---------------------------------\\n')\n",
    "# print('This is a sample from the training data:\\n')\n",
    "# print(train_data[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d4ddf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_file_path = './data/tinystories_data.txt'\n",
    "\n",
    "# with open(text_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#     for example in train_data:\n",
    "#         f.write(example['text'] + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2340807f",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "797a537d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer file ./data/tinystories-tokenizer_2000.json already exists. Skipping training.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(f'{TOKENIZER_FILE}_{VOCAB_SIZE}.json'):\n",
    "    print(f\"Tokenizer file {TOKENIZER_FILE}_{VOCAB_SIZE}.json already exists. Skipping training.\")\n",
    "else:\n",
    "    # Initialize a BPE tokenizer\n",
    "    tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "    tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "    # Configure the trainer with a vocabulary size and special tokens\n",
    "    trainer = BpeTrainer(vocab_size=VOCAB_SIZE, special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"])\n",
    "\n",
    "    # Train the tokenizer on our text file\n",
    "    print(\"Training tokenizer...\")\n",
    "    tokenizer.train(['./data/tinystories_data.txt'], trainer)\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # --- Save and Test the Tokenizer ---\n",
    "    tokenizer_path = f'{TOKENIZER_FILE}_{VOCAB_SIZE}.json'\n",
    "    tokenizer.save(tokenizer_path)\n",
    "    print(f\"Tokenizer saved to {tokenizer_path}\")\n",
    "\n",
    "    # Load it back and test\n",
    "    tokenizer = Tokenizer.from_file(tokenizer_path)\n",
    "    encoded = tokenizer.encode(\"Once upon a time, there was a little fox.\")\n",
    "\n",
    "    print(\"\\n--- Testing the Tokenizer ---\")\n",
    "    print(\"Tokens:\", encoded.tokens)\n",
    "    print(\"IDs:\", encoded.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0d52e8",
   "metadata": {},
   "source": [
    "# Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aa64fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk file ./data/chunked_stories_2000_256.npz already exists. Skipping chunking.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(f'{CHUNK_FILE}_{VOCAB_SIZE}_{CONTEXT_LENGTH}.npz'):\n",
    "    print(f\"Chunk file {CHUNK_FILE}_{VOCAB_SIZE}_{CONTEXT_LENGTH}.npz already exists. Skipping chunking.\")\n",
    "else:\n",
    "    # Load the dataset (use a subset for testing)\n",
    "    dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train\")\n",
    "    if SAMPLE_LIMIT:\n",
    "        dataset = dataset.select(range(min(SAMPLE_LIMIT, len(dataset))))\n",
    "\n",
    "    # Load the tokenizer\n",
    "    tokenizer = Tokenizer.from_file(f'{TOKENIZER_FILE}_{VOCAB_SIZE}.json')\n",
    "\n",
    "    # Process all stories and collect chunks\n",
    "    all_chunks = []\n",
    "    for story in tqdm(dataset[\"text\"], desc=\"Chunking stories\"):\n",
    "        story_chunks = chunk_story(story, tokenizer, '[EOS]', '[PAD]', CONTEXT_LENGTH)\n",
    "        all_chunks.extend(story_chunks)\n",
    "\n",
    "    # Convert list to numpy array for efficient storage\n",
    "    chunks_array = np.array(all_chunks, dtype=np.int32)\n",
    "\n",
    "    # Print statistics\n",
    "    print(f\"Created {len(all_chunks)} chunks of length {CONTEXT_LENGTH}\")\n",
    "    print(f\"Total tokens: {len(all_chunks) * CONTEXT_LENGTH:,}\")\n",
    "    print(f\"Array shape: {chunks_array.shape}\")\n",
    "\n",
    "    # Save the chunks to a compressed file\n",
    "    print(f\"Saving chunks to {CHUNK_FILE}_{VOCAB_SIZE}_{CONTEXT_LENGTH}.npz...\")\n",
    "    np.savez_compressed(f'{CHUNK_FILE}_{VOCAB_SIZE}_{CONTEXT_LENGTH}.npz', chunks=chunks_array)\n",
    "    print(f\"Saved successfully! File size: {os.path.getsize(f'{CHUNK_FILE}_{VOCAB_SIZE}_{CONTEXT_LENGTH}.npz') / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956f4788",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0657c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(f'{CHUNK_FILE}_{VOCAB_SIZE}_{CONTEXT_LENGTH}.npz')\n",
    "dicts = data_to_array_of_dict(data['chunks'], name=DICT_LABEL)\n",
    "\n",
    "assert type(dicts) == list\n",
    "assert type(dicts[0]) == dict\n",
    "assert type(dicts[0][DICT_LABEL]) == np.ndarray\n",
    "\n",
    "buffer = dx.buffer_from_vector(dicts)\n",
    "stream = buffer.shuffle().to_stream().batch(32).prefetch(8,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f6b69af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 256)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for x in stream:\n",
    "    print(x[DICT_LABEL].shape)\n",
    "    print(type(x[DICT_LABEL]))\n",
    "    break  # Just to test the first batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5f0f44",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7657796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_file(f'{TOKENIZER_FILE}_{VOCAB_SIZE}.json')\n",
    "pad_token_id = tokenizer.token_to_id('[PAD]')\n",
    "optimizer = optim.AdamW(learning_rate=0.001, betas=[0.9, 0.95], weight_decay=0.1)\n",
    "loss_and_grad_fn = nn.value_and_grad(model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bba11ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6dd17962cb143d4b11fa90c0d689c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================\n",
      "Metal active memory: 0.00 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.00 GB\n",
      "========================================================\n",
      "Metal active memory: 0.00 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.00 GB\n",
      "========================================================\n",
      "Metal active memory: 0.00 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.00 GB\n",
      "========================================================\n",
      "Metal active memory: 0.00 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.00 GB\n",
      "========================================================\n",
      "Metal active memory: 0.01 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.01 GB\n",
      "========================================================\n",
      "Metal active memory: 0.01 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.01 GB\n",
      "========================================================\n",
      "Metal active memory: 0.01 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.01 GB\n",
      "========================================================\n",
      "Metal active memory: 0.01 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.01 GB\n",
      "========================================================\n",
      "Metal active memory: 0.01 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.01 GB\n",
      "========================================================\n",
      "Metal active memory: 0.01 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.01 GB\n",
      "========================================================\n",
      "Metal active memory: 0.02 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.02 GB\n",
      "========================================================\n",
      "Metal active memory: 0.02 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.02 GB\n",
      "========================================================\n",
      "Metal active memory: 0.02 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.02 GB\n",
      "========================================================\n",
      "Metal active memory: 0.02 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.02 GB\n",
      "========================================================\n",
      "Metal active memory: 0.02 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.02 GB\n",
      "========================================================\n",
      "Metal active memory: 0.02 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.02 GB\n",
      "========================================================\n",
      "Metal active memory: 0.02 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.02 GB\n",
      "========================================================\n",
      "Metal active memory: 0.03 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.03 GB\n",
      "========================================================\n",
      "Metal active memory: 0.03 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.03 GB\n",
      "========================================================\n",
      "Metal active memory: 0.03 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.03 GB\n",
      "========================================================\n",
      "Metal active memory: 0.03 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.03 GB\n",
      "========================================================\n",
      "Metal active memory: 0.03 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.03 GB\n",
      "========================================================\n",
      "Metal active memory: 0.03 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.03 GB\n",
      "========================================================\n",
      "Metal active memory: 0.04 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.04 GB\n",
      "========================================================\n",
      "Metal active memory: 0.04 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.04 GB\n",
      "========================================================\n",
      "Metal active memory: 0.04 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.04 GB\n",
      "========================================================\n",
      "Metal active memory: 0.04 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.04 GB\n",
      "========================================================\n",
      "Metal active memory: 0.04 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.04 GB\n",
      "========================================================\n",
      "Metal active memory: 0.04 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.04 GB\n",
      "========================================================\n",
      "Metal active memory: 0.04 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.04 GB\n",
      "========================================================\n",
      "Metal active memory: 0.05 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.05 GB\n",
      "========================================================\n",
      "Metal active memory: 0.05 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.05 GB\n",
      "========================================================\n",
      "Metal active memory: 0.05 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.05 GB\n",
      "========================================================\n",
      "Metal active memory: 0.05 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.05 GB\n",
      "========================================================\n",
      "Metal active memory: 0.05 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.05 GB\n",
      "========================================================\n",
      "Metal active memory: 0.05 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.05 GB\n",
      "========================================================\n",
      "Metal active memory: 0.06 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.06 GB\n",
      "========================================================\n",
      "Metal active memory: 0.06 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.06 GB\n",
      "========================================================\n",
      "Metal active memory: 0.06 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.06 GB\n",
      "========================================================\n",
      "Metal active memory: 0.06 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.06 GB\n",
      "========================================================\n",
      "Metal active memory: 0.06 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.06 GB\n",
      "========================================================\n",
      "Metal active memory: 0.06 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.06 GB\n",
      "========================================================\n",
      "Metal active memory: 0.07 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.07 GB\n",
      "========================================================\n",
      "Metal active memory: 0.07 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.07 GB\n",
      "========================================================\n",
      "Metal active memory: 0.07 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.07 GB\n",
      "========================================================\n",
      "Metal active memory: 0.07 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.07 GB\n",
      "========================================================\n",
      "Metal active memory: 0.07 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.07 GB\n",
      "========================================================\n",
      "Metal active memory: 0.07 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.07 GB\n",
      "========================================================\n",
      "Metal active memory: 0.07 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.07 GB\n",
      "========================================================\n",
      "Metal active memory: 0.08 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.08 GB\n",
      "========================================================\n",
      "Metal active memory: 0.08 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.08 GB\n",
      "========================================================\n",
      "Metal active memory: 0.08 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.08 GB\n",
      "========================================================\n",
      "Metal active memory: 0.08 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.08 GB\n",
      "========================================================\n",
      "Metal active memory: 0.08 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.08 GB\n",
      "========================================================\n",
      "Metal active memory: 0.08 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.08 GB\n",
      "========================================================\n",
      "Metal active memory: 0.09 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.09 GB\n",
      "========================================================\n",
      "Metal active memory: 0.09 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.09 GB\n",
      "========================================================\n",
      "Metal active memory: 0.09 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.09 GB\n",
      "========================================================\n",
      "Metal active memory: 0.09 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.09 GB\n",
      "========================================================\n",
      "Metal active memory: 0.09 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.09 GB\n",
      "========================================================\n",
      "Metal active memory: 0.09 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.09 GB\n",
      "========================================================\n",
      "Metal active memory: 0.09 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.09 GB\n",
      "========================================================\n",
      "Metal active memory: 0.10 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.10 GB\n",
      "========================================================\n",
      "Metal active memory: 0.10 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.10 GB\n",
      "========================================================\n",
      "Metal active memory: 0.10 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.10 GB\n",
      "========================================================\n",
      "Metal active memory: 0.10 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.10 GB\n",
      "========================================================\n",
      "Metal active memory: 0.10 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.10 GB\n",
      "========================================================\n",
      "Metal active memory: 0.10 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.10 GB\n",
      "========================================================\n",
      "Metal active memory: 0.11 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.11 GB\n",
      "========================================================\n",
      "Metal active memory: 0.11 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.11 GB\n",
      "========================================================\n",
      "Metal active memory: 0.11 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.11 GB\n",
      "========================================================\n",
      "Metal active memory: 0.11 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.11 GB\n",
      "========================================================\n",
      "Metal active memory: 0.11 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.11 GB\n",
      "========================================================\n",
      "Metal active memory: 0.11 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.11 GB\n",
      "========================================================\n",
      "Metal active memory: 0.11 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.11 GB\n",
      "========================================================\n",
      "Metal active memory: 0.12 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.12 GB\n",
      "========================================================\n",
      "Metal active memory: 0.12 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.12 GB\n",
      "========================================================\n",
      "Metal active memory: 0.12 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.12 GB\n",
      "========================================================\n",
      "Metal active memory: 0.12 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.12 GB\n",
      "========================================================\n",
      "Metal active memory: 0.12 GB\n",
      "Metal cache memory: 0.00 GB\n",
      "Metal peak memory: 0.12 GB\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[metal::malloc] Resource limit (499000) exceeded.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m target_seq = mx_seq[:, \u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# Exclude the first token for target\u001b[39;00m\n\u001b[32m      7\u001b[39m loss, grads = loss_and_grad_fn(model, input_seq, target_seq, pad_token_id)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i % \u001b[32m50\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m========================================================\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/mlx/lib/python3.12/site-packages/mlx/optimizers/optimizers.py:29\u001b[39m, in \u001b[36mOptimizer.update\u001b[39m\u001b[34m(self, model, gradients)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, model: Module, gradients: \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m     21\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Apply the gradients to the parameters of the model and update the\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[33;03m    model with the new parameters.\u001b[39;00m\n\u001b[32m     23\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m \u001b[33;03m                          via :func:`mlx.nn.value_and_grad`.\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     model.update(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/mlx/lib/python3.12/site-packages/mlx/optimizers/optimizers.py:109\u001b[39m, in \u001b[36mOptimizer.apply_gradients\u001b[39m\u001b[34m(self, gradients, parameters)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28mself\u001b[39m.state[\u001b[33m\"\u001b[39m\u001b[33mstep\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.step + \u001b[32m1\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m# Apply the update\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_single\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/mlx/lib/python3.12/site-packages/mlx/utils.py:53\u001b[39m, in \u001b[36mtree_map\u001b[39m\u001b[34m(fn, tree, is_leaf, *rest)\u001b[39m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m TreeType(\n\u001b[32m     48\u001b[39m         tree_map(fn, child, *(r[i] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest), is_leaf=is_leaf)\n\u001b[32m     49\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i, child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tree)\n\u001b[32m     50\u001b[39m     )\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m         k: \u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k, child \u001b[38;5;129;01min\u001b[39;00m tree.items()\n\u001b[32m     55\u001b[39m     }\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(tree, *rest)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/mlx/lib/python3.12/site-packages/mlx/utils.py:53\u001b[39m, in \u001b[36mtree_map\u001b[39m\u001b[34m(fn, tree, is_leaf, *rest)\u001b[39m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m TreeType(\n\u001b[32m     48\u001b[39m         tree_map(fn, child, *(r[i] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest), is_leaf=is_leaf)\n\u001b[32m     49\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i, child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tree)\n\u001b[32m     50\u001b[39m     )\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m         k: \u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k, child \u001b[38;5;129;01min\u001b[39;00m tree.items()\n\u001b[32m     55\u001b[39m     }\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(tree, *rest)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/mlx/lib/python3.12/site-packages/mlx/utils.py:47\u001b[39m, in \u001b[36mtree_map\u001b[39m\u001b[34m(fn, tree, is_leaf, *rest)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m     46\u001b[39m     TreeType = \u001b[38;5;28mtype\u001b[39m(tree)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTreeType\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     53\u001b[39m         k: tree_map(fn, child, *(r[k] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest), is_leaf=is_leaf)\n\u001b[32m     54\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k, child \u001b[38;5;129;01min\u001b[39;00m tree.items()\n\u001b[32m     55\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/mlx/lib/python3.12/site-packages/mlx/utils.py:48\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m     46\u001b[39m     TreeType = \u001b[38;5;28mtype\u001b[39m(tree)\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m TreeType(\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m         \u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i, child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tree)\n\u001b[32m     50\u001b[39m     )\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     53\u001b[39m         k: tree_map(fn, child, *(r[k] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest), is_leaf=is_leaf)\n\u001b[32m     54\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k, child \u001b[38;5;129;01min\u001b[39;00m tree.items()\n\u001b[32m     55\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/mlx/lib/python3.12/site-packages/mlx/utils.py:53\u001b[39m, in \u001b[36mtree_map\u001b[39m\u001b[34m(fn, tree, is_leaf, *rest)\u001b[39m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m TreeType(\n\u001b[32m     48\u001b[39m         tree_map(fn, child, *(r[i] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest), is_leaf=is_leaf)\n\u001b[32m     49\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i, child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tree)\n\u001b[32m     50\u001b[39m     )\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m         k: \u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k, child \u001b[38;5;129;01min\u001b[39;00m tree.items()\n\u001b[32m     55\u001b[39m     }\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(tree, *rest)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/mlx/lib/python3.12/site-packages/mlx/utils.py:53\u001b[39m, in \u001b[36mtree_map\u001b[39m\u001b[34m(fn, tree, is_leaf, *rest)\u001b[39m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m TreeType(\n\u001b[32m     48\u001b[39m         tree_map(fn, child, *(r[i] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest), is_leaf=is_leaf)\n\u001b[32m     49\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i, child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tree)\n\u001b[32m     50\u001b[39m     )\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m         k: \u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k, child \u001b[38;5;129;01min\u001b[39;00m tree.items()\n\u001b[32m     55\u001b[39m     }\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(tree, *rest)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/mlx/lib/python3.12/site-packages/mlx/utils.py:53\u001b[39m, in \u001b[36mtree_map\u001b[39m\u001b[34m(fn, tree, is_leaf, *rest)\u001b[39m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m TreeType(\n\u001b[32m     48\u001b[39m         tree_map(fn, child, *(r[i] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest), is_leaf=is_leaf)\n\u001b[32m     49\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i, child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tree)\n\u001b[32m     50\u001b[39m     )\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m         k: \u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k, child \u001b[38;5;129;01min\u001b[39;00m tree.items()\n\u001b[32m     55\u001b[39m     }\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(tree, *rest)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/mlx/lib/python3.12/site-packages/mlx/utils.py:57\u001b[39m, in \u001b[36mtree_map\u001b[39m\u001b[34m(fn, tree, is_leaf, *rest)\u001b[39m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     53\u001b[39m         k: tree_map(fn, child, *(r[k] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest), is_leaf=is_leaf)\n\u001b[32m     54\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k, child \u001b[38;5;129;01min\u001b[39;00m tree.items()\n\u001b[32m     55\u001b[39m     }\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mrest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/mlx/lib/python3.12/site-packages/mlx/optimizers/optimizers.py:586\u001b[39m, in \u001b[36mAdamW.apply_single\u001b[39m\u001b[34m(self, gradient, parameter, state)\u001b[39m\n\u001b[32m    581\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Performs the AdamW parameter update by modifying the parameters\u001b[39;00m\n\u001b[32m    582\u001b[39m \u001b[33;03mpassed into Adam.\u001b[39;00m\n\u001b[32m    583\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    585\u001b[39m lr = \u001b[38;5;28mself\u001b[39m.learning_rate.astype(gradient.dtype)\n\u001b[32m--> \u001b[39m\u001b[32m586\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    587\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameter\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\n\u001b[32m    588\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/mlx/lib/python3.12/site-packages/mlx/optimizers/optimizers.py:524\u001b[39m, in \u001b[36mAdam.apply_single\u001b[39m\u001b[34m(self, gradient, parameter, state)\u001b[39m\n\u001b[32m    522\u001b[39m v = state[\u001b[33m\"\u001b[39m\u001b[33mv\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    523\u001b[39m m = b1 * m + (\u001b[32m1\u001b[39m - b1) * gradient\n\u001b[32m--> \u001b[39m\u001b[32m524\u001b[39m v = b2 * v + \u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mmx\u001b[49m\u001b[43m.\u001b[49m\u001b[43msquare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    525\u001b[39m state[\u001b[33m\"\u001b[39m\u001b[33mm\u001b[39m\u001b[33m\"\u001b[39m] = m\n\u001b[32m    526\u001b[39m state[\u001b[33m\"\u001b[39m\u001b[33mv\u001b[39m\u001b[33m\"\u001b[39m] = v\n",
      "\u001b[31mRuntimeError\u001b[39m: [metal::malloc] Resource limit (499000) exceeded."
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    losses = []\n",
    "    for i, seq in tqdm(enumerate(stream), desc=\"Processing batches\"):\n",
    "        mx_seq = mx.array(seq[DICT_LABEL])\n",
    "        input_seq = mx_seq[:, :-1]  # Exclude the last token for input\n",
    "        target_seq = mx_seq[:, 1:]  # Exclude the first token for target\n",
    "        loss, grads = loss_and_grad_fn(model, input_seq, target_seq, pad_token_id)\n",
    "        optimizer.update(model, grads)\n",
    "        if i % 50 == 0:\n",
    "            print(\"========================================================\")\n",
    "            print(f\"Metal active memory: {mx.get_active_memory() / 1024**3:.2f} GB\")\n",
    "            print(f\"Metal cache memory: {mx.get_cache_memory() / 1024**3:.2f} GB\")\n",
    "            print(f\"Metal peak memory: {mx.get_peak_memory() / 1024**3:.2f} GB\")\n",
    "        # print(f\"Batch {i + 1}, Loss: {loss:.4f}\")\n",
    "        # break\n",
    "    # print average loss for the epoch with tqdm progress bar\n",
    "    avg_loss = mx.array(losses).mean()\n",
    "    tqdm.write(f\"Epoch {epoch + 1}/{10}, Average Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4112c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLX current default device: Device(gpu, 0)\n"
     ]
    }
   ],
   "source": [
    "print(f'MLX current default device: {mx.default_device()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
