{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "939879bc",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b3f288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Configuration\n",
    "CONTEXT_LENGTH = 512  # Fixed context length for chunks\n",
    "EMBEDDING_DIM = 256  # Dimension of the token embeddings\n",
    "NUM_HEADS = 8  # Number of attention heads\n",
    "NUM_LAYERS = 3  # Number of transformer layers\n",
    "QK_HEAD_DIM = 16  # Dimension of the query and key heads\n",
    "V_HEAD_DIM = 32  # Dimension of the value head\n",
    "MLP_DIM = 1024  # Dimension of the hidden layers in the transformer\n",
    "DROPOUT_RATE = 0.1  # Dropout rate for regularization\n",
    "\n",
    "# Data Configuration\n",
    "VOCAB_SIZE = 512  # Size of the vocabulary\n",
    "PADDING = True # Whether to pad sequences\n",
    "PACKING = True # Whether to pack sequences for training\n",
    "\n",
    "# Training Configuration\n",
    "SEED = 42  # Random seed for reproducibility\n",
    "BATCH_SIZE = 128  # Batch size for training\n",
    "EPOCHS = 10 # Number of epochs to train\n",
    "SAMPLE_LIMIT = 200000  # Set to None to process the entire dataset\n",
    "LR = 0.001  # Learning rate for the optimizer\n",
    "WEIGHT_DECAY = 0.01  # Weight decay for the optimizer\n",
    "BETA1 = 0.9  # Beta1 for the Adam optimizer\n",
    "BETA2 = 0.999  # Beta2 for the Adam optimizer\n",
    "\n",
    "# File Paths and Labels\n",
    "TOKENIZER_FILE = \"./data/tinystories-tokenizer\"\n",
    "CHUNK_FILE = \"./data/chunked_stories\"\n",
    "LOG_DIR = None\n",
    "# LOG_DIR = './runs/2025-08-26_17-09-10'\n",
    "DICT_LABEL = 'seq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ba92886",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from models.torch import SmallLanguageModel, loss_fn, print_story\n",
    "from data.utils import train_tokenizer, chunk_story, create_dict_parameters, encode_story, pack_stories, pretty_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23fe6e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging parameters\n"
     ]
    }
   ],
   "source": [
    "params = create_dict_parameters(locals())\n",
    "LOG_DIR = f'runs/{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}' if LOG_DIR is None else LOG_DIR\n",
    "writer = SummaryWriter(log_dir=LOG_DIR)\n",
    "if len(list(Path(LOG_DIR).glob('events.out.tfevents.*'))) == 1:\n",
    "    print(f\"Logging parameters\")\n",
    "    writer.add_text('Parameters', pretty_json(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2340807f",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "797a537d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer file ./data/tinystories-tokenizer_512_200000.json already exists. Skipping training.\n",
      "\n",
      "--- Testing the Tokenizer ---\n",
      "Tokens: [' Once', ' upon', ' a', ' time,', ' there', ' was', ' a', ' little', ' f', 'o', 'x', '.', '\\n', ' It', ' li', 'ved', ' in', ' a', ' f', 'ore', 'st', ' and', ' loved', ' to', ' ex', 'pl', 'ore', '.']\n",
      "IDs: [302, 321, 126, 350, 272, 149, 126, 269, 140, 82, 91, 20, 4, 276, 245, 297, 185, 126, 140, 299, 236, 132, 382, 133, 346, 493, 299, 20]\n",
      "Decoded: Once upon a time, there was a little fox. It lived in a forest and loved to explore.\n"
     ]
    }
   ],
   "source": [
    "tokenizer_path = f'{TOKENIZER_FILE}_{VOCAB_SIZE}_{SAMPLE_LIMIT}.json'\n",
    "if os.path.exists(tokenizer_path):\n",
    "    tokenizer = Tokenizer.from_file(tokenizer_path)\n",
    "    print(f\"Tokenizer file {tokenizer_path} already exists. Skipping training.\")\n",
    "else:\n",
    "    dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train\")\n",
    "    if SAMPLE_LIMIT:\n",
    "        dataset = dataset.select(range(min(SAMPLE_LIMIT, len(dataset))))\n",
    "    tokenizer = train_tokenizer(dataset, vocab_size=VOCAB_SIZE, special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\", \"\\n\"])\n",
    "    tokenizer.save(tokenizer_path)\n",
    "    print(f\"Tokenizer saved to {tokenizer_path}\")\n",
    "\n",
    "sos_token_id = tokenizer.token_to_id('[SOS]')\n",
    "eos_token_id = tokenizer.token_to_id('[EOS]')\n",
    "pad_token_id = tokenizer.token_to_id('[PAD]')\n",
    "\n",
    "tokenizer = Tokenizer.from_file(tokenizer_path)\n",
    "encoded = tokenizer.encode(\"Once upon a time, there was a little fox.\\nIt lived in a forest and loved to explore.\")\n",
    "\n",
    "print(\"\\n--- Testing the Tokenizer ---\")\n",
    "print(\"Tokens:\", encoded.tokens)\n",
    "print(\"IDs:\", encoded.ids)\n",
    "print(\"Decoded:\", tokenizer.decode(encoded.ids, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0d52e8",
   "metadata": {},
   "source": [
    "# Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aa64fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk file ./data/chunked_stories_512_512_200000_padding_packing.npz already exists. Skipping chunking.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if PADDING and PACKING:\n",
    "    chunk_file_path = f'{CHUNK_FILE}_{VOCAB_SIZE}_{CONTEXT_LENGTH}_{SAMPLE_LIMIT}_padding_packing.npz'\n",
    "elif PADDING:\n",
    "    chunk_file_path = f'{CHUNK_FILE}_{VOCAB_SIZE}_{CONTEXT_LENGTH}_{SAMPLE_LIMIT}_padding.npz'\n",
    "elif PACKING:\n",
    "    chunk_file_path = f'{CHUNK_FILE}_{VOCAB_SIZE}_{CONTEXT_LENGTH}_{SAMPLE_LIMIT}_packing.npz'\n",
    "else:\n",
    "    chunk_file_path = f'{CHUNK_FILE}_{VOCAB_SIZE}_{CONTEXT_LENGTH}_{SAMPLE_LIMIT}.npz'\n",
    "figure_path = f'./figures/histogram_{VOCAB_SIZE}_{SAMPLE_LIMIT}.png'\n",
    "if os.path.exists(chunk_file_path):\n",
    "    print(f\"Chunk file {chunk_file_path} already exists. Skipping chunking.\")\n",
    "\n",
    "    # display the existing histogram\n",
    "    plt.imshow(plt.imread(figure_path))\n",
    "    plt.axis('off')\n",
    "else:\n",
    "    # Load the dataset\n",
    "    if not ('dataset' in locals()):\n",
    "        dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train\")\n",
    "        if SAMPLE_LIMIT:\n",
    "            dataset = dataset.select(range(min(SAMPLE_LIMIT, len(dataset))))\n",
    "\n",
    "    # Load the tokenizer\n",
    "    tokenizer = Tokenizer.from_file(tokenizer_path)\n",
    "\n",
    "    # Process all stories and collect chunks\n",
    "    all_chunks = []\n",
    "    unfinished_chunk = []\n",
    "    num_non_special_tokens = []\n",
    "    for story in tqdm(dataset[\"text\"], desc=\"Chunking stories\"):\n",
    "        if PACKING:\n",
    "            story_chunks, non_special_token_count = encode_story(story, tokenizer, '[SOS]', '[EOS]')\n",
    "            all_chunks.append(story_chunks)\n",
    "        else:\n",
    "            story_chunks, unfinished_chunk, non_special_token_count = chunk_story(story, tokenizer, '[SOS]', '[EOS]', CONTEXT_LENGTH,\n",
    "                                                            unfinished_chunk=unfinished_chunk, padding=PADDING, pad_token='[PAD]')\n",
    "            all_chunks.extend(story_chunks)\n",
    "        num_non_special_tokens.append(non_special_token_count)\n",
    "\n",
    "    # Convert list to numpy array for efficient storage\n",
    "    if PACKING:\n",
    "        chunks_array = np.array(pack_stories(all_chunks, CONTEXT_LENGTH, tokenizer.token_to_id('[PAD]')), dtype=np.int32)\n",
    "    else:\n",
    "        chunks_array = np.array(all_chunks, dtype=np.int32)\n",
    "    unique_tokens, counts = np.unique(chunks_array, return_counts=True)\n",
    "\n",
    "    # Print statistics\n",
    "    print(f\"Total tokens: {CONTEXT_LENGTH * chunks_array.shape[0]:,}\")\n",
    "    print(f\"Total non-special tokens: {np.sum(counts[3:]):,}\")\n",
    "    print(f\"Number of special tokens: {np.sum(counts[:3]):,}\")\n",
    "    print(f\"Array shape: {chunks_array.shape}\")\n",
    "\n",
    "    # Save the chunks to a compressed file\n",
    "    print(f\"Saving chunks to {chunk_file_path}...\")\n",
    "    np.savez_compressed(chunk_file_path, chunks=chunks_array)\n",
    "    print(f\"Saved successfully! File size: {os.path.getsize(chunk_file_path) / (1024 * 1024):.2f} MB\")\n",
    "    if PADDING and PACKING:\n",
    "        text_info_path = f'./data/chunk_info_{VOCAB_SIZE}_{CONTEXT_LENGTH}_{SAMPLE_LIMIT}_padding_packing.txt'\n",
    "    elif PADDING:\n",
    "        text_info_path = f'./data/chunk_info_{VOCAB_SIZE}_{CONTEXT_LENGTH}_{SAMPLE_LIMIT}_padding.txt'\n",
    "    elif PACKING:\n",
    "        text_info_path = f'./data/chunk_info_{VOCAB_SIZE}_{CONTEXT_LENGTH}_{SAMPLE_LIMIT}_packing.txt'\n",
    "    else:\n",
    "        text_info_path = f'./data/chunk_info_{VOCAB_SIZE}_{CONTEXT_LENGTH}_{SAMPLE_LIMIT}.txt'\n",
    "\n",
    "    plt.hist(num_non_special_tokens, bins=50, color='blue')\n",
    "    plt.title(\"Distribution of Story Lengths\")\n",
    "    plt.xlabel(\"Length (number of tokens)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.savefig(figure_path)\n",
    "\n",
    "    with open(text_info_path, 'w') as f:\n",
    "        f.write(f\"Sample limit: {SAMPLE_LIMIT:,}\\n\")\n",
    "        f.write(f\"Vocabulary Size: {VOCAB_SIZE:,}\\n\")\n",
    "        f.write(f\"Context length: {CONTEXT_LENGTH:,}\\n\")\n",
    "        f.write(f\"Number of chunks: {chunks_array.shape[0]:,}\\n\")\n",
    "        f.write(f\"Number of tokens: {CONTEXT_LENGTH * chunks_array.shape[0]:,}\\n\")\n",
    "        f.write(f\"Number of non-special tokens: {np.sum(counts[3:]):,}\\n\")\n",
    "        f.write(f\"Number of special tokens: {np.sum(counts[:3]):,}\\n\")\n",
    "        f.write(f\"Padding used: {PADDING}\\n\")\n",
    "        f.write(f\"Packing used: {PACKING}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956f4788",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0657c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches per epoch: 966\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(SEED)\n",
    "data = np.load(chunk_file_path)['chunks']\n",
    "\n",
    "# Create dataset\n",
    "class StoryDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "dataset = StoryDataset(data)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE,\n",
    "shuffle=True)\n",
    "num_batches = len(dataloader)\n",
    "print(f\"Number of batches per epoch: {num_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f6b69af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 512)\n",
      "<class 'numpy.ndarray'>\n",
      "[SOS] Once upon a time, there was a boy named Timmy. Timmy was a very clean boy who loved to play outside. One day, Timmy's mom asked him to clean\n",
      "up his toys before he could go outside to play. Timmy didn't want to clean up and said, \"I don't want to clean up, I want to go play outside\n",
      "now!\"\n",
      "\n",
      " Timmy's mom replied, \"Timmy, it's important to clean up after ourselves. If we don't, our toys will get lost or broken. Plus, it's not fair to leave a mess\n",
      "for someone else to clean up.\"\n",
      "\n",
      " Timmy thought about what his mom said and realized she was right. He cleaned up his toys and went outside to play. Later that\n",
      "day, Timmy's friend came over and saw how clean Timmy's room was. His friend said, \"Wow, Timmy! Your room is so clean! I wish my room was as clean as\n",
      "yours.\"\n",
      "\n",
      " Timmy smiled and said, \"Thanks! My mom taught me that it's important to clean up after ourselves and not leave a mess for someone else to clean up.\"[EOS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "[SOS] Once upon a time, there was a lazy cat named Mittens. Mittens loved to lay in the sun all day long and never did anything. One day, Mittens saw\n",
      "a bird flying high in the sky and wanted to catch it. \n",
      "\n",
      " Mittens asked his friend, a dog named Spot, \"How can I catch that bird?\" \n",
      "\n",
      " Spot answered,\n",
      "\"You can't catch it with your lazy ways. You need to run and jump high to catch it.\" \n",
      "\n",
      " Mittens thought about it and decided to try. He ran and\n",
      "jumped but missed the bird. He fell down and hurt his palm. \n",
      "\n",
      " Spot asked, \"Are you okay?\" \n",
      "\n",
      " Mittens answered, \"Yes, I am okay. I will try again tomorrow.\"\n",
      "\n",
      "\n",
      " From that day on, Mittens was no longer lazy. He practiced running and jumping every day until he was able to catch the bird. And he lived happily ever\n",
      "after.[EOS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n"
     ]
    }
   ],
   "source": [
    "for x in dataloader:\n",
    "    x = x.numpy()\n",
    "    print(x.shape)\n",
    "    print(type(x))\n",
    "    text = tokenizer.decode(x[0], skip_special_tokens=False).split(' ')\n",
    "    for i in range(0, len(text), 30):\n",
    "        print(' '.join(text[i:i+30]))\n",
    "    text = tokenizer.decode(x[BATCH_SIZE-1], skip_special_tokens=False).split(' ')\n",
    "    for i in range(0, len(text), 30):\n",
    "        print(' '.join(text[i:i+30]))\n",
    "    break  # Just to test the first batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aa72f0",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a15263a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the model: 2,432,256\n"
     ]
    }
   ],
   "source": [
    "model = SmallLanguageModel(vocab_dim=VOCAB_SIZE, embed_dim=EMBEDDING_DIM, n_head=NUM_HEADS, num_layers=NUM_LAYERS, qk_head_dim=QK_HEAD_DIM, v_head_dim=V_HEAD_DIM, mlp_dim=MLP_DIM, max_len=CONTEXT_LENGTH, dropout_rate=DROPOUT_RATE)\n",
    "model.to(device)\n",
    "print(f\"Number of parameters in the model: {sum(param.numel() for param in model.parameters()):,}\")\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR, betas=[BETA1, BETA2], weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5f0f44",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf0600c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f'{LOG_DIR}/checkpoint.pt'):\n",
    "    checkpoint = torch.load(f'{LOG_DIR}/checkpoint.pt', weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    torch.set_rng_state(checkpoint['rng_state'])\n",
    "    start_epoch_from = checkpoint['start_epoch_from']\n",
    "    print(f\"Resuming training from epoch {start_epoch_from}.\")\n",
    "else:\n",
    "    start_epoch_from = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bba11ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0, Loss: 6.3825\n",
      "Batch 1, Loss: 5.9966\n",
      "Batch 2, Loss: 5.7431\n",
      "Batch 3, Loss: 5.5903\n",
      "Batch 4, Loss: 5.4793\n",
      "Batch 5, Loss: 5.3770\n",
      "Batch 6, Loss: 5.2801\n",
      "Batch 7, Loss: 5.1703\n",
      "Batch 8, Loss: 5.0967\n",
      "Batch 9, Loss: 4.9891\n",
      "Batch 10, Loss: 4.9429\n",
      "Batch 11, Loss: 4.8451\n",
      "Batch 12, Loss: 4.7593\n",
      "Batch 13, Loss: 4.6891\n",
      "Batch 14, Loss: 4.6242\n",
      "Batch 15, Loss: 4.5500\n",
      "Batch 16, Loss: 4.5034\n",
      "Batch 17, Loss: 4.4227\n",
      "Batch 18, Loss: 4.3651\n",
      "Batch 19, Loss: 4.2915\n",
      "Batch 20, Loss: 4.2370\n",
      "Batch 21, Loss: 4.1997\n",
      "Batch 22, Loss: 4.1425\n",
      "Batch 23, Loss: 4.0916\n",
      "Batch 24, Loss: 4.0600\n",
      "Batch 25, Loss: 4.0291\n",
      "Batch 26, Loss: 3.9663\n",
      "Batch 27, Loss: 3.9759\n",
      "Batch 28, Loss: 3.9535\n",
      "Batch 29, Loss: 3.8676\n",
      "Batch 30, Loss: 3.8634\n",
      "Batch 31, Loss: 3.8482\n",
      "Batch 32, Loss: 3.7910\n",
      "Batch 33, Loss: 3.7920\n",
      "Batch 34, Loss: 3.7781\n",
      "Batch 35, Loss: 3.7456\n",
      "Batch 36, Loss: 3.7300\n",
      "Batch 37, Loss: 3.6884\n",
      "Batch 38, Loss: 3.6821\n",
      "Batch 39, Loss: 3.6611\n",
      "Batch 40, Loss: 3.6317\n",
      "Batch 41, Loss: 3.6379\n",
      "Batch 42, Loss: 3.6181\n",
      "Batch 43, Loss: 3.6101\n",
      "Batch 44, Loss: 3.5915\n",
      "Batch 45, Loss: 3.6191\n",
      "Batch 46, Loss: 3.5761\n",
      "Batch 47, Loss: 3.5823\n",
      "Batch 48, Loss: 3.5654\n",
      "Batch 49, Loss: 3.5697\n",
      "Batch 50, Loss: 3.5205\n",
      "Batch 51, Loss: 3.5428\n",
      "Batch 52, Loss: 3.5029\n",
      "Batch 53, Loss: 3.5100\n",
      "Batch 54, Loss: 3.5270\n",
      "Batch 55, Loss: 3.5197\n",
      "Batch 56, Loss: 3.5230\n",
      "Batch 57, Loss: 3.5002\n",
      "Batch 58, Loss: 3.5153\n",
      "Batch 59, Loss: 3.4730\n",
      "Batch 60, Loss: 3.4829\n",
      "Batch 61, Loss: 3.4703\n",
      "Batch 62, Loss: 3.4574\n",
      "Batch 63, Loss: 3.4571\n",
      "Batch 64, Loss: 3.4741\n",
      "Batch 65, Loss: 3.4319\n",
      "Batch 66, Loss: 3.4449\n",
      "Batch 67, Loss: 3.4356\n",
      "Batch 68, Loss: 3.4302\n",
      "Batch 69, Loss: 3.4067\n",
      "Batch 70, Loss: 3.4503\n",
      "Batch 71, Loss: 3.4182\n",
      "Batch 72, Loss: 3.4037\n",
      "Batch 73, Loss: 3.4268\n",
      "Batch 74, Loss: 3.4266\n",
      "Batch 75, Loss: 3.4137\n",
      "Batch 76, Loss: 3.3921\n",
      "Batch 77, Loss: 3.4006\n",
      "Batch 78, Loss: 3.4024\n",
      "Batch 79, Loss: 3.3987\n",
      "Batch 80, Loss: 3.4034\n",
      "Batch 81, Loss: 3.3774\n",
      "Batch 82, Loss: 3.3834\n",
      "Batch 83, Loss: 3.3632\n",
      "Batch 84, Loss: 3.3651\n",
      "Batch 85, Loss: 3.3661\n",
      "Batch 86, Loss: 3.3527\n",
      "Batch 87, Loss: 3.3667\n",
      "Batch 88, Loss: 3.3244\n",
      "Batch 89, Loss: 3.3756\n",
      "Batch 90, Loss: 3.3574\n",
      "Batch 91, Loss: 3.3554\n",
      "Batch 92, Loss: 3.3579\n",
      "Batch 93, Loss: 3.3433\n",
      "Batch 94, Loss: 3.3092\n",
      "Batch 95, Loss: 3.3421\n",
      "Batch 96, Loss: 3.3044\n",
      "Batch 97, Loss: 3.3300\n",
      "Batch 98, Loss: 3.3168\n",
      "Batch 99, Loss: 3.3081\n",
      "Batch 100, Loss: 3.2901\n",
      "Batch 101, Loss: 3.2897\n",
      "Batch 102, Loss: 3.3231\n",
      "Batch 103, Loss: 3.2992\n",
      "Batch 104, Loss: 3.3154\n",
      "Batch 105, Loss: 3.2974\n",
      "Batch 106, Loss: 3.3015\n",
      "Batch 107, Loss: 3.2908\n",
      "Batch 108, Loss: 3.2971\n",
      "Batch 109, Loss: 3.2919\n",
      "Batch 110, Loss: 3.2655\n",
      "Batch 111, Loss: 3.2829\n",
      "Batch 112, Loss: 3.2565\n",
      "Batch 113, Loss: 3.2909\n",
      "Batch 114, Loss: 3.2658\n",
      "Batch 115, Loss: 3.2581\n",
      "Batch 116, Loss: 3.2701\n",
      "Batch 117, Loss: 3.2227\n",
      "Batch 118, Loss: 3.2641\n",
      "Batch 119, Loss: 3.2647\n",
      "Batch 120, Loss: 3.2457\n",
      "Batch 121, Loss: 3.2525\n",
      "Batch 122, Loss: 3.2373\n",
      "Batch 123, Loss: 3.2434\n",
      "Batch 124, Loss: 3.2581\n",
      "Batch 125, Loss: 3.2333\n",
      "Batch 126, Loss: 3.2138\n",
      "Batch 127, Loss: 3.2516\n",
      "Batch 128, Loss: 3.2268\n",
      "Batch 129, Loss: 3.2309\n",
      "Batch 130, Loss: 3.2479\n",
      "Batch 131, Loss: 3.2263\n",
      "Batch 132, Loss: 3.2340\n",
      "Batch 133, Loss: 3.2237\n",
      "Batch 134, Loss: 3.2252\n",
      "Batch 135, Loss: 3.2267\n",
      "Batch 136, Loss: 3.2060\n",
      "Batch 137, Loss: 3.2044\n",
      "Batch 138, Loss: 3.1760\n",
      "Batch 139, Loss: 3.1989\n",
      "Batch 140, Loss: 3.1939\n",
      "Batch 141, Loss: 3.1739\n",
      "Batch 142, Loss: 3.1947\n",
      "Batch 143, Loss: 3.2066\n",
      "Batch 144, Loss: 3.1684\n",
      "Batch 145, Loss: 3.1757\n",
      "Batch 146, Loss: 3.1733\n",
      "Batch 147, Loss: 3.1712\n",
      "Batch 148, Loss: 3.1450\n",
      "Batch 149, Loss: 3.1693\n",
      "Batch 150, Loss: 3.1854\n",
      "Batch 151, Loss: 3.1753\n",
      "Batch 152, Loss: 3.1577\n",
      "Batch 153, Loss: 3.1336\n",
      "Batch 154, Loss: 3.1579\n",
      "Batch 155, Loss: 3.1262\n",
      "Batch 156, Loss: 3.1303\n",
      "Batch 157, Loss: 3.1607\n",
      "Batch 158, Loss: 3.1198\n",
      "Batch 159, Loss: 3.1205\n",
      "Batch 160, Loss: 3.1411\n",
      "Batch 161, Loss: 3.1290\n",
      "Batch 162, Loss: 3.1590\n",
      "Batch 163, Loss: 3.1482\n",
      "Batch 164, Loss: 3.1182\n",
      "Batch 165, Loss: 3.1083\n",
      "Batch 166, Loss: 3.1508\n",
      "Batch 167, Loss: 3.1067\n",
      "Batch 168, Loss: 3.1317\n",
      "Batch 169, Loss: 3.1298\n",
      "Batch 170, Loss: 3.1262\n",
      "Batch 171, Loss: 3.1077\n",
      "Batch 172, Loss: 3.1325\n",
      "Batch 173, Loss: 3.1136\n",
      "Batch 174, Loss: 3.0846\n",
      "Batch 175, Loss: 3.1199\n",
      "Batch 176, Loss: 3.1104\n",
      "Batch 177, Loss: 3.0693\n",
      "Batch 178, Loss: 3.0885\n",
      "Batch 179, Loss: 3.0996\n",
      "Batch 180, Loss: 3.0981\n",
      "Batch 181, Loss: 3.0710\n",
      "Batch 182, Loss: 3.0827\n",
      "Batch 183, Loss: 3.1135\n",
      "Batch 184, Loss: 3.0769\n",
      "Batch 185, Loss: 3.0780\n",
      "Batch 186, Loss: 3.0685\n",
      "Batch 187, Loss: 3.0831\n",
      "Batch 188, Loss: 3.0943\n",
      "Batch 189, Loss: 3.0779\n",
      "Batch 190, Loss: 3.0585\n",
      "Batch 191, Loss: 3.0685\n",
      "Batch 192, Loss: 3.0593\n",
      "Batch 193, Loss: 3.0377\n",
      "Batch 194, Loss: 3.0514\n",
      "Batch 195, Loss: 3.0635\n",
      "Batch 196, Loss: 3.0500\n",
      "Batch 197, Loss: 3.0400\n",
      "Batch 198, Loss: 3.0226\n",
      "Batch 199, Loss: 3.0361\n",
      "Batch 200, Loss: 3.0332\n",
      "Batch 201, Loss: 3.0174\n",
      "Batch 202, Loss: 3.0213\n",
      "Batch 203, Loss: 3.0242\n",
      "Batch 204, Loss: 3.0164\n",
      "Batch 205, Loss: 3.0292\n",
      "Batch 206, Loss: 3.0265\n",
      "Batch 207, Loss: 3.0176\n",
      "Batch 208, Loss: 3.0037\n",
      "Batch 209, Loss: 3.0111\n",
      "Batch 210, Loss: 2.9991\n",
      "Batch 211, Loss: 2.9923\n",
      "Batch 212, Loss: 3.0057\n",
      "Batch 213, Loss: 2.9969\n",
      "Batch 214, Loss: 3.0011\n",
      "Batch 215, Loss: 3.0015\n",
      "Batch 216, Loss: 2.9812\n",
      "Batch 217, Loss: 2.9919\n",
      "Batch 218, Loss: 2.9573\n",
      "Batch 219, Loss: 2.9765\n",
      "Batch 220, Loss: 2.9459\n",
      "Batch 221, Loss: 2.9556\n",
      "Batch 222, Loss: 2.9552\n",
      "Batch 223, Loss: 2.9879\n",
      "Batch 224, Loss: 2.9580\n",
      "Batch 225, Loss: 2.9427\n",
      "Batch 226, Loss: 2.9486\n",
      "Batch 227, Loss: 2.9528\n",
      "Batch 228, Loss: 2.9615\n",
      "Batch 229, Loss: 2.9468\n",
      "Batch 230, Loss: 2.9335\n",
      "Batch 231, Loss: 2.9452\n",
      "Batch 232, Loss: 2.9389\n",
      "Batch 233, Loss: 2.9279\n",
      "Batch 234, Loss: 2.9249\n",
      "Batch 235, Loss: 2.9245\n",
      "Batch 236, Loss: 2.9209\n",
      "Batch 237, Loss: 2.9373\n",
      "Batch 238, Loss: 2.9189\n",
      "Batch 239, Loss: 2.9118\n",
      "Batch 240, Loss: 2.8869\n",
      "Batch 241, Loss: 2.9305\n",
      "Batch 242, Loss: 2.9349\n",
      "Batch 243, Loss: 2.9100\n",
      "Batch 244, Loss: 2.8874\n",
      "Batch 245, Loss: 2.8861\n",
      "Batch 246, Loss: 2.9164\n",
      "Batch 247, Loss: 2.8549\n",
      "Batch 248, Loss: 2.8719\n",
      "Batch 249, Loss: 2.8948\n",
      "Batch 250, Loss: 2.8760\n",
      "Batch 251, Loss: 2.8845\n",
      "Batch 252, Loss: 2.8544\n",
      "Batch 253, Loss: 2.8441\n",
      "Batch 254, Loss: 2.8649\n",
      "Batch 255, Loss: 2.8461\n",
      "Batch 256, Loss: 2.8554\n",
      "Batch 257, Loss: 2.8392\n",
      "Batch 258, Loss: 2.8426\n",
      "Batch 259, Loss: 2.8509\n",
      "Batch 260, Loss: 2.8505\n",
      "Batch 261, Loss: 2.8532\n",
      "Batch 262, Loss: 2.8108\n",
      "Batch 263, Loss: 2.8277\n",
      "Batch 264, Loss: 2.8157\n",
      "Batch 265, Loss: 2.8220\n",
      "Batch 266, Loss: 2.8321\n",
      "Batch 267, Loss: 2.8181\n",
      "Batch 268, Loss: 2.8063\n",
      "Batch 269, Loss: 2.8047\n",
      "Batch 270, Loss: 2.7958\n",
      "Batch 271, Loss: 2.7799\n",
      "Batch 272, Loss: 2.8057\n",
      "Batch 273, Loss: 2.7977\n",
      "Batch 274, Loss: 2.8301\n",
      "Batch 275, Loss: 2.7889\n",
      "Batch 276, Loss: 2.7836\n",
      "Batch 277, Loss: 2.7973\n",
      "Batch 278, Loss: 2.7752\n",
      "Batch 279, Loss: 2.7986\n",
      "Batch 280, Loss: 2.7718\n",
      "Batch 281, Loss: 2.7821\n",
      "Batch 282, Loss: 2.7642\n",
      "Batch 283, Loss: 2.7794\n",
      "Batch 284, Loss: 2.7577\n",
      "Batch 285, Loss: 2.7896\n",
      "Batch 286, Loss: 2.7503\n",
      "Batch 287, Loss: 2.7588\n",
      "Batch 288, Loss: 2.7722\n",
      "Batch 289, Loss: 2.7142\n",
      "Batch 290, Loss: 2.7082\n",
      "Batch 291, Loss: 2.7236\n",
      "Batch 292, Loss: 2.7153\n",
      "Batch 293, Loss: 2.7453\n",
      "Batch 294, Loss: 2.7093\n",
      "Batch 295, Loss: 2.7251\n",
      "Batch 296, Loss: 2.7247\n",
      "Batch 297, Loss: 2.6982\n",
      "Batch 298, Loss: 2.6911\n",
      "Batch 299, Loss: 2.6764\n",
      "Batch 300, Loss: 2.7035\n",
      "Batch 301, Loss: 2.6875\n",
      "Batch 302, Loss: 2.6756\n",
      "Batch 303, Loss: 2.6984\n",
      "Batch 304, Loss: 2.6873\n",
      "Batch 305, Loss: 2.6777\n",
      "Batch 306, Loss: 2.6809\n",
      "Batch 307, Loss: 2.6947\n",
      "Batch 308, Loss: 2.6663\n",
      "Batch 309, Loss: 2.6580\n",
      "Batch 310, Loss: 2.6759\n",
      "Batch 311, Loss: 2.6790\n",
      "Batch 312, Loss: 2.6671\n",
      "Batch 313, Loss: 2.6769\n",
      "Batch 314, Loss: 2.6325\n",
      "Batch 315, Loss: 2.6234\n",
      "Batch 316, Loss: 2.6706\n",
      "Batch 317, Loss: 2.6429\n",
      "Batch 318, Loss: 2.6185\n",
      "Batch 319, Loss: 2.6382\n",
      "Batch 320, Loss: 2.6197\n",
      "Batch 321, Loss: 2.6150\n",
      "Batch 322, Loss: 2.6281\n",
      "Batch 323, Loss: 2.6273\n",
      "Batch 324, Loss: 2.6173\n",
      "Batch 325, Loss: 2.6168\n",
      "Batch 326, Loss: 2.5889\n",
      "Batch 327, Loss: 2.6214\n",
      "Batch 328, Loss: 2.6034\n",
      "Batch 329, Loss: 2.6127\n",
      "Batch 330, Loss: 2.5988\n",
      "Batch 331, Loss: 2.6106\n",
      "Batch 332, Loss: 2.5722\n",
      "Batch 333, Loss: 2.5953\n",
      "Batch 334, Loss: 2.5860\n",
      "Batch 335, Loss: 2.5950\n",
      "Batch 336, Loss: 2.5681\n",
      "Batch 337, Loss: 2.5650\n",
      "Batch 338, Loss: 2.5693\n",
      "Batch 339, Loss: 2.5664\n",
      "Batch 340, Loss: 2.5409\n",
      "Batch 341, Loss: 2.5766\n",
      "Batch 342, Loss: 2.5673\n",
      "Batch 343, Loss: 2.5584\n",
      "Batch 344, Loss: 2.5473\n",
      "Batch 345, Loss: 2.5419\n",
      "Batch 346, Loss: 2.5569\n",
      "Batch 347, Loss: 2.5302\n",
      "Batch 348, Loss: 2.5210\n",
      "Batch 349, Loss: 2.5561\n",
      "Batch 350, Loss: 2.5180\n",
      "Batch 351, Loss: 2.5279\n",
      "Batch 352, Loss: 2.5237\n",
      "Batch 353, Loss: 2.4872\n",
      "Batch 354, Loss: 2.4844\n",
      "Batch 355, Loss: 2.5177\n",
      "Batch 356, Loss: 2.5087\n",
      "Batch 357, Loss: 2.5055\n",
      "Batch 358, Loss: 2.4806\n",
      "Batch 359, Loss: 2.5241\n",
      "Batch 360, Loss: 2.4865\n",
      "Batch 361, Loss: 2.5084\n",
      "Batch 362, Loss: 2.5030\n",
      "Batch 363, Loss: 2.4866\n",
      "Batch 364, Loss: 2.4696\n",
      "Batch 365, Loss: 2.4893\n",
      "Batch 366, Loss: 2.4780\n",
      "Batch 367, Loss: 2.4693\n",
      "Batch 368, Loss: 2.4736\n",
      "Batch 369, Loss: 2.4827\n",
      "Batch 370, Loss: 2.4745\n",
      "Batch 371, Loss: 2.4894\n",
      "Batch 372, Loss: 2.4927\n",
      "Batch 373, Loss: 2.4870\n",
      "Batch 374, Loss: 2.4706\n",
      "Batch 375, Loss: 2.4382\n",
      "Batch 376, Loss: 2.4417\n",
      "Batch 377, Loss: 2.4610\n",
      "Batch 378, Loss: 2.4821\n",
      "Batch 379, Loss: 2.4541\n",
      "Batch 380, Loss: 2.4379\n",
      "Batch 381, Loss: 2.4604\n",
      "Batch 382, Loss: 2.4549\n",
      "Batch 383, Loss: 2.4324\n",
      "Batch 384, Loss: 2.4433\n",
      "Batch 385, Loss: 2.4178\n",
      "Batch 386, Loss: 2.4341\n",
      "Batch 387, Loss: 2.4350\n",
      "Batch 388, Loss: 2.4118\n",
      "Batch 389, Loss: 2.4441\n",
      "Batch 390, Loss: 2.4102\n",
      "Batch 391, Loss: 2.4063\n",
      "Batch 392, Loss: 2.4389\n",
      "Batch 393, Loss: 2.4175\n",
      "Batch 394, Loss: 2.4363\n",
      "Batch 395, Loss: 2.3941\n",
      "Batch 396, Loss: 2.4421\n",
      "Batch 397, Loss: 2.3981\n",
      "Batch 398, Loss: 2.3730\n",
      "Batch 399, Loss: 2.3888\n",
      "Batch 400, Loss: 2.3935\n",
      "Batch 401, Loss: 2.3971\n",
      "Batch 402, Loss: 2.3777\n",
      "Batch 403, Loss: 2.3964\n",
      "Batch 404, Loss: 2.3768\n",
      "Batch 405, Loss: 2.3493\n",
      "Batch 406, Loss: 2.3742\n",
      "Batch 407, Loss: 2.3497\n",
      "Batch 408, Loss: 2.3739\n",
      "Batch 409, Loss: 2.3908\n",
      "Batch 410, Loss: 2.3799\n",
      "Batch 411, Loss: 2.3787\n",
      "Batch 412, Loss: 2.3502\n",
      "Batch 413, Loss: 2.3845\n",
      "Batch 414, Loss: 2.3629\n",
      "Batch 415, Loss: 2.3276\n",
      "Batch 416, Loss: 2.3349\n",
      "Batch 417, Loss: 2.3316\n",
      "Batch 418, Loss: 2.3696\n",
      "Batch 419, Loss: 2.3495\n",
      "Batch 420, Loss: 2.3456\n",
      "Batch 421, Loss: 2.3392\n",
      "Batch 422, Loss: 2.3247\n",
      "Batch 423, Loss: 2.3675\n",
      "Batch 424, Loss: 2.3081\n",
      "Batch 425, Loss: 2.3644\n",
      "Batch 426, Loss: 2.3246\n",
      "Batch 427, Loss: 2.3183\n",
      "Batch 428, Loss: 2.3512\n",
      "Batch 429, Loss: 2.3154\n",
      "Batch 430, Loss: 2.3305\n",
      "Batch 431, Loss: 2.3140\n",
      "Batch 432, Loss: 2.3124\n",
      "Batch 433, Loss: 2.3143\n",
      "Batch 434, Loss: 2.3300\n",
      "Batch 435, Loss: 2.3083\n",
      "Batch 436, Loss: 2.3218\n",
      "Batch 437, Loss: 2.3223\n",
      "Batch 438, Loss: 2.3081\n",
      "Batch 439, Loss: 2.3020\n",
      "Batch 440, Loss: 2.2888\n",
      "Batch 441, Loss: 2.2813\n",
      "Batch 442, Loss: 2.2723\n",
      "Batch 443, Loss: 2.2802\n",
      "Batch 444, Loss: 2.2971\n",
      "Batch 445, Loss: 2.3038\n",
      "Batch 446, Loss: 2.2708\n",
      "Batch 447, Loss: 2.2791\n",
      "Batch 448, Loss: 2.2782\n",
      "Batch 449, Loss: 2.2826\n",
      "Batch 450, Loss: 2.2828\n",
      "Batch 451, Loss: 2.2717\n",
      "Batch 452, Loss: 2.2669\n",
      "Batch 453, Loss: 2.2885\n",
      "Batch 454, Loss: 2.2738\n",
      "Batch 455, Loss: 2.2601\n",
      "Batch 456, Loss: 2.2700\n",
      "Batch 457, Loss: 2.2682\n",
      "Batch 458, Loss: 2.2602\n",
      "Batch 459, Loss: 2.2292\n",
      "Batch 460, Loss: 2.2538\n",
      "Batch 461, Loss: 2.2964\n",
      "Batch 462, Loss: 2.2614\n",
      "Batch 463, Loss: 2.2541\n",
      "Batch 464, Loss: 2.2328\n",
      "Batch 465, Loss: 2.2096\n",
      "Batch 466, Loss: 2.2300\n",
      "Batch 467, Loss: 2.1958\n",
      "Batch 468, Loss: 2.2682\n",
      "Batch 469, Loss: 2.2304\n",
      "Batch 470, Loss: 2.2383\n",
      "Batch 471, Loss: 2.2278\n",
      "Batch 472, Loss: 2.2445\n",
      "Batch 473, Loss: 2.2390\n",
      "Batch 474, Loss: 2.2320\n",
      "Batch 475, Loss: 2.2024\n",
      "Batch 476, Loss: 2.2692\n",
      "Batch 477, Loss: 2.2478\n",
      "Batch 478, Loss: 2.1855\n",
      "Batch 479, Loss: 2.2196\n",
      "Batch 480, Loss: 2.2445\n",
      "Batch 481, Loss: 2.2421\n",
      "Batch 482, Loss: 2.1949\n",
      "Batch 483, Loss: 2.2138\n",
      "John was a chilver sheepy. She lived in a smellytern dink in her favorite forest. Everyone was very careful. He used the floor, a little \n",
      "coines everyone to look ate ke- itâ€™s collect, but it wasn't emty. Johnâ€™ted to help. He ran outside to the park, but he had dancy \n",
      "things that he could not retculie it. John was still to dinn? Then John saw a big, sock on his wag was crying from his \n",
      "eylt. He was very upset. He picked them up the garden. His Do away and dinoin hopped but itles away. John was so happy to \n",
      "see what was inside. They used to be there hellollo. When it wants danked home, it was time to dink when they were as singing. \n",
      "\n",
      "--------------------\n",
      "Batch 484, Loss: 2.2520\n",
      "Batch 485, Loss: 2.1922\n",
      "Batch 486, Loss: 2.1879\n",
      "Batch 487, Loss: 2.2250\n",
      "Batch 488, Loss: 2.2083\n",
      "Batch 489, Loss: 2.2135\n",
      "Batch 490, Loss: 2.2077\n",
      "Batch 491, Loss: 2.1926\n",
      "Batch 492, Loss: 2.1909\n",
      "Batch 493, Loss: 2.1902\n",
      "Batch 494, Loss: 2.1835\n",
      "Batch 495, Loss: 2.1944\n",
      "Batch 496, Loss: 2.1994\n",
      "Batch 497, Loss: 2.1629\n",
      "Batch 498, Loss: 2.1831\n",
      "Batch 499, Loss: 2.2019\n",
      "Batch 500, Loss: 2.1888\n",
      "Batch 501, Loss: 2.1600\n",
      "Batch 502, Loss: 2.1783\n",
      "Batch 503, Loss: 2.1420\n",
      "Batch 504, Loss: 2.1564\n",
      "Batch 505, Loss: 2.1169\n",
      "Batch 506, Loss: 2.1414\n",
      "Batch 507, Loss: 2.1422\n",
      "Batch 508, Loss: 2.1685\n",
      "Batch 509, Loss: 2.1740\n",
      "Batch 510, Loss: 2.1552\n",
      "Batch 511, Loss: 2.1636\n",
      "Batch 512, Loss: 2.1495\n",
      "Batch 513, Loss: 2.1332\n",
      "Batch 514, Loss: 2.1412\n",
      "Batch 515, Loss: 2.1642\n",
      "Batch 516, Loss: 2.1179\n",
      "Batch 517, Loss: 2.1328\n",
      "Batch 518, Loss: 2.1300\n",
      "Batch 519, Loss: 2.1072\n",
      "Batch 520, Loss: 2.1307\n",
      "Batch 521, Loss: 2.1614\n",
      "Batch 522, Loss: 2.1461\n",
      "Batch 523, Loss: 2.1489\n",
      "Batch 524, Loss: 2.1781\n",
      "Batch 525, Loss: 2.1111\n",
      "Batch 526, Loss: 2.1438\n",
      "Batch 527, Loss: 2.1318\n",
      "Batch 528, Loss: 2.1352\n",
      "Batch 529, Loss: 2.1639\n",
      "Batch 530, Loss: 2.1295\n",
      "Batch 531, Loss: 2.1402\n",
      "Batch 532, Loss: 2.1437\n",
      "Batch 533, Loss: 2.1447\n",
      "Batch 534, Loss: 2.1079\n",
      "Batch 535, Loss: 2.1388\n",
      "Batch 536, Loss: 2.0995\n",
      "Batch 537, Loss: 2.1024\n",
      "Batch 538, Loss: 2.1413\n",
      "Batch 539, Loss: 2.1110\n",
      "Batch 540, Loss: 2.1440\n",
      "Batch 541, Loss: 2.0823\n",
      "Batch 542, Loss: 2.0593\n",
      "Batch 543, Loss: 2.0965\n",
      "Batch 544, Loss: 2.0987\n",
      "Batch 545, Loss: 2.0977\n",
      "Batch 546, Loss: 2.1131\n",
      "Batch 547, Loss: 2.0918\n",
      "Batch 548, Loss: 2.1024\n",
      "Batch 549, Loss: 2.0996\n",
      "Batch 550, Loss: 2.1003\n",
      "Batch 551, Loss: 2.0965\n",
      "Batch 552, Loss: 2.0848\n",
      "Batch 553, Loss: 2.0912\n",
      "Batch 554, Loss: 2.0964\n",
      "Batch 555, Loss: 2.0796\n",
      "Batch 556, Loss: 2.1042\n",
      "Batch 557, Loss: 2.0873\n",
      "Batch 558, Loss: 2.1001\n",
      "Batch 559, Loss: 2.0757\n",
      "Batch 560, Loss: 2.1112\n",
      "Batch 561, Loss: 2.0793\n",
      "Batch 562, Loss: 2.1111\n",
      "Batch 563, Loss: 2.1147\n",
      "Batch 564, Loss: 2.1121\n",
      "Batch 565, Loss: 2.0600\n",
      "Batch 566, Loss: 2.0517\n",
      "Batch 567, Loss: 2.0640\n",
      "Batch 568, Loss: 2.0820\n",
      "Batch 569, Loss: 2.0852\n",
      "Batch 570, Loss: 2.1173\n",
      "Batch 571, Loss: 2.0928\n",
      "Batch 572, Loss: 2.0454\n",
      "Batch 573, Loss: 2.0788\n",
      "Batch 574, Loss: 2.0441\n",
      "Batch 575, Loss: 2.0804\n",
      "Batch 576, Loss: 2.0504\n",
      "Batch 577, Loss: 2.0805\n",
      "Batch 578, Loss: 2.0413\n",
      "Batch 579, Loss: 2.0671\n",
      "Batch 580, Loss: 2.0653\n",
      "Batch 581, Loss: 2.0444\n",
      "Batch 582, Loss: 2.0999\n",
      "Batch 583, Loss: 2.0818\n",
      "Batch 584, Loss: 2.0718\n",
      "Batch 585, Loss: 2.0543\n",
      "Batch 586, Loss: 2.0409\n",
      "Batch 587, Loss: 2.0283\n",
      "Batch 588, Loss: 2.0567\n",
      "Batch 589, Loss: 2.0775\n",
      "Batch 590, Loss: 2.0398\n",
      "Batch 591, Loss: 2.0319\n",
      "Batch 592, Loss: 2.0645\n",
      "Batch 593, Loss: 2.0411\n",
      "Batch 594, Loss: 2.0637\n",
      "Batch 595, Loss: 2.0352\n",
      "Batch 596, Loss: 2.0497\n",
      "Batch 597, Loss: 2.0858\n",
      "Batch 598, Loss: 2.0593\n",
      "Batch 599, Loss: 2.0376\n",
      "Batch 600, Loss: 2.0682\n",
      "Batch 601, Loss: 2.0238\n",
      "Batch 602, Loss: 2.0436\n",
      "Batch 603, Loss: 2.0322\n",
      "Batch 604, Loss: 2.0313\n",
      "Batch 605, Loss: 2.0409\n",
      "Batch 606, Loss: 2.0372\n",
      "Batch 607, Loss: 2.0259\n",
      "Batch 608, Loss: 2.0654\n",
      "Batch 609, Loss: 2.0343\n",
      "Batch 610, Loss: 2.0273\n",
      "Batch 611, Loss: 2.0204\n",
      "Batch 612, Loss: 2.0316\n",
      "Batch 613, Loss: 2.0322\n",
      "Batch 614, Loss: 2.0219\n",
      "Batch 615, Loss: 2.0489\n",
      "Batch 616, Loss: 2.0261\n",
      "Batch 617, Loss: 2.0110\n",
      "Batch 618, Loss: 2.0511\n",
      "Batch 619, Loss: 2.0155\n",
      "Batch 620, Loss: 1.9999\n",
      "Batch 621, Loss: 2.0226\n",
      "Batch 622, Loss: 2.0232\n",
      "Batch 623, Loss: 2.0149\n",
      "Batch 624, Loss: 2.0216\n",
      "Batch 625, Loss: 2.0220\n",
      "Batch 626, Loss: 2.0316\n",
      "Batch 627, Loss: 2.0018\n",
      "Batch 628, Loss: 2.0033\n",
      "Batch 629, Loss: 2.0100\n",
      "Batch 630, Loss: 2.0119\n",
      "Batch 631, Loss: 2.0047\n",
      "Batch 632, Loss: 2.0317\n",
      "Batch 633, Loss: 2.0319\n",
      "Batch 634, Loss: 2.0437\n",
      "Batch 635, Loss: 2.0252\n",
      "Batch 636, Loss: 2.0013\n",
      "Batch 637, Loss: 2.0165\n",
      "Batch 638, Loss: 1.9911\n",
      "Batch 639, Loss: 2.0090\n",
      "Batch 640, Loss: 2.0016\n",
      "Batch 641, Loss: 1.9823\n",
      "Batch 642, Loss: 2.0321\n",
      "Batch 643, Loss: 2.0095\n",
      "Batch 644, Loss: 1.9887\n",
      "Batch 645, Loss: 1.9984\n",
      "Batch 646, Loss: 1.9899\n",
      "Batch 647, Loss: 2.0103\n",
      "Batch 648, Loss: 1.9774\n",
      "Batch 649, Loss: 1.9808\n",
      "Batch 650, Loss: 2.0174\n",
      "Batch 651, Loss: 1.9808\n",
      "Batch 652, Loss: 1.9843\n",
      "Batch 653, Loss: 1.9734\n",
      "Batch 654, Loss: 1.9748\n",
      "Batch 655, Loss: 2.0033\n",
      "Batch 656, Loss: 1.9667\n",
      "Batch 657, Loss: 2.0366\n",
      "Batch 658, Loss: 1.9856\n",
      "Batch 659, Loss: 1.9701\n",
      "Batch 660, Loss: 1.9872\n",
      "Batch 661, Loss: 1.9761\n",
      "Batch 662, Loss: 1.9466\n",
      "Batch 663, Loss: 1.9656\n",
      "Batch 664, Loss: 1.9759\n",
      "Batch 665, Loss: 1.9591\n",
      "Batch 666, Loss: 2.0016\n",
      "Batch 667, Loss: 2.0011\n",
      "Batch 668, Loss: 1.9631\n",
      "Batch 669, Loss: 1.9771\n",
      "Batch 670, Loss: 1.9672\n",
      "Batch 671, Loss: 1.9858\n",
      "Batch 672, Loss: 1.9527\n",
      "Batch 673, Loss: 1.9568\n",
      "Batch 674, Loss: 1.9360\n",
      "Batch 675, Loss: 1.9701\n",
      "Batch 676, Loss: 1.9613\n",
      "Batch 677, Loss: 1.9711\n",
      "Batch 678, Loss: 1.9735\n",
      "Batch 679, Loss: 1.9467\n",
      "Batch 680, Loss: 1.9810\n",
      "Batch 681, Loss: 1.9606\n",
      "Batch 682, Loss: 1.9710\n",
      "Batch 683, Loss: 1.9560\n",
      "Batch 684, Loss: 1.9292\n",
      "Batch 685, Loss: 1.9943\n",
      "Batch 686, Loss: 1.9678\n",
      "Batch 687, Loss: 1.9501\n",
      "Batch 688, Loss: 1.9228\n",
      "Batch 689, Loss: 1.9820\n",
      "Batch 690, Loss: 1.9656\n",
      "Batch 691, Loss: 1.9538\n",
      "Batch 692, Loss: 1.9503\n",
      "Batch 693, Loss: 1.9737\n",
      "Batch 694, Loss: 1.9632\n",
      "Batch 695, Loss: 1.9370\n",
      "Batch 696, Loss: 1.9791\n",
      "Batch 697, Loss: 1.9519\n",
      "Batch 698, Loss: 1.9377\n",
      "Batch 699, Loss: 1.9581\n",
      "Batch 700, Loss: 1.9088\n",
      "Batch 701, Loss: 1.9643\n",
      "Batch 702, Loss: 1.9495\n",
      "Batch 703, Loss: 1.9595\n",
      "Batch 704, Loss: 1.9345\n",
      "Batch 705, Loss: 1.9118\n",
      "Batch 706, Loss: 1.9372\n",
      "Batch 707, Loss: 1.9573\n",
      "Batch 708, Loss: 1.9383\n",
      "Batch 709, Loss: 1.9538\n",
      "Batch 710, Loss: 1.9749\n",
      "Batch 711, Loss: 1.9180\n",
      "Batch 712, Loss: 1.9425\n",
      "Batch 713, Loss: 1.9515\n",
      "Batch 714, Loss: 1.9424\n",
      "Batch 715, Loss: 1.9359\n",
      "Batch 716, Loss: 1.9167\n",
      "Batch 717, Loss: 1.9339\n",
      "Batch 718, Loss: 1.9520\n",
      "Batch 719, Loss: 1.9516\n",
      "Batch 720, Loss: 1.9570\n",
      "Batch 721, Loss: 1.9412\n",
      "Batch 722, Loss: 1.9069\n",
      "Batch 723, Loss: 1.9320\n",
      "Batch 724, Loss: 1.9476\n",
      "Batch 725, Loss: 1.9288\n",
      "Batch 726, Loss: 1.9206\n",
      "Batch 727, Loss: 1.9309\n",
      "Batch 728, Loss: 1.9150\n",
      "Batch 729, Loss: 1.9328\n",
      "Batch 730, Loss: 1.9314\n",
      "Batch 731, Loss: 1.9366\n",
      "Batch 732, Loss: 1.9231\n",
      "Batch 733, Loss: 1.9046\n",
      "Batch 734, Loss: 1.9208\n",
      "Batch 735, Loss: 1.9246\n",
      "Batch 736, Loss: 1.9133\n",
      "Batch 737, Loss: 1.9139\n",
      "Batch 738, Loss: 1.9084\n",
      "Batch 739, Loss: 1.9217\n",
      "Batch 740, Loss: 1.9248\n",
      "Batch 741, Loss: 1.9125\n",
      "Batch 742, Loss: 1.9246\n",
      "Batch 743, Loss: 1.9207\n",
      "Batch 744, Loss: 1.9372\n",
      "Batch 745, Loss: 1.9170\n",
      "Batch 746, Loss: 1.9284\n",
      "Batch 747, Loss: 1.9238\n",
      "Batch 748, Loss: 1.9257\n",
      "Batch 749, Loss: 1.9065\n",
      "Batch 750, Loss: 1.9021\n",
      "Batch 751, Loss: 1.9210\n",
      "Batch 752, Loss: 1.9170\n",
      "Batch 753, Loss: 1.8900\n",
      "Batch 754, Loss: 1.9117\n",
      "Batch 755, Loss: 1.9050\n",
      "Batch 756, Loss: 1.9190\n",
      "Batch 757, Loss: 1.9221\n",
      "Batch 758, Loss: 1.9140\n",
      "Batch 759, Loss: 1.9127\n",
      "Batch 760, Loss: 1.8917\n",
      "Batch 761, Loss: 1.9115\n",
      "Batch 762, Loss: 1.9164\n",
      "Batch 763, Loss: 1.8959\n",
      "Batch 764, Loss: 1.8783\n",
      "Batch 765, Loss: 1.9083\n",
      "Batch 766, Loss: 1.9070\n",
      "Batch 767, Loss: 1.9223\n",
      "Batch 768, Loss: 1.9107\n",
      "Batch 769, Loss: 1.9049\n",
      "Batch 770, Loss: 1.8646\n",
      "Batch 771, Loss: 1.9006\n",
      "Batch 772, Loss: 1.9203\n",
      "Batch 773, Loss: 1.9051\n",
      "Batch 774, Loss: 1.8908\n",
      "Batch 775, Loss: 1.8652\n",
      "Batch 776, Loss: 1.9169\n",
      "Batch 777, Loss: 1.8864\n",
      "Batch 778, Loss: 1.9180\n",
      "Batch 779, Loss: 1.9241\n",
      "Batch 780, Loss: 1.9230\n",
      "Batch 781, Loss: 1.8911\n",
      "Batch 782, Loss: 1.9136\n",
      "Batch 783, Loss: 1.9191\n",
      "Batch 784, Loss: 1.8653\n",
      "Batch 785, Loss: 1.9072\n",
      "Batch 786, Loss: 1.9081\n",
      "Batch 787, Loss: 1.9114\n",
      "Batch 788, Loss: 1.8728\n",
      "Batch 789, Loss: 1.8726\n",
      "Batch 790, Loss: 1.8825\n",
      "Batch 791, Loss: 1.8472\n",
      "Batch 792, Loss: 1.9310\n",
      "Batch 793, Loss: 1.8693\n",
      "Batch 794, Loss: 1.8687\n",
      "Batch 795, Loss: 1.8687\n",
      "Batch 796, Loss: 1.8864\n",
      "Batch 797, Loss: 1.8956\n",
      "Batch 798, Loss: 1.9003\n",
      "Batch 799, Loss: 1.8779\n",
      "Batch 800, Loss: 1.8773\n",
      "Batch 801, Loss: 1.9066\n",
      "Batch 802, Loss: 1.8833\n",
      "Batch 803, Loss: 1.9246\n",
      "Batch 804, Loss: 1.8985\n",
      "Batch 805, Loss: 1.8861\n",
      "Batch 806, Loss: 1.8777\n",
      "Batch 807, Loss: 1.8622\n",
      "Batch 808, Loss: 1.8824\n",
      "Batch 809, Loss: 1.8824\n",
      "Batch 810, Loss: 1.8996\n",
      "Batch 811, Loss: 1.8691\n",
      "Batch 812, Loss: 1.8977\n",
      "Batch 813, Loss: 1.8753\n",
      "Batch 814, Loss: 1.8873\n",
      "Batch 815, Loss: 1.8695\n",
      "Batch 816, Loss: 1.9096\n",
      "Batch 817, Loss: 1.8963\n",
      "Batch 818, Loss: 1.8753\n",
      "Batch 819, Loss: 1.9015\n",
      "Batch 820, Loss: 1.8366\n",
      "Batch 821, Loss: 1.8605\n",
      "Batch 822, Loss: 1.9084\n",
      "Batch 823, Loss: 1.8849\n",
      "Batch 824, Loss: 1.9114\n",
      "Batch 825, Loss: 1.8861\n",
      "Batch 826, Loss: 1.8750\n",
      "Batch 827, Loss: 1.8671\n",
      "Batch 828, Loss: 1.8681\n",
      "Batch 829, Loss: 1.8907\n",
      "Batch 830, Loss: 1.8465\n",
      "Batch 831, Loss: 1.8668\n",
      "Batch 832, Loss: 1.8891\n",
      "Batch 833, Loss: 1.8637\n",
      "Batch 834, Loss: 1.8622\n",
      "Batch 835, Loss: 1.8774\n",
      "Batch 836, Loss: 1.8856\n",
      "Batch 837, Loss: 1.8471\n",
      "Batch 838, Loss: 1.8695\n",
      "Batch 839, Loss: 1.8585\n",
      "Batch 840, Loss: 1.8587\n",
      "Batch 841, Loss: 1.8922\n",
      "Batch 842, Loss: 1.8434\n",
      "Batch 843, Loss: 1.8759\n",
      "Batch 844, Loss: 1.8550\n",
      "Batch 845, Loss: 1.8952\n",
      "Batch 846, Loss: 1.8716\n",
      "Batch 847, Loss: 1.8560\n",
      "Batch 848, Loss: 1.8304\n",
      "Batch 849, Loss: 1.8638\n",
      "Batch 850, Loss: 1.8652\n",
      "Batch 851, Loss: 1.8825\n",
      "Batch 852, Loss: 1.8577\n",
      "Batch 853, Loss: 1.8674\n",
      "Batch 854, Loss: 1.8337\n",
      "Batch 855, Loss: 1.8644\n",
      "Batch 856, Loss: 1.8377\n",
      "Batch 857, Loss: 1.8348\n",
      "Batch 858, Loss: 1.8322\n",
      "Batch 859, Loss: 1.8442\n",
      "Batch 860, Loss: 1.8612\n",
      "Batch 861, Loss: 1.8745\n",
      "Batch 862, Loss: 1.8539\n",
      "Batch 863, Loss: 1.8528\n",
      "Batch 864, Loss: 1.8075\n",
      "Batch 865, Loss: 1.8427\n",
      "Batch 866, Loss: 1.8758\n",
      "Batch 867, Loss: 1.8227\n",
      "Batch 868, Loss: 1.8637\n",
      "Batch 869, Loss: 1.8668\n",
      "Batch 870, Loss: 1.8583\n",
      "Batch 871, Loss: 1.8124\n",
      "Batch 872, Loss: 1.8654\n",
      "Batch 873, Loss: 1.8432\n",
      "Batch 874, Loss: 1.8519\n",
      "Batch 875, Loss: 1.8748\n",
      "Batch 876, Loss: 1.8512\n",
      "Batch 877, Loss: 1.8361\n",
      "Batch 878, Loss: 1.8614\n",
      "Batch 879, Loss: 1.8621\n",
      "Batch 880, Loss: 1.8489\n",
      "Batch 881, Loss: 1.8266\n",
      "Batch 882, Loss: 1.8381\n",
      "Batch 883, Loss: 1.8338\n",
      "Batch 884, Loss: 1.8250\n",
      "Batch 885, Loss: 1.8751\n",
      "Batch 886, Loss: 1.8235\n",
      "Batch 887, Loss: 1.8585\n",
      "Batch 888, Loss: 1.8390\n",
      "Batch 889, Loss: 1.8267\n",
      "Batch 890, Loss: 1.8133\n",
      "Batch 891, Loss: 1.8306\n",
      "Batch 892, Loss: 1.8253\n",
      "Batch 893, Loss: 1.8420\n",
      "Batch 894, Loss: 1.8358\n",
      "Batch 895, Loss: 1.8197\n",
      "Batch 896, Loss: 1.8495\n",
      "Batch 897, Loss: 1.8202\n",
      "Batch 898, Loss: 1.8454\n",
      "Batch 899, Loss: 1.8541\n",
      "Batch 900, Loss: 1.8320\n",
      "Batch 901, Loss: 1.8266\n",
      "Batch 902, Loss: 1.8351\n",
      "Batch 903, Loss: 1.8352\n",
      "Batch 904, Loss: 1.8246\n",
      "Batch 905, Loss: 1.8284\n",
      "Batch 906, Loss: 1.8121\n",
      "Batch 907, Loss: 1.8237\n",
      "Batch 908, Loss: 1.8277\n",
      "Batch 909, Loss: 1.8262\n",
      "Batch 910, Loss: 1.8416\n",
      "Batch 911, Loss: 1.8062\n",
      "Batch 912, Loss: 1.8411\n",
      "Batch 913, Loss: 1.8223\n",
      "Batch 914, Loss: 1.8384\n",
      "Batch 915, Loss: 1.8282\n",
      "Batch 916, Loss: 1.8441\n",
      "Batch 917, Loss: 1.7918\n",
      "Batch 918, Loss: 1.8474\n",
      "Batch 919, Loss: 1.8409\n",
      "Batch 920, Loss: 1.7971\n",
      "Batch 921, Loss: 1.8445\n",
      "Batch 922, Loss: 1.8276\n",
      "Batch 923, Loss: 1.8542\n",
      "Batch 924, Loss: 1.8521\n",
      "Batch 925, Loss: 1.8225\n",
      "Batch 926, Loss: 1.8199\n",
      "Batch 927, Loss: 1.8393\n",
      "Batch 928, Loss: 1.8020\n",
      "Batch 929, Loss: 1.8373\n",
      "Batch 930, Loss: 1.8408\n",
      "Batch 931, Loss: 1.8147\n",
      "Batch 932, Loss: 1.7926\n",
      "Batch 933, Loss: 1.8289\n",
      "Batch 934, Loss: 1.8427\n",
      "Batch 935, Loss: 1.8338\n",
      "Batch 936, Loss: 1.8098\n",
      "Batch 937, Loss: 1.8232\n",
      "Batch 938, Loss: 1.8131\n",
      "Batch 939, Loss: 1.7861\n",
      "Batch 940, Loss: 1.8607\n",
      "Batch 941, Loss: 1.8211\n",
      "Batch 942, Loss: 1.8143\n",
      "Batch 943, Loss: 1.8284\n",
      "Batch 944, Loss: 1.8241\n",
      "Batch 945, Loss: 1.8016\n",
      "Batch 946, Loss: 1.8050\n",
      "Batch 947, Loss: 1.8065\n",
      "Batch 948, Loss: 1.8176\n",
      "Batch 949, Loss: 1.8472\n",
      "Batch 950, Loss: 1.8321\n",
      "Batch 951, Loss: 1.7818\n",
      "Batch 952, Loss: 1.7899\n",
      "Batch 953, Loss: 1.8056\n",
      "Batch 954, Loss: 1.7936\n",
      "Batch 955, Loss: 1.8216\n",
      "Batch 956, Loss: 1.8022\n",
      "Batch 957, Loss: 1.7870\n",
      "Batch 958, Loss: 1.8229\n",
      "Batch 959, Loss: 1.8182\n",
      "Batch 960, Loss: 1.8284\n",
      "Batch 961, Loss: 1.8213\n",
      "Batch 962, Loss: 1.8176\n",
      "Batch 963, Loss: 1.7962\n",
      "Batch 964, Loss: 1.8736\n",
      "Batch 965, Loss: 1.8036\n",
      "Epoch 1, Average Loss: 2.4641\n",
      "Once upon a time, there was a little girl named Sally. Sally liked to play in the sea off sugarboard. One day, she saw something \n",
      "that made her dress After and her happy. This suggest popping thing in the sea! So, she dresediboard and carefully decided to hop out. As \n",
      "the sky heard a butterfly, she reached out of the hand. It was big, mouse shaking and Instead After she reached inside the park. She \n",
      "found her dress all over the garden one makes, and faster! At the man saw the monkey into many dreses. He wanted to play with \n",
      "him too, so she pouredaled they move inside with it. His dad was very proud of her and nothing was gone. They both laughed and \n",
      "said, \"Hey, you do it again. You've want them to be gone first, just like hope. At the end of the day of the day, \n",
      "Sally's dressiment. Today with her dresed dress and And she liried to play withiss, but she would always be stisten. \n",
      "\n",
      "--------------------\n",
      "Batch 0, Loss: 1.8003\n",
      "Batch 1, Loss: 1.8382\n",
      "Batch 2, Loss: 1.8165\n",
      "Batch 3, Loss: 1.8132\n",
      "Batch 4, Loss: 1.8001\n",
      "Batch 5, Loss: 1.7889\n",
      "Batch 6, Loss: 1.8357\n",
      "Batch 7, Loss: 1.8237\n",
      "Batch 8, Loss: 1.7987\n",
      "Batch 9, Loss: 1.8255\n",
      "Batch 10, Loss: 1.8150\n",
      "Batch 11, Loss: 1.8110\n",
      "Batch 12, Loss: 1.7806\n",
      "Batch 13, Loss: 1.7964\n",
      "Batch 14, Loss: 1.7975\n",
      "Batch 15, Loss: 1.8054\n",
      "Batch 16, Loss: 1.8233\n",
      "Batch 17, Loss: 1.7983\n",
      "Batch 18, Loss: 1.8248\n",
      "Batch 19, Loss: 1.8115\n",
      "Batch 20, Loss: 1.8014\n",
      "Batch 21, Loss: 1.8408\n",
      "Batch 22, Loss: 1.7530\n",
      "Batch 23, Loss: 1.7866\n",
      "Batch 24, Loss: 1.8082\n",
      "Batch 25, Loss: 1.7995\n",
      "Batch 26, Loss: 1.7786\n",
      "Batch 27, Loss: 1.7932\n",
      "Batch 28, Loss: 1.7797\n",
      "Batch 29, Loss: 1.7858\n",
      "Batch 30, Loss: 1.7895\n",
      "Batch 31, Loss: 1.7831\n",
      "Batch 32, Loss: 1.7574\n",
      "Batch 33, Loss: 1.7557\n",
      "Batch 34, Loss: 1.7945\n",
      "Batch 35, Loss: 1.8005\n",
      "Batch 36, Loss: 1.7826\n",
      "Batch 37, Loss: 1.7900\n",
      "Batch 38, Loss: 1.7811\n",
      "Batch 39, Loss: 1.7826\n",
      "Batch 40, Loss: 1.7995\n",
      "Batch 41, Loss: 1.7822\n",
      "Batch 42, Loss: 1.8259\n",
      "Batch 43, Loss: 1.7724\n",
      "Batch 44, Loss: 1.8068\n",
      "Batch 45, Loss: 1.8492\n",
      "Batch 46, Loss: 1.7857\n",
      "Batch 47, Loss: 1.8053\n",
      "Batch 48, Loss: 1.7683\n",
      "Batch 49, Loss: 1.7844\n",
      "Batch 50, Loss: 1.8057\n",
      "Batch 51, Loss: 1.8171\n",
      "Batch 52, Loss: 1.7698\n",
      "Batch 53, Loss: 1.7852\n",
      "Batch 54, Loss: 1.7773\n",
      "Batch 55, Loss: 1.7918\n",
      "Batch 56, Loss: 1.7808\n",
      "Batch 57, Loss: 1.7971\n",
      "Batch 58, Loss: 1.7810\n",
      "Batch 59, Loss: 1.7923\n",
      "Batch 60, Loss: 1.7680\n",
      "Batch 61, Loss: 1.7880\n",
      "Batch 62, Loss: 1.7637\n",
      "Batch 63, Loss: 1.7715\n",
      "Batch 64, Loss: 1.8028\n",
      "Batch 65, Loss: 1.7702\n",
      "Batch 66, Loss: 1.7790\n",
      "Batch 67, Loss: 1.7799\n",
      "Batch 68, Loss: 1.8207\n",
      "Batch 69, Loss: 1.7635\n",
      "Batch 70, Loss: 1.7748\n",
      "Batch 71, Loss: 1.7784\n",
      "Batch 72, Loss: 1.7739\n",
      "Batch 73, Loss: 1.7594\n",
      "Batch 74, Loss: 1.7732\n",
      "Batch 75, Loss: 1.7856\n",
      "Batch 76, Loss: 1.7739\n",
      "Batch 77, Loss: 1.7704\n",
      "Batch 78, Loss: 1.7853\n",
      "Batch 79, Loss: 1.7892\n",
      "Batch 80, Loss: 1.7755\n",
      "Batch 81, Loss: 1.7820\n",
      "Batch 82, Loss: 1.8165\n",
      "Batch 83, Loss: 1.7658\n",
      "Batch 84, Loss: 1.7759\n",
      "Batch 85, Loss: 1.8156\n",
      "Batch 86, Loss: 1.7860\n",
      "Batch 87, Loss: 1.7716\n",
      "Batch 88, Loss: 1.7903\n",
      "Batch 89, Loss: 1.7776\n",
      "Batch 90, Loss: 1.7688\n",
      "Batch 91, Loss: 1.7977\n",
      "Batch 92, Loss: 1.7740\n",
      "Batch 93, Loss: 1.7783\n",
      "Batch 94, Loss: 1.7645\n",
      "Batch 95, Loss: 1.7896\n",
      "Batch 96, Loss: 1.7770\n",
      "Batch 97, Loss: 1.7697\n",
      "Batch 98, Loss: 1.8066\n",
      "Batch 99, Loss: 1.7706\n",
      "Batch 100, Loss: 1.7630\n",
      "Batch 101, Loss: 1.7740\n",
      "Batch 102, Loss: 1.7555\n",
      "Batch 103, Loss: 1.7623\n",
      "Batch 104, Loss: 1.7566\n",
      "Batch 105, Loss: 1.7798\n",
      "Batch 106, Loss: 1.7709\n",
      "Batch 107, Loss: 1.7540\n",
      "Batch 108, Loss: 1.7785\n",
      "Batch 109, Loss: 1.7800\n",
      "Batch 110, Loss: 1.7577\n",
      "Batch 111, Loss: 1.7745\n",
      "Batch 112, Loss: 1.7664\n",
      "Batch 113, Loss: 1.7708\n",
      "Batch 114, Loss: 1.7745\n",
      "Batch 115, Loss: 1.7902\n",
      "Batch 116, Loss: 1.7729\n",
      "Batch 117, Loss: 1.7755\n",
      "Batch 118, Loss: 1.7637\n",
      "Batch 119, Loss: 1.7899\n",
      "Batch 120, Loss: 1.7755\n",
      "Batch 121, Loss: 1.7696\n",
      "Batch 122, Loss: 1.7570\n",
      "Batch 123, Loss: 1.7578\n",
      "Batch 124, Loss: 1.7658\n",
      "Batch 125, Loss: 1.7532\n",
      "Batch 126, Loss: 1.7652\n",
      "Batch 127, Loss: 1.7719\n",
      "Batch 128, Loss: 1.7840\n",
      "Batch 129, Loss: 1.7641\n",
      "Batch 130, Loss: 1.7820\n",
      "Batch 131, Loss: 1.7605\n",
      "Batch 132, Loss: 1.7683\n",
      "Batch 133, Loss: 1.7405\n",
      "Batch 134, Loss: 1.7508\n",
      "Batch 135, Loss: 1.7708\n",
      "Batch 136, Loss: 1.7810\n",
      "Batch 137, Loss: 1.7492\n",
      "Batch 138, Loss: 1.7669\n",
      "Batch 139, Loss: 1.7519\n",
      "Batch 140, Loss: 1.7424\n",
      "Batch 141, Loss: 1.7598\n",
      "Batch 142, Loss: 1.7538\n",
      "Batch 143, Loss: 1.7753\n",
      "Batch 144, Loss: 1.7775\n",
      "Batch 145, Loss: 1.7698\n",
      "Batch 146, Loss: 1.7578\n",
      "Batch 147, Loss: 1.7531\n",
      "Batch 148, Loss: 1.7596\n",
      "Batch 149, Loss: 1.7617\n",
      "Batch 150, Loss: 1.7538\n",
      "Batch 151, Loss: 1.7792\n",
      "Batch 152, Loss: 1.7698\n",
      "Batch 153, Loss: 1.7700\n",
      "Batch 154, Loss: 1.7475\n",
      "Batch 155, Loss: 1.7513\n",
      "Batch 156, Loss: 1.7602\n",
      "Batch 157, Loss: 1.7586\n",
      "Batch 158, Loss: 1.7677\n",
      "Batch 159, Loss: 1.7419\n",
      "Batch 160, Loss: 1.7629\n",
      "Batch 161, Loss: 1.7213\n",
      "Batch 162, Loss: 1.7711\n",
      "Batch 163, Loss: 1.7710\n",
      "Batch 164, Loss: 1.7562\n",
      "Batch 165, Loss: 1.7346\n",
      "Batch 166, Loss: 1.7471\n",
      "Batch 167, Loss: 1.7597\n",
      "Batch 168, Loss: 1.7615\n",
      "Batch 169, Loss: 1.7552\n",
      "Batch 170, Loss: 1.7503\n",
      "Batch 171, Loss: 1.7758\n",
      "Batch 172, Loss: 1.7629\n",
      "Batch 173, Loss: 1.7872\n",
      "Batch 174, Loss: 1.7083\n",
      "Batch 175, Loss: 1.7549\n",
      "Batch 176, Loss: 1.7454\n",
      "Batch 177, Loss: 1.7747\n",
      "Batch 178, Loss: 1.7486\n",
      "Batch 179, Loss: 1.7772\n",
      "Batch 180, Loss: 1.7449\n",
      "Batch 181, Loss: 1.7782\n",
      "Batch 182, Loss: 1.7273\n",
      "Batch 183, Loss: 1.7342\n",
      "Batch 184, Loss: 1.7457\n",
      "Batch 185, Loss: 1.7337\n",
      "Batch 186, Loss: 1.7474\n",
      "Batch 187, Loss: 1.7334\n",
      "Batch 188, Loss: 1.7596\n",
      "Batch 189, Loss: 1.7514\n",
      "Batch 190, Loss: 1.7612\n",
      "Batch 191, Loss: 1.7378\n",
      "Batch 192, Loss: 1.7527\n",
      "Batch 193, Loss: 1.7450\n",
      "Batch 194, Loss: 1.7753\n",
      "Batch 195, Loss: 1.7457\n",
      "Batch 196, Loss: 1.7263\n",
      "Batch 197, Loss: 1.7565\n",
      "Batch 198, Loss: 1.7228\n",
      "Batch 199, Loss: 1.7514\n",
      "Batch 200, Loss: 1.7637\n",
      "Batch 201, Loss: 1.7436\n",
      "Batch 202, Loss: 1.7388\n",
      "Batch 203, Loss: 1.7382\n",
      "Batch 204, Loss: 1.7434\n",
      "Batch 205, Loss: 1.7172\n",
      "Batch 206, Loss: 1.7535\n",
      "Batch 207, Loss: 1.7878\n",
      "Batch 208, Loss: 1.7387\n",
      "Batch 209, Loss: 1.7389\n",
      "Batch 210, Loss: 1.7690\n",
      "Batch 211, Loss: 1.7280\n",
      "Batch 212, Loss: 1.7342\n",
      "Batch 213, Loss: 1.7631\n",
      "Batch 214, Loss: 1.7067\n",
      "Batch 215, Loss: 1.7453\n",
      "Batch 216, Loss: 1.7350\n",
      "Batch 217, Loss: 1.7357\n",
      "Batch 218, Loss: 1.7162\n",
      "Batch 219, Loss: 1.7498\n",
      "Batch 220, Loss: 1.7443\n",
      "Batch 221, Loss: 1.7375\n",
      "Batch 222, Loss: 1.7479\n",
      "Batch 223, Loss: 1.7290\n",
      "Batch 224, Loss: 1.7356\n",
      "Batch 225, Loss: 1.7254\n",
      "Batch 226, Loss: 1.7499\n",
      "Batch 227, Loss: 1.7084\n",
      "Batch 228, Loss: 1.7672\n",
      "Batch 229, Loss: 1.7231\n",
      "Batch 230, Loss: 1.7420\n",
      "Batch 231, Loss: 1.7943\n",
      "Batch 232, Loss: 1.7349\n",
      "Batch 233, Loss: 1.7496\n",
      "Batch 234, Loss: 1.7216\n",
      "Batch 235, Loss: 1.7287\n",
      "Batch 236, Loss: 1.7147\n",
      "Batch 237, Loss: 1.7304\n",
      "Batch 238, Loss: 1.7256\n",
      "Batch 239, Loss: 1.7575\n",
      "Batch 240, Loss: 1.7427\n",
      "Batch 241, Loss: 1.7225\n",
      "Batch 242, Loss: 1.7465\n",
      "Batch 243, Loss: 1.7542\n",
      "Batch 244, Loss: 1.7527\n",
      "Batch 245, Loss: 1.7035\n",
      "Batch 246, Loss: 1.7159\n",
      "Batch 247, Loss: 1.7333\n",
      "Batch 248, Loss: 1.7335\n",
      "Batch 249, Loss: 1.7623\n",
      "Batch 250, Loss: 1.7412\n",
      "Batch 251, Loss: 1.7301\n",
      "Batch 252, Loss: 1.7329\n",
      "Batch 253, Loss: 1.7258\n",
      "Batch 254, Loss: 1.7131\n",
      "Batch 255, Loss: 1.7274\n",
      "Batch 256, Loss: 1.7078\n",
      "Batch 257, Loss: 1.7488\n",
      "Batch 258, Loss: 1.7164\n",
      "Batch 259, Loss: 1.7227\n",
      "Batch 260, Loss: 1.7229\n",
      "Batch 261, Loss: 1.7437\n",
      "Batch 262, Loss: 1.7345\n",
      "Batch 263, Loss: 1.7771\n",
      "Batch 264, Loss: 1.7314\n",
      "Batch 265, Loss: 1.7660\n",
      "Batch 266, Loss: 1.7447\n",
      "Batch 267, Loss: 1.7532\n",
      "Batch 268, Loss: 1.7316\n",
      "Batch 269, Loss: 1.7206\n",
      "Batch 270, Loss: 1.7490\n",
      "Batch 271, Loss: 1.7343\n",
      "Batch 272, Loss: 1.7002\n",
      "Batch 273, Loss: 1.7628\n",
      "Batch 274, Loss: 1.7293\n",
      "Batch 275, Loss: 1.7319\n",
      "Batch 276, Loss: 1.7371\n",
      "Batch 277, Loss: 1.7410\n",
      "Batch 278, Loss: 1.7063\n",
      "Batch 279, Loss: 1.7159\n",
      "Batch 280, Loss: 1.7352\n",
      "Batch 281, Loss: 1.7650\n",
      "Batch 282, Loss: 1.7097\n",
      "Batch 283, Loss: 1.7228\n",
      "Batch 284, Loss: 1.7078\n",
      "Batch 285, Loss: 1.7449\n",
      "Batch 286, Loss: 1.7253\n",
      "Batch 287, Loss: 1.7287\n",
      "Batch 288, Loss: 1.7050\n",
      "Batch 289, Loss: 1.7162\n",
      "Batch 290, Loss: 1.7461\n",
      "Batch 291, Loss: 1.7064\n",
      "Batch 292, Loss: 1.7314\n",
      "Batch 293, Loss: 1.7343\n",
      "Batch 294, Loss: 1.7503\n",
      "Batch 295, Loss: 1.6957\n",
      "Batch 296, Loss: 1.7643\n",
      "Batch 297, Loss: 1.7240\n",
      "Batch 298, Loss: 1.7571\n",
      "Batch 299, Loss: 1.7444\n",
      "Batch 300, Loss: 1.6931\n",
      "Batch 301, Loss: 1.7243\n",
      "Batch 302, Loss: 1.7425\n",
      "Batch 303, Loss: 1.7363\n",
      "Batch 304, Loss: 1.7225\n",
      "Batch 305, Loss: 1.7295\n",
      "Batch 306, Loss: 1.7109\n",
      "Batch 307, Loss: 1.7222\n",
      "Batch 308, Loss: 1.7256\n",
      "Batch 309, Loss: 1.7444\n",
      "Batch 310, Loss: 1.7273\n",
      "Batch 311, Loss: 1.7273\n",
      "Batch 312, Loss: 1.7050\n",
      "Batch 313, Loss: 1.7246\n",
      "Batch 314, Loss: 1.7456\n",
      "Batch 315, Loss: 1.7490\n",
      "Batch 316, Loss: 1.7466\n",
      "Batch 317, Loss: 1.7169\n",
      "Batch 318, Loss: 1.7403\n",
      "Batch 319, Loss: 1.7111\n",
      "Batch 320, Loss: 1.7281\n",
      "Batch 321, Loss: 1.6904\n",
      "Batch 322, Loss: 1.7206\n",
      "Batch 323, Loss: 1.7075\n",
      "Batch 324, Loss: 1.7385\n",
      "Batch 325, Loss: 1.6953\n",
      "Batch 326, Loss: 1.7015\n",
      "Batch 327, Loss: 1.7027\n",
      "Batch 328, Loss: 1.7296\n",
      "Batch 329, Loss: 1.7542\n",
      "Batch 330, Loss: 1.7154\n",
      "Batch 331, Loss: 1.6911\n",
      "Batch 332, Loss: 1.7312\n",
      "Batch 333, Loss: 1.7244\n",
      "Batch 334, Loss: 1.7050\n",
      "Batch 335, Loss: 1.6944\n",
      "Batch 336, Loss: 1.7099\n",
      "Batch 337, Loss: 1.7220\n",
      "Batch 338, Loss: 1.6988\n",
      "Batch 339, Loss: 1.7312\n",
      "Batch 340, Loss: 1.6938\n",
      "Batch 341, Loss: 1.7155\n",
      "Batch 342, Loss: 1.7013\n",
      "Batch 343, Loss: 1.7264\n",
      "Batch 344, Loss: 1.7054\n",
      "Batch 345, Loss: 1.7485\n",
      "Batch 346, Loss: 1.7211\n",
      "Batch 347, Loss: 1.7089\n",
      "Batch 348, Loss: 1.7125\n",
      "Batch 349, Loss: 1.6847\n",
      "Batch 350, Loss: 1.7091\n",
      "Batch 351, Loss: 1.7243\n",
      "Batch 352, Loss: 1.7295\n",
      "Batch 353, Loss: 1.7303\n",
      "Batch 354, Loss: 1.7083\n",
      "Batch 355, Loss: 1.7243\n",
      "Batch 356, Loss: 1.7155\n",
      "Batch 357, Loss: 1.7274\n",
      "Batch 358, Loss: 1.7221\n",
      "Batch 359, Loss: 1.6924\n",
      "Batch 360, Loss: 1.7052\n",
      "Batch 361, Loss: 1.6962\n",
      "Batch 362, Loss: 1.6904\n",
      "Batch 363, Loss: 1.7057\n",
      "Batch 364, Loss: 1.7238\n",
      "Batch 365, Loss: 1.6936\n",
      "Batch 366, Loss: 1.7147\n",
      "Batch 367, Loss: 1.6930\n",
      "Batch 368, Loss: 1.6898\n",
      "Batch 369, Loss: 1.7242\n",
      "Batch 370, Loss: 1.7085\n",
      "Batch 371, Loss: 1.7073\n",
      "Batch 372, Loss: 1.7019\n",
      "Batch 373, Loss: 1.6932\n",
      "Batch 374, Loss: 1.6938\n",
      "Batch 375, Loss: 1.6783\n",
      "Batch 376, Loss: 1.6831\n",
      "Batch 377, Loss: 1.7115\n",
      "Batch 378, Loss: 1.7056\n",
      "Batch 379, Loss: 1.7347\n",
      "Batch 380, Loss: 1.6941\n",
      "Batch 381, Loss: 1.7072\n",
      "Batch 382, Loss: 1.6939\n",
      "Batch 383, Loss: 1.6975\n",
      "Batch 384, Loss: 1.7088\n",
      "Batch 385, Loss: 1.7217\n",
      "Batch 386, Loss: 1.7051\n",
      "Batch 387, Loss: 1.6858\n",
      "Batch 388, Loss: 1.7082\n",
      "Batch 389, Loss: 1.6716\n",
      "Batch 390, Loss: 1.7132\n",
      "Batch 391, Loss: 1.6879\n",
      "Batch 392, Loss: 1.7199\n",
      "Batch 393, Loss: 1.7077\n",
      "Batch 394, Loss: 1.6749\n",
      "Batch 395, Loss: 1.6939\n",
      "Batch 396, Loss: 1.7176\n",
      "Batch 397, Loss: 1.6612\n",
      "Batch 398, Loss: 1.7168\n",
      "Batch 399, Loss: 1.7137\n",
      "Batch 400, Loss: 1.6966\n",
      "Batch 401, Loss: 1.7162\n",
      "Batch 402, Loss: 1.7142\n",
      "Batch 403, Loss: 1.7080\n",
      "Batch 404, Loss: 1.7101\n",
      "Batch 405, Loss: 1.7068\n",
      "Batch 406, Loss: 1.6826\n",
      "Batch 407, Loss: 1.7059\n",
      "Batch 408, Loss: 1.7244\n",
      "Batch 409, Loss: 1.7053\n",
      "Batch 410, Loss: 1.7097\n",
      "Batch 411, Loss: 1.6877\n",
      "Batch 412, Loss: 1.7066\n",
      "Batch 413, Loss: 1.6959\n",
      "Batch 414, Loss: 1.7009\n",
      "Batch 415, Loss: 1.6992\n",
      "Batch 416, Loss: 1.7151\n",
      "Batch 417, Loss: 1.7189\n",
      "Batch 418, Loss: 1.7076\n",
      "Batch 419, Loss: 1.6996\n",
      "Batch 420, Loss: 1.6939\n",
      "Batch 421, Loss: 1.6738\n",
      "Batch 422, Loss: 1.6827\n",
      "Batch 423, Loss: 1.7331\n",
      "Batch 424, Loss: 1.6991\n",
      "Batch 425, Loss: 1.6829\n",
      "Batch 426, Loss: 1.6908\n",
      "Batch 427, Loss: 1.7029\n",
      "Batch 428, Loss: 1.7087\n",
      "Batch 429, Loss: 1.6795\n",
      "Batch 430, Loss: 1.6814\n",
      "Batch 431, Loss: 1.6901\n",
      "Batch 432, Loss: 1.7044\n",
      "Batch 433, Loss: 1.6884\n",
      "Batch 434, Loss: 1.7036\n",
      "Batch 435, Loss: 1.6965\n",
      "Batch 436, Loss: 1.7157\n",
      "Batch 437, Loss: 1.7089\n",
      "Batch 438, Loss: 1.7262\n",
      "Batch 439, Loss: 1.7293\n",
      "Batch 440, Loss: 1.6889\n",
      "Batch 441, Loss: 1.7035\n",
      "Batch 442, Loss: 1.6855\n",
      "Batch 443, Loss: 1.7145\n",
      "Batch 444, Loss: 1.6945\n",
      "Batch 445, Loss: 1.6978\n",
      "Batch 446, Loss: 1.6992\n",
      "Batch 447, Loss: 1.7176\n",
      "Batch 448, Loss: 1.6939\n",
      "Batch 449, Loss: 1.6910\n",
      "Batch 450, Loss: 1.7052\n",
      "Batch 451, Loss: 1.7138\n",
      "Batch 452, Loss: 1.6918\n",
      "Batch 453, Loss: 1.7081\n",
      "Batch 454, Loss: 1.6695\n",
      "Batch 455, Loss: 1.7073\n",
      "Batch 456, Loss: 1.6865\n",
      "Batch 457, Loss: 1.6865\n",
      "Batch 458, Loss: 1.7069\n",
      "Batch 459, Loss: 1.6818\n",
      "Batch 460, Loss: 1.6913\n",
      "Batch 461, Loss: 1.6754\n",
      "Batch 462, Loss: 1.6464\n",
      "Batch 463, Loss: 1.6898\n",
      "Batch 464, Loss: 1.6710\n",
      "Batch 465, Loss: 1.7017\n",
      "Batch 466, Loss: 1.7182\n",
      "Batch 467, Loss: 1.7008\n",
      "Batch 468, Loss: 1.6951\n",
      "Batch 469, Loss: 1.6797\n",
      "Batch 470, Loss: 1.6948\n",
      "Batch 471, Loss: 1.6966\n",
      "Batch 472, Loss: 1.6862\n",
      "Batch 473, Loss: 1.6985\n",
      "Batch 474, Loss: 1.7128\n",
      "Batch 475, Loss: 1.7046\n",
      "Batch 476, Loss: 1.6984\n",
      "Batch 477, Loss: 1.7010\n",
      "Batch 478, Loss: 1.6783\n",
      "Batch 479, Loss: 1.6790\n",
      "Batch 480, Loss: 1.6683\n",
      "Batch 481, Loss: 1.7118\n",
      "Batch 482, Loss: 1.6809\n",
      "Batch 483, Loss: 1.6882\n",
      "John and his mum were bothering. They had even wait Emily's hand and they couldn't because it was surprised to because the duck was yellow \n",
      "as they people they didn't have enough something new. Suddenly, one of them enthusiandiastic bolasticed in reading their body. John and his mum went to \n",
      "the Qulue. John ran to work. When they got to the veulub with the boxed body's hands. He took it in and they walked until \n",
      "they were all still having her new friends. Suddenly, John decided to come back and see the people again. He asked her mum to stop \n",
      "and mum smiled and said they would become tripping so many things with kids and sing. They laughed and had so much fun. \n",
      "\n",
      "--------------------\n",
      "Batch 484, Loss: 1.7083\n",
      "Batch 485, Loss: 1.6655\n",
      "Batch 486, Loss: 1.6822\n",
      "Batch 487, Loss: 1.6967\n",
      "Batch 488, Loss: 1.6979\n",
      "Batch 489, Loss: 1.6556\n",
      "Batch 490, Loss: 1.6764\n",
      "Batch 491, Loss: 1.6793\n",
      "Batch 492, Loss: 1.7109\n",
      "Batch 493, Loss: 1.6721\n",
      "Batch 494, Loss: 1.6937\n",
      "Batch 495, Loss: 1.6944\n",
      "Batch 496, Loss: 1.6644\n",
      "Batch 497, Loss: 1.6817\n",
      "Batch 498, Loss: 1.7182\n",
      "Batch 499, Loss: 1.6694\n",
      "Batch 500, Loss: 1.6878\n",
      "Batch 501, Loss: 1.6845\n",
      "Batch 502, Loss: 1.6727\n",
      "Batch 503, Loss: 1.6860\n",
      "Batch 504, Loss: 1.6873\n",
      "Batch 505, Loss: 1.6809\n",
      "Batch 506, Loss: 1.6808\n",
      "Batch 507, Loss: 1.6847\n",
      "Batch 508, Loss: 1.6796\n",
      "Batch 509, Loss: 1.6866\n",
      "Batch 510, Loss: 1.6744\n",
      "Batch 511, Loss: 1.6791\n",
      "Batch 512, Loss: 1.6798\n",
      "Batch 513, Loss: 1.7096\n",
      "Batch 514, Loss: 1.6973\n",
      "Batch 515, Loss: 1.6959\n",
      "Batch 516, Loss: 1.7138\n",
      "Batch 517, Loss: 1.6767\n",
      "Batch 518, Loss: 1.6650\n",
      "Batch 519, Loss: 1.6924\n",
      "Batch 520, Loss: 1.6760\n",
      "Batch 521, Loss: 1.6983\n",
      "Batch 522, Loss: 1.7113\n",
      "Batch 523, Loss: 1.6782\n",
      "Batch 524, Loss: 1.6855\n",
      "Batch 525, Loss: 1.6773\n",
      "Batch 526, Loss: 1.6918\n",
      "Batch 527, Loss: 1.6879\n",
      "Batch 528, Loss: 1.6654\n",
      "Batch 529, Loss: 1.6904\n",
      "Batch 530, Loss: 1.6782\n",
      "Batch 531, Loss: 1.6823\n",
      "Batch 532, Loss: 1.6926\n",
      "Batch 533, Loss: 1.6618\n",
      "Batch 534, Loss: 1.7036\n",
      "Batch 535, Loss: 1.6870\n",
      "Batch 536, Loss: 1.6454\n",
      "Batch 537, Loss: 1.6888\n",
      "Batch 538, Loss: 1.6687\n",
      "Batch 539, Loss: 1.7048\n",
      "Batch 540, Loss: 1.6963\n",
      "Batch 541, Loss: 1.6733\n",
      "Batch 542, Loss: 1.6696\n",
      "Batch 543, Loss: 1.6793\n",
      "Batch 544, Loss: 1.6850\n",
      "Batch 545, Loss: 1.6654\n",
      "Batch 546, Loss: 1.6900\n",
      "Batch 547, Loss: 1.6802\n",
      "Batch 548, Loss: 1.7013\n",
      "Batch 549, Loss: 1.6972\n",
      "Batch 550, Loss: 1.7171\n",
      "Batch 551, Loss: 1.6818\n",
      "Batch 552, Loss: 1.7129\n",
      "Batch 553, Loss: 1.6584\n",
      "Batch 554, Loss: 1.6878\n",
      "Batch 555, Loss: 1.6802\n",
      "Batch 556, Loss: 1.6806\n",
      "Batch 557, Loss: 1.6595\n",
      "Batch 558, Loss: 1.6681\n",
      "Batch 559, Loss: 1.6790\n",
      "Batch 560, Loss: 1.6679\n",
      "Batch 561, Loss: 1.6486\n",
      "Batch 562, Loss: 1.6693\n",
      "Batch 563, Loss: 1.6901\n",
      "Batch 564, Loss: 1.6875\n",
      "Batch 565, Loss: 1.6725\n",
      "Batch 566, Loss: 1.6652\n",
      "Batch 567, Loss: 1.6636\n",
      "Batch 568, Loss: 1.6551\n",
      "Batch 569, Loss: 1.6800\n",
      "Batch 570, Loss: 1.6911\n",
      "Batch 571, Loss: 1.6555\n",
      "Batch 572, Loss: 1.6789\n",
      "Batch 573, Loss: 1.6519\n",
      "Batch 574, Loss: 1.6835\n",
      "Batch 575, Loss: 1.6417\n",
      "Batch 576, Loss: 1.6539\n",
      "Batch 577, Loss: 1.6683\n",
      "Batch 578, Loss: 1.6829\n",
      "Batch 579, Loss: 1.7133\n",
      "Batch 580, Loss: 1.6636\n",
      "Batch 581, Loss: 1.6558\n",
      "Batch 582, Loss: 1.6923\n",
      "Batch 583, Loss: 1.7145\n",
      "Batch 584, Loss: 1.6703\n",
      "Batch 585, Loss: 1.6544\n",
      "Batch 586, Loss: 1.6817\n",
      "Batch 587, Loss: 1.6621\n",
      "Batch 588, Loss: 1.6795\n",
      "Batch 589, Loss: 1.6630\n",
      "Batch 590, Loss: 1.6614\n",
      "Batch 591, Loss: 1.6896\n",
      "Batch 592, Loss: 1.6915\n",
      "Batch 593, Loss: 1.6633\n",
      "Batch 594, Loss: 1.6920\n",
      "Batch 595, Loss: 1.6691\n",
      "Batch 596, Loss: 1.6586\n",
      "Batch 597, Loss: 1.6526\n",
      "Batch 598, Loss: 1.6574\n",
      "Batch 599, Loss: 1.6724\n",
      "Batch 600, Loss: 1.6776\n",
      "Batch 601, Loss: 1.6538\n",
      "Batch 602, Loss: 1.6772\n",
      "Batch 603, Loss: 1.6605\n",
      "Batch 604, Loss: 1.6606\n",
      "Batch 605, Loss: 1.6648\n",
      "Batch 606, Loss: 1.6644\n",
      "Batch 607, Loss: 1.6736\n",
      "Batch 608, Loss: 1.6410\n",
      "Batch 609, Loss: 1.6728\n",
      "Batch 610, Loss: 1.6701\n",
      "Batch 611, Loss: 1.6905\n",
      "Batch 612, Loss: 1.6887\n",
      "Batch 613, Loss: 1.6968\n",
      "Batch 614, Loss: 1.7100\n",
      "Batch 615, Loss: 1.6405\n",
      "Batch 616, Loss: 1.6820\n",
      "Batch 617, Loss: 1.6798\n",
      "Batch 618, Loss: 1.6548\n",
      "Batch 619, Loss: 1.6713\n",
      "Batch 620, Loss: 1.6688\n",
      "Batch 621, Loss: 1.6595\n",
      "Batch 622, Loss: 1.6742\n",
      "Batch 623, Loss: 1.6379\n",
      "Batch 624, Loss: 1.6367\n",
      "Batch 625, Loss: 1.6835\n",
      "Batch 626, Loss: 1.6748\n",
      "Batch 627, Loss: 1.6640\n",
      "Batch 628, Loss: 1.6983\n",
      "Batch 629, Loss: 1.6489\n",
      "Batch 630, Loss: 1.6480\n",
      "Batch 631, Loss: 1.6919\n",
      "Batch 632, Loss: 1.6619\n",
      "Batch 633, Loss: 1.6986\n",
      "Batch 634, Loss: 1.6668\n",
      "Batch 635, Loss: 1.6638\n",
      "Batch 636, Loss: 1.6693\n",
      "Batch 637, Loss: 1.6742\n",
      "Batch 638, Loss: 1.6685\n",
      "Batch 639, Loss: 1.6508\n",
      "Batch 640, Loss: 1.6644\n",
      "Batch 641, Loss: 1.6829\n",
      "Batch 642, Loss: 1.6462\n",
      "Batch 643, Loss: 1.6909\n",
      "Batch 644, Loss: 1.6660\n",
      "Batch 645, Loss: 1.6505\n",
      "Batch 646, Loss: 1.6952\n",
      "Batch 647, Loss: 1.6706\n",
      "Batch 648, Loss: 1.6532\n",
      "Batch 649, Loss: 1.6640\n",
      "Batch 650, Loss: 1.6518\n",
      "Batch 651, Loss: 1.6886\n",
      "Batch 652, Loss: 1.6537\n",
      "Batch 653, Loss: 1.6494\n",
      "Batch 654, Loss: 1.6735\n",
      "Batch 655, Loss: 1.6890\n",
      "Batch 656, Loss: 1.6592\n",
      "Batch 657, Loss: 1.6619\n",
      "Batch 658, Loss: 1.6638\n",
      "Batch 659, Loss: 1.6491\n",
      "Batch 660, Loss: 1.6511\n",
      "Batch 661, Loss: 1.6497\n",
      "Batch 662, Loss: 1.6739\n",
      "Batch 663, Loss: 1.6839\n",
      "Batch 664, Loss: 1.6863\n",
      "Batch 665, Loss: 1.6493\n",
      "Batch 666, Loss: 1.6633\n",
      "Batch 667, Loss: 1.6577\n",
      "Batch 668, Loss: 1.6466\n",
      "Batch 669, Loss: 1.7045\n",
      "Batch 670, Loss: 1.6879\n",
      "Batch 671, Loss: 1.6420\n",
      "Batch 672, Loss: 1.6549\n",
      "Batch 673, Loss: 1.6664\n",
      "Batch 674, Loss: 1.6765\n",
      "Batch 675, Loss: 1.6591\n",
      "Batch 676, Loss: 1.6682\n",
      "Batch 677, Loss: 1.6430\n",
      "Batch 678, Loss: 1.6829\n",
      "Batch 679, Loss: 1.6359\n",
      "Batch 680, Loss: 1.6547\n",
      "Batch 681, Loss: 1.6558\n",
      "Batch 682, Loss: 1.6570\n",
      "Batch 683, Loss: 1.6636\n",
      "Batch 684, Loss: 1.6235\n",
      "Batch 685, Loss: 1.6607\n",
      "Batch 686, Loss: 1.6509\n",
      "Batch 687, Loss: 1.6640\n",
      "Batch 688, Loss: 1.6528\n",
      "Batch 689, Loss: 1.6638\n",
      "Batch 690, Loss: 1.6754\n",
      "Batch 691, Loss: 1.6658\n",
      "Batch 692, Loss: 1.6362\n",
      "Batch 693, Loss: 1.6487\n",
      "Batch 694, Loss: 1.6639\n",
      "Batch 695, Loss: 1.6597\n",
      "Batch 696, Loss: 1.6622\n",
      "Batch 697, Loss: 1.6471\n",
      "Batch 698, Loss: 1.6640\n",
      "Batch 699, Loss: 1.6613\n",
      "Batch 700, Loss: 1.6525\n",
      "Batch 701, Loss: 1.6470\n",
      "Batch 702, Loss: 1.6666\n",
      "Batch 703, Loss: 1.6713\n",
      "Batch 704, Loss: 1.6544\n",
      "Batch 705, Loss: 1.6715\n",
      "Batch 706, Loss: 1.6822\n",
      "Batch 707, Loss: 1.6863\n",
      "Batch 708, Loss: 1.6418\n",
      "Batch 709, Loss: 1.6708\n",
      "Batch 710, Loss: 1.6264\n",
      "Batch 711, Loss: 1.6538\n",
      "Batch 712, Loss: 1.6544\n",
      "Batch 713, Loss: 1.6469\n",
      "Batch 714, Loss: 1.6417\n",
      "Batch 715, Loss: 1.6494\n",
      "Batch 716, Loss: 1.6657\n",
      "Batch 717, Loss: 1.6409\n",
      "Batch 718, Loss: 1.6360\n",
      "Batch 719, Loss: 1.6593\n",
      "Batch 720, Loss: 1.6466\n",
      "Batch 721, Loss: 1.6485\n",
      "Batch 722, Loss: 1.6639\n",
      "Batch 723, Loss: 1.6346\n",
      "Batch 724, Loss: 1.6451\n",
      "Batch 725, Loss: 1.6434\n",
      "Batch 726, Loss: 1.6748\n",
      "Batch 727, Loss: 1.6426\n",
      "Batch 728, Loss: 1.6624\n",
      "Batch 729, Loss: 1.6434\n",
      "Batch 730, Loss: 1.6407\n",
      "Batch 731, Loss: 1.6714\n",
      "Batch 732, Loss: 1.6326\n",
      "Batch 733, Loss: 1.6662\n",
      "Batch 734, Loss: 1.6469\n",
      "Batch 735, Loss: 1.6408\n",
      "Batch 736, Loss: 1.6482\n",
      "Batch 737, Loss: 1.6468\n",
      "Batch 738, Loss: 1.6575\n",
      "Batch 739, Loss: 1.6900\n",
      "Batch 740, Loss: 1.6263\n",
      "Batch 741, Loss: 1.6514\n",
      "Batch 742, Loss: 1.6499\n",
      "Batch 743, Loss: 1.6471\n",
      "Batch 744, Loss: 1.6639\n",
      "Batch 745, Loss: 1.6690\n",
      "Batch 746, Loss: 1.6596\n",
      "Batch 747, Loss: 1.6369\n",
      "Batch 748, Loss: 1.6788\n",
      "Batch 749, Loss: 1.6373\n",
      "Batch 750, Loss: 1.6668\n",
      "Batch 751, Loss: 1.6666\n",
      "Batch 752, Loss: 1.6372\n",
      "Batch 753, Loss: 1.6529\n",
      "Batch 754, Loss: 1.6619\n",
      "Batch 755, Loss: 1.6593\n",
      "Batch 756, Loss: 1.6602\n",
      "Batch 757, Loss: 1.6259\n",
      "Batch 758, Loss: 1.6317\n",
      "Batch 759, Loss: 1.6546\n",
      "Batch 760, Loss: 1.6319\n",
      "Batch 761, Loss: 1.6380\n",
      "Batch 762, Loss: 1.6623\n",
      "Batch 763, Loss: 1.6730\n",
      "Batch 764, Loss: 1.6454\n",
      "Batch 765, Loss: 1.7031\n",
      "Batch 766, Loss: 1.6648\n",
      "Batch 767, Loss: 1.6640\n",
      "Batch 768, Loss: 1.6417\n",
      "Batch 769, Loss: 1.6055\n",
      "Batch 770, Loss: 1.6634\n",
      "Batch 771, Loss: 1.6423\n",
      "Batch 772, Loss: 1.6659\n",
      "Batch 773, Loss: 1.6553\n",
      "Batch 774, Loss: 1.6265\n",
      "Batch 775, Loss: 1.6666\n",
      "Batch 776, Loss: 1.6451\n",
      "Batch 777, Loss: 1.6452\n",
      "Batch 778, Loss: 1.6319\n",
      "Batch 779, Loss: 1.6720\n",
      "Batch 780, Loss: 1.6487\n",
      "Batch 781, Loss: 1.6320\n",
      "Batch 782, Loss: 1.6375\n",
      "Batch 783, Loss: 1.6644\n",
      "Batch 784, Loss: 1.6576\n",
      "Batch 785, Loss: 1.6461\n",
      "Batch 786, Loss: 1.6783\n",
      "Batch 787, Loss: 1.6595\n",
      "Batch 788, Loss: 1.6440\n",
      "Batch 789, Loss: 1.6327\n",
      "Batch 790, Loss: 1.6255\n",
      "Batch 791, Loss: 1.6314\n",
      "Batch 792, Loss: 1.6383\n",
      "Batch 793, Loss: 1.6404\n",
      "Batch 794, Loss: 1.6312\n",
      "Batch 795, Loss: 1.6419\n",
      "Batch 796, Loss: 1.6440\n",
      "Batch 797, Loss: 1.6714\n",
      "Batch 798, Loss: 1.6436\n",
      "Batch 799, Loss: 1.6437\n",
      "Batch 800, Loss: 1.6915\n",
      "Batch 801, Loss: 1.6258\n",
      "Batch 802, Loss: 1.6381\n",
      "Batch 803, Loss: 1.6476\n",
      "Batch 804, Loss: 1.6546\n",
      "Batch 805, Loss: 1.6468\n",
      "Batch 806, Loss: 1.6541\n",
      "Batch 807, Loss: 1.6413\n",
      "Batch 808, Loss: 1.6117\n",
      "Batch 809, Loss: 1.6428\n",
      "Batch 810, Loss: 1.6207\n",
      "Batch 811, Loss: 1.6567\n",
      "Batch 812, Loss: 1.6513\n",
      "Batch 813, Loss: 1.6375\n",
      "Batch 814, Loss: 1.6449\n",
      "Batch 815, Loss: 1.6444\n",
      "Batch 816, Loss: 1.6443\n",
      "Batch 817, Loss: 1.6304\n",
      "Batch 818, Loss: 1.6671\n",
      "Batch 819, Loss: 1.6526\n",
      "Batch 820, Loss: 1.6441\n",
      "Batch 821, Loss: 1.6420\n",
      "Batch 822, Loss: 1.6130\n",
      "Batch 823, Loss: 1.6427\n",
      "Batch 824, Loss: 1.6577\n",
      "Batch 825, Loss: 1.6504\n",
      "Batch 826, Loss: 1.6180\n",
      "Batch 827, Loss: 1.6514\n",
      "Batch 828, Loss: 1.6246\n",
      "Batch 829, Loss: 1.6427\n",
      "Batch 830, Loss: 1.6283\n",
      "Batch 831, Loss: 1.6575\n",
      "Batch 832, Loss: 1.6257\n",
      "Batch 833, Loss: 1.6279\n",
      "Batch 834, Loss: 1.6463\n",
      "Batch 835, Loss: 1.6145\n",
      "Batch 836, Loss: 1.6551\n",
      "Batch 837, Loss: 1.6399\n",
      "Batch 838, Loss: 1.6332\n",
      "Batch 839, Loss: 1.6477\n",
      "Batch 840, Loss: 1.6006\n",
      "Batch 841, Loss: 1.6515\n",
      "Batch 842, Loss: 1.6575\n",
      "Batch 843, Loss: 1.6470\n",
      "Batch 844, Loss: 1.6346\n",
      "Batch 845, Loss: 1.6737\n",
      "Batch 846, Loss: 1.6439\n",
      "Batch 847, Loss: 1.6143\n",
      "Batch 848, Loss: 1.6397\n",
      "Batch 849, Loss: 1.6283\n",
      "Batch 850, Loss: 1.6248\n",
      "Batch 851, Loss: 1.6442\n",
      "Batch 852, Loss: 1.6382\n",
      "Batch 853, Loss: 1.6354\n",
      "Batch 854, Loss: 1.6326\n",
      "Batch 855, Loss: 1.6460\n",
      "Batch 856, Loss: 1.6249\n",
      "Batch 857, Loss: 1.6389\n",
      "Batch 858, Loss: 1.6073\n",
      "Batch 859, Loss: 1.6371\n",
      "Batch 860, Loss: 1.6586\n",
      "Batch 861, Loss: 1.6767\n",
      "Batch 862, Loss: 1.6459\n",
      "Batch 863, Loss: 1.6499\n",
      "Batch 864, Loss: 1.6048\n",
      "Batch 865, Loss: 1.6313\n",
      "Batch 866, Loss: 1.6422\n",
      "Batch 867, Loss: 1.6361\n",
      "Batch 868, Loss: 1.6414\n",
      "Batch 869, Loss: 1.6590\n",
      "Batch 870, Loss: 1.6429\n",
      "Batch 871, Loss: 1.6360\n",
      "Batch 872, Loss: 1.6107\n",
      "Batch 873, Loss: 1.6324\n",
      "Batch 874, Loss: 1.6490\n",
      "Batch 875, Loss: 1.6261\n",
      "Batch 876, Loss: 1.6462\n",
      "Batch 877, Loss: 1.6402\n",
      "Batch 878, Loss: 1.6478\n",
      "Batch 879, Loss: 1.6316\n",
      "Batch 880, Loss: 1.6248\n",
      "Batch 881, Loss: 1.6499\n",
      "Batch 882, Loss: 1.6397\n",
      "Batch 883, Loss: 1.6331\n",
      "Batch 884, Loss: 1.6276\n",
      "Batch 885, Loss: 1.6330\n",
      "Batch 886, Loss: 1.6603\n",
      "Batch 887, Loss: 1.6503\n",
      "Batch 888, Loss: 1.6473\n",
      "Batch 889, Loss: 1.6286\n",
      "Batch 890, Loss: 1.6041\n",
      "Batch 891, Loss: 1.6245\n",
      "Batch 892, Loss: 1.6223\n",
      "Batch 893, Loss: 1.6161\n",
      "Batch 894, Loss: 1.6391\n",
      "Batch 895, Loss: 1.6445\n",
      "Batch 896, Loss: 1.6248\n",
      "Batch 897, Loss: 1.6267\n",
      "Batch 898, Loss: 1.6357\n",
      "Batch 899, Loss: 1.6299\n",
      "Batch 900, Loss: 1.6355\n",
      "Batch 901, Loss: 1.6521\n",
      "Batch 902, Loss: 1.6288\n",
      "Batch 903, Loss: 1.5939\n",
      "Batch 904, Loss: 1.6453\n",
      "Batch 905, Loss: 1.6030\n",
      "Batch 906, Loss: 1.6405\n",
      "Batch 907, Loss: 1.6178\n",
      "Batch 908, Loss: 1.6301\n",
      "Batch 909, Loss: 1.6159\n",
      "Batch 910, Loss: 1.6266\n",
      "Batch 911, Loss: 1.6501\n",
      "Batch 912, Loss: 1.6295\n",
      "Batch 913, Loss: 1.6545\n",
      "Batch 914, Loss: 1.6552\n",
      "Batch 915, Loss: 1.6564\n",
      "Batch 916, Loss: 1.6242\n",
      "Batch 917, Loss: 1.6125\n",
      "Batch 918, Loss: 1.6470\n",
      "Batch 919, Loss: 1.6184\n",
      "Batch 920, Loss: 1.6524\n",
      "Batch 921, Loss: 1.6460\n",
      "Batch 922, Loss: 1.6361\n",
      "Batch 923, Loss: 1.6295\n",
      "Batch 924, Loss: 1.6198\n",
      "Batch 925, Loss: 1.6350\n",
      "Batch 926, Loss: 1.6128\n",
      "Batch 927, Loss: 1.6303\n",
      "Batch 928, Loss: 1.6130\n",
      "Batch 929, Loss: 1.6416\n",
      "Batch 930, Loss: 1.6149\n",
      "Batch 931, Loss: 1.6412\n",
      "Batch 932, Loss: 1.6138\n",
      "Batch 933, Loss: 1.6337\n",
      "Batch 934, Loss: 1.6357\n",
      "Batch 935, Loss: 1.6398\n",
      "Batch 936, Loss: 1.6198\n",
      "Batch 937, Loss: 1.6172\n",
      "Batch 938, Loss: 1.6330\n",
      "Batch 939, Loss: 1.6192\n",
      "Batch 940, Loss: 1.6309\n",
      "Batch 941, Loss: 1.6321\n",
      "Batch 942, Loss: 1.6434\n",
      "Batch 943, Loss: 1.6314\n",
      "Batch 944, Loss: 1.6230\n",
      "Batch 945, Loss: 1.6444\n",
      "Batch 946, Loss: 1.6260\n",
      "Batch 947, Loss: 1.6104\n",
      "Batch 948, Loss: 1.6248\n",
      "Batch 949, Loss: 1.6285\n",
      "Batch 950, Loss: 1.6234\n",
      "Batch 951, Loss: 1.6310\n",
      "Batch 952, Loss: 1.6578\n",
      "Batch 953, Loss: 1.6129\n",
      "Batch 954, Loss: 1.6170\n",
      "Batch 955, Loss: 1.6340\n",
      "Batch 956, Loss: 1.6000\n",
      "Batch 957, Loss: 1.6233\n",
      "Batch 958, Loss: 1.6330\n",
      "Batch 959, Loss: 1.6011\n",
      "Batch 960, Loss: 1.6141\n",
      "Batch 961, Loss: 1.6308\n",
      "Batch 962, Loss: 1.6166\n",
      "Batch 963, Loss: 1.6382\n",
      "Batch 964, Loss: 1.6518\n",
      "Batch 965, Loss: 1.6193\n",
      "Epoch 2, Average Loss: 1.6981\n",
      "One day, little boy named Tim found an ice crawling on the ground. He liked to run and play with it. Suddenly, a sign shone \n",
      "in the forest. The sun was setce! Tim was sad. Tim wanted to wish the ice cream was? The 3, Tim's friends, Bir friend came \n",
      "over. Bird said, \"No, it's mine, Grandpicy!\" Tim was scared and did not have an idea. Bird climbed up the ice crawling on the ground. \n",
      "When Tim got closer, he saw a ice cream to Mird. She thought, \"We too ice cream of ice cream and see the ice cream!\" \n",
      "Bird said, \"Well, that for ice cream. Go let's play on it, Tim.\" Bird thanked Bird and played together all day. From then on, Tim \n",
      "and Bird got to make ice cream on. The End. \n",
      "\n",
      "--------------------\n",
      "Batch 0, Loss: 1.5948\n",
      "Batch 1, Loss: 1.6339\n",
      "Batch 2, Loss: 1.6078\n",
      "Batch 3, Loss: 1.6159\n",
      "Batch 4, Loss: 1.6135\n",
      "Batch 5, Loss: 1.6531\n",
      "Batch 6, Loss: 1.6012\n",
      "Batch 7, Loss: 1.5984\n",
      "Batch 8, Loss: 1.6020\n",
      "Batch 9, Loss: 1.6205\n",
      "Batch 10, Loss: 1.6169\n",
      "Batch 11, Loss: 1.6390\n",
      "Batch 12, Loss: 1.6155\n",
      "Batch 13, Loss: 1.6242\n",
      "Batch 14, Loss: 1.5931\n",
      "Batch 15, Loss: 1.6170\n",
      "Batch 16, Loss: 1.6185\n",
      "Batch 17, Loss: 1.6108\n",
      "Batch 18, Loss: 1.6106\n",
      "Batch 19, Loss: 1.6163\n",
      "Batch 20, Loss: 1.6188\n",
      "Batch 21, Loss: 1.6084\n",
      "Batch 22, Loss: 1.6296\n",
      "Batch 23, Loss: 1.6067\n",
      "Batch 24, Loss: 1.5997\n",
      "Batch 25, Loss: 1.6118\n",
      "Batch 26, Loss: 1.6054\n",
      "Batch 27, Loss: 1.6141\n",
      "Batch 28, Loss: 1.5987\n",
      "Batch 29, Loss: 1.6335\n",
      "Batch 30, Loss: 1.5936\n",
      "Batch 31, Loss: 1.6161\n",
      "Batch 32, Loss: 1.6233\n",
      "Batch 33, Loss: 1.5899\n",
      "Batch 34, Loss: 1.6405\n",
      "Batch 35, Loss: 1.5925\n",
      "Batch 36, Loss: 1.6142\n",
      "Batch 37, Loss: 1.6169\n",
      "Batch 38, Loss: 1.6210\n",
      "Batch 39, Loss: 1.6132\n",
      "Batch 40, Loss: 1.5925\n",
      "Batch 41, Loss: 1.6115\n",
      "Batch 42, Loss: 1.6377\n",
      "Batch 43, Loss: 1.6344\n",
      "Batch 44, Loss: 1.6333\n",
      "Batch 45, Loss: 1.5996\n",
      "Batch 46, Loss: 1.6097\n",
      "Batch 47, Loss: 1.6188\n",
      "Batch 48, Loss: 1.6162\n",
      "Batch 49, Loss: 1.6167\n",
      "Batch 50, Loss: 1.5930\n",
      "Batch 51, Loss: 1.6354\n",
      "Batch 52, Loss: 1.6274\n",
      "Batch 53, Loss: 1.6160\n",
      "Batch 54, Loss: 1.6162\n",
      "Batch 55, Loss: 1.6310\n",
      "Batch 56, Loss: 1.6266\n",
      "Batch 57, Loss: 1.6360\n",
      "Batch 58, Loss: 1.6194\n",
      "Batch 59, Loss: 1.5945\n",
      "Batch 60, Loss: 1.5986\n",
      "Batch 61, Loss: 1.5922\n",
      "Batch 62, Loss: 1.6081\n",
      "Batch 63, Loss: 1.5809\n",
      "Batch 64, Loss: 1.6269\n",
      "Batch 65, Loss: 1.6036\n",
      "Batch 66, Loss: 1.5927\n",
      "Batch 67, Loss: 1.6028\n",
      "Batch 68, Loss: 1.6093\n",
      "Batch 69, Loss: 1.6364\n",
      "Batch 70, Loss: 1.6192\n",
      "Batch 71, Loss: 1.6440\n",
      "Batch 72, Loss: 1.5928\n",
      "Batch 73, Loss: 1.6101\n",
      "Batch 74, Loss: 1.6135\n",
      "Batch 75, Loss: 1.6030\n",
      "Batch 76, Loss: 1.5995\n",
      "Batch 77, Loss: 1.6001\n",
      "Batch 78, Loss: 1.6163\n",
      "Batch 79, Loss: 1.5945\n",
      "Batch 80, Loss: 1.6368\n",
      "Batch 81, Loss: 1.6001\n",
      "Batch 82, Loss: 1.6215\n",
      "Batch 83, Loss: 1.5984\n",
      "Batch 84, Loss: 1.5870\n",
      "Batch 85, Loss: 1.5963\n",
      "Batch 86, Loss: 1.5932\n",
      "Batch 87, Loss: 1.6485\n",
      "Batch 88, Loss: 1.6125\n",
      "Batch 89, Loss: 1.6119\n",
      "Batch 90, Loss: 1.5958\n",
      "Batch 91, Loss: 1.6269\n",
      "Batch 92, Loss: 1.5953\n",
      "Batch 93, Loss: 1.6018\n",
      "Batch 94, Loss: 1.5963\n",
      "Batch 95, Loss: 1.6289\n",
      "Batch 96, Loss: 1.5843\n",
      "Batch 97, Loss: 1.6093\n",
      "Batch 98, Loss: 1.6202\n",
      "Batch 99, Loss: 1.6298\n",
      "Batch 100, Loss: 1.6310\n",
      "Batch 101, Loss: 1.5979\n",
      "Batch 102, Loss: 1.5826\n",
      "Batch 103, Loss: 1.6050\n",
      "Batch 104, Loss: 1.6004\n",
      "Batch 105, Loss: 1.6081\n",
      "Batch 106, Loss: 1.5719\n",
      "Batch 107, Loss: 1.6135\n",
      "Batch 108, Loss: 1.5888\n",
      "Batch 109, Loss: 1.6226\n",
      "Batch 110, Loss: 1.6222\n",
      "Batch 111, Loss: 1.5861\n",
      "Batch 112, Loss: 1.6070\n",
      "Batch 113, Loss: 1.6166\n",
      "Batch 114, Loss: 1.5878\n",
      "Batch 115, Loss: 1.5978\n",
      "Batch 116, Loss: 1.6213\n",
      "Batch 117, Loss: 1.6222\n",
      "Batch 118, Loss: 1.5997\n",
      "Batch 119, Loss: 1.6328\n",
      "Batch 120, Loss: 1.6021\n",
      "Batch 121, Loss: 1.6176\n",
      "Batch 122, Loss: 1.6111\n",
      "Batch 123, Loss: 1.5973\n",
      "Batch 124, Loss: 1.6282\n",
      "Batch 125, Loss: 1.5909\n",
      "Batch 126, Loss: 1.5993\n",
      "Batch 127, Loss: 1.6350\n",
      "Batch 128, Loss: 1.6058\n",
      "Batch 129, Loss: 1.5875\n",
      "Batch 130, Loss: 1.6092\n",
      "Batch 131, Loss: 1.5790\n",
      "Batch 132, Loss: 1.6052\n",
      "Batch 133, Loss: 1.6030\n",
      "Batch 134, Loss: 1.6200\n",
      "Batch 135, Loss: 1.5879\n",
      "Batch 136, Loss: 1.6062\n",
      "Batch 137, Loss: 1.5938\n",
      "Batch 138, Loss: 1.6063\n",
      "Batch 139, Loss: 1.6025\n",
      "Batch 140, Loss: 1.5890\n",
      "Batch 141, Loss: 1.6036\n",
      "Batch 142, Loss: 1.5997\n",
      "Batch 143, Loss: 1.6043\n",
      "Batch 144, Loss: 1.5896\n",
      "Batch 145, Loss: 1.5887\n",
      "Batch 146, Loss: 1.5980\n",
      "Batch 147, Loss: 1.5954\n",
      "Batch 148, Loss: 1.6133\n",
      "Batch 149, Loss: 1.6033\n",
      "Batch 150, Loss: 1.5812\n",
      "Batch 151, Loss: 1.6019\n",
      "Batch 152, Loss: 1.6193\n",
      "Batch 153, Loss: 1.6116\n",
      "Batch 154, Loss: 1.6022\n",
      "Batch 155, Loss: 1.6165\n",
      "Batch 156, Loss: 1.6079\n",
      "Batch 157, Loss: 1.6007\n",
      "Batch 158, Loss: 1.6048\n",
      "Batch 159, Loss: 1.6274\n",
      "Batch 160, Loss: 1.5972\n",
      "Batch 161, Loss: 1.6211\n",
      "Batch 162, Loss: 1.5827\n",
      "Batch 163, Loss: 1.5925\n",
      "Batch 164, Loss: 1.6075\n",
      "Batch 165, Loss: 1.6181\n",
      "Batch 166, Loss: 1.6089\n",
      "Batch 167, Loss: 1.6004\n",
      "Batch 168, Loss: 1.5962\n",
      "Batch 169, Loss: 1.5912\n",
      "Batch 170, Loss: 1.6061\n",
      "Batch 171, Loss: 1.6014\n",
      "Batch 172, Loss: 1.6360\n",
      "Batch 173, Loss: 1.6177\n",
      "Batch 174, Loss: 1.6192\n",
      "Batch 175, Loss: 1.6160\n",
      "Batch 176, Loss: 1.6383\n",
      "Batch 177, Loss: 1.5808\n",
      "Batch 178, Loss: 1.6119\n",
      "Batch 179, Loss: 1.6027\n",
      "Batch 180, Loss: 1.5706\n",
      "Batch 181, Loss: 1.6140\n",
      "Batch 182, Loss: 1.5939\n",
      "Batch 183, Loss: 1.5927\n",
      "Batch 184, Loss: 1.6310\n",
      "Batch 185, Loss: 1.5850\n",
      "Batch 186, Loss: 1.5906\n",
      "Batch 187, Loss: 1.6047\n",
      "Batch 188, Loss: 1.6094\n",
      "Batch 189, Loss: 1.5963\n",
      "Batch 190, Loss: 1.6180\n",
      "Batch 191, Loss: 1.5719\n",
      "Batch 192, Loss: 1.5839\n",
      "Batch 193, Loss: 1.5819\n",
      "Batch 194, Loss: 1.6205\n",
      "Batch 195, Loss: 1.6122\n",
      "Batch 196, Loss: 1.5796\n",
      "Batch 197, Loss: 1.5984\n",
      "Batch 198, Loss: 1.6144\n",
      "Batch 199, Loss: 1.5726\n",
      "Batch 200, Loss: 1.6104\n",
      "Batch 201, Loss: 1.6105\n",
      "Batch 202, Loss: 1.5973\n",
      "Batch 203, Loss: 1.6067\n",
      "Batch 204, Loss: 1.5904\n",
      "Batch 205, Loss: 1.6277\n",
      "Batch 206, Loss: 1.6373\n",
      "Batch 207, Loss: 1.5807\n",
      "Batch 208, Loss: 1.5975\n",
      "Batch 209, Loss: 1.5830\n",
      "Batch 210, Loss: 1.5777\n",
      "Batch 211, Loss: 1.6059\n",
      "Batch 212, Loss: 1.5842\n",
      "Batch 213, Loss: 1.6024\n",
      "Batch 214, Loss: 1.6016\n",
      "Batch 215, Loss: 1.6133\n",
      "Batch 216, Loss: 1.6166\n",
      "Batch 217, Loss: 1.5859\n",
      "Batch 218, Loss: 1.5720\n",
      "Batch 219, Loss: 1.5915\n",
      "Batch 220, Loss: 1.5842\n",
      "Batch 221, Loss: 1.5920\n",
      "Batch 222, Loss: 1.5786\n",
      "Batch 223, Loss: 1.5928\n",
      "Batch 224, Loss: 1.5944\n",
      "Batch 225, Loss: 1.6014\n",
      "Batch 226, Loss: 1.5804\n",
      "Batch 227, Loss: 1.5912\n",
      "Batch 228, Loss: 1.6046\n",
      "Batch 229, Loss: 1.6200\n",
      "Batch 230, Loss: 1.5658\n",
      "Batch 231, Loss: 1.5983\n",
      "Batch 232, Loss: 1.6305\n",
      "Batch 233, Loss: 1.6211\n",
      "Batch 234, Loss: 1.5832\n",
      "Batch 235, Loss: 1.6184\n",
      "Batch 236, Loss: 1.5874\n",
      "Batch 237, Loss: 1.5986\n",
      "Batch 238, Loss: 1.6036\n",
      "Batch 239, Loss: 1.5723\n",
      "Batch 240, Loss: 1.6118\n",
      "Batch 241, Loss: 1.6156\n",
      "Batch 242, Loss: 1.5955\n",
      "Batch 243, Loss: 1.6025\n",
      "Batch 244, Loss: 1.6079\n",
      "Batch 245, Loss: 1.6034\n",
      "Batch 246, Loss: 1.5856\n",
      "Batch 247, Loss: 1.5946\n",
      "Batch 248, Loss: 1.6134\n",
      "Batch 249, Loss: 1.5979\n",
      "Batch 250, Loss: 1.5823\n",
      "Batch 251, Loss: 1.5930\n",
      "Batch 252, Loss: 1.5943\n",
      "Batch 253, Loss: 1.6148\n",
      "Batch 254, Loss: 1.6355\n",
      "Batch 255, Loss: 1.5778\n",
      "Batch 256, Loss: 1.5929\n",
      "Batch 257, Loss: 1.5983\n",
      "Batch 258, Loss: 1.5934\n",
      "Batch 259, Loss: 1.5845\n",
      "Batch 260, Loss: 1.5974\n",
      "Batch 261, Loss: 1.6052\n",
      "Batch 262, Loss: 1.5709\n",
      "Batch 263, Loss: 1.5906\n",
      "Batch 264, Loss: 1.6169\n",
      "Batch 265, Loss: 1.6291\n",
      "Batch 266, Loss: 1.5688\n",
      "Batch 267, Loss: 1.5916\n",
      "Batch 268, Loss: 1.6012\n",
      "Batch 269, Loss: 1.5576\n",
      "Batch 270, Loss: 1.6039\n",
      "Batch 271, Loss: 1.5877\n",
      "Batch 272, Loss: 1.5905\n",
      "Batch 273, Loss: 1.6091\n",
      "Batch 274, Loss: 1.6013\n",
      "Batch 275, Loss: 1.5836\n",
      "Batch 276, Loss: 1.6136\n",
      "Batch 277, Loss: 1.5952\n",
      "Batch 278, Loss: 1.6254\n",
      "Batch 279, Loss: 1.5999\n",
      "Batch 280, Loss: 1.6128\n",
      "Batch 281, Loss: 1.5748\n",
      "Batch 282, Loss: 1.5902\n",
      "Batch 283, Loss: 1.5998\n",
      "Batch 284, Loss: 1.5857\n",
      "Batch 285, Loss: 1.5959\n",
      "Batch 286, Loss: 1.6087\n",
      "Batch 287, Loss: 1.6119\n",
      "Batch 288, Loss: 1.6054\n",
      "Batch 289, Loss: 1.5628\n",
      "Batch 290, Loss: 1.5781\n",
      "Batch 291, Loss: 1.6124\n",
      "Batch 292, Loss: 1.5939\n",
      "Batch 293, Loss: 1.5731\n",
      "Batch 294, Loss: 1.5754\n",
      "Batch 295, Loss: 1.6079\n",
      "Batch 296, Loss: 1.6128\n",
      "Batch 297, Loss: 1.5910\n",
      "Batch 298, Loss: 1.6074\n",
      "Batch 299, Loss: 1.5944\n",
      "Batch 300, Loss: 1.6210\n",
      "Batch 301, Loss: 1.5991\n",
      "Batch 302, Loss: 1.5954\n",
      "Batch 303, Loss: 1.6180\n",
      "Batch 304, Loss: 1.5788\n",
      "Batch 305, Loss: 1.6109\n",
      "Batch 306, Loss: 1.6402\n",
      "Batch 307, Loss: 1.5977\n",
      "Batch 308, Loss: 1.6012\n",
      "Batch 309, Loss: 1.6185\n",
      "Batch 310, Loss: 1.5925\n",
      "Batch 311, Loss: 1.5898\n",
      "Batch 312, Loss: 1.6035\n",
      "Batch 313, Loss: 1.5681\n",
      "Batch 314, Loss: 1.5822\n",
      "Batch 315, Loss: 1.5907\n",
      "Batch 316, Loss: 1.5849\n",
      "Batch 317, Loss: 1.5724\n",
      "Batch 318, Loss: 1.6028\n",
      "Batch 319, Loss: 1.6029\n",
      "Batch 320, Loss: 1.5923\n",
      "Batch 321, Loss: 1.5869\n",
      "Batch 322, Loss: 1.6063\n",
      "Batch 323, Loss: 1.6105\n",
      "Batch 324, Loss: 1.6077\n",
      "Batch 325, Loss: 1.5761\n",
      "Batch 326, Loss: 1.6187\n",
      "Batch 327, Loss: 1.5833\n",
      "Batch 328, Loss: 1.5941\n",
      "Batch 329, Loss: 1.6187\n",
      "Batch 330, Loss: 1.5831\n",
      "Batch 331, Loss: 1.5697\n",
      "Batch 332, Loss: 1.6191\n",
      "Batch 333, Loss: 1.5914\n",
      "Batch 334, Loss: 1.5943\n",
      "Batch 335, Loss: 1.5858\n",
      "Batch 336, Loss: 1.5977\n",
      "Batch 337, Loss: 1.6133\n",
      "Batch 338, Loss: 1.5858\n",
      "Batch 339, Loss: 1.6107\n",
      "Batch 340, Loss: 1.5765\n",
      "Batch 341, Loss: 1.5880\n",
      "Batch 342, Loss: 1.5679\n",
      "Batch 343, Loss: 1.6026\n",
      "Batch 344, Loss: 1.5848\n",
      "Batch 345, Loss: 1.5880\n",
      "Batch 346, Loss: 1.5739\n",
      "Batch 347, Loss: 1.5877\n",
      "Batch 348, Loss: 1.6083\n",
      "Batch 349, Loss: 1.6198\n",
      "Batch 350, Loss: 1.5944\n",
      "Batch 351, Loss: 1.5871\n",
      "Batch 352, Loss: 1.5871\n",
      "Batch 353, Loss: 1.5939\n",
      "Batch 354, Loss: 1.5979\n",
      "Batch 355, Loss: 1.6173\n",
      "Batch 356, Loss: 1.6046\n",
      "Batch 357, Loss: 1.5820\n",
      "Batch 358, Loss: 1.5703\n",
      "Batch 359, Loss: 1.5747\n",
      "Batch 360, Loss: 1.5885\n",
      "Batch 361, Loss: 1.5754\n",
      "Batch 362, Loss: 1.5747\n",
      "Batch 363, Loss: 1.5639\n",
      "Batch 364, Loss: 1.6193\n",
      "Batch 365, Loss: 1.5803\n",
      "Batch 366, Loss: 1.6076\n",
      "Batch 367, Loss: 1.5817\n",
      "Batch 368, Loss: 1.5536\n",
      "Batch 369, Loss: 1.6022\n",
      "Batch 370, Loss: 1.5802\n",
      "Batch 371, Loss: 1.5666\n",
      "Batch 372, Loss: 1.5486\n",
      "Batch 373, Loss: 1.5877\n",
      "Batch 374, Loss: 1.5767\n",
      "Batch 375, Loss: 1.6008\n",
      "Batch 376, Loss: 1.5787\n",
      "Batch 377, Loss: 1.6043\n",
      "Batch 378, Loss: 1.5697\n",
      "Batch 379, Loss: 1.6143\n",
      "Batch 380, Loss: 1.6101\n",
      "Batch 381, Loss: 1.5683\n",
      "Batch 382, Loss: 1.6172\n",
      "Batch 383, Loss: 1.5807\n",
      "Batch 384, Loss: 1.5790\n",
      "Batch 385, Loss: 1.5937\n",
      "Batch 386, Loss: 1.5936\n",
      "Batch 387, Loss: 1.5860\n",
      "Batch 388, Loss: 1.6091\n",
      "Batch 389, Loss: 1.5830\n",
      "Batch 390, Loss: 1.5932\n",
      "Batch 391, Loss: 1.5945\n",
      "Batch 392, Loss: 1.5753\n",
      "Batch 393, Loss: 1.5630\n",
      "Batch 394, Loss: 1.5722\n",
      "Batch 395, Loss: 1.6159\n",
      "Batch 396, Loss: 1.5542\n",
      "Batch 397, Loss: 1.5963\n",
      "Batch 398, Loss: 1.5795\n",
      "Batch 399, Loss: 1.5540\n",
      "Batch 400, Loss: 1.5751\n",
      "Batch 401, Loss: 1.5538\n",
      "Batch 402, Loss: 1.5780\n",
      "Batch 403, Loss: 1.5910\n",
      "Batch 404, Loss: 1.5860\n",
      "Batch 405, Loss: 1.5840\n",
      "Batch 406, Loss: 1.6099\n",
      "Batch 407, Loss: 1.5743\n",
      "Batch 408, Loss: 1.6143\n",
      "Batch 409, Loss: 1.6049\n",
      "Batch 410, Loss: 1.6036\n",
      "Batch 411, Loss: 1.5784\n",
      "Batch 412, Loss: 1.5900\n",
      "Batch 413, Loss: 1.5755\n",
      "Batch 414, Loss: 1.5750\n",
      "Batch 415, Loss: 1.5790\n",
      "Batch 416, Loss: 1.5930\n",
      "Batch 417, Loss: 1.5917\n",
      "Batch 418, Loss: 1.5769\n",
      "Batch 419, Loss: 1.5775\n",
      "Batch 420, Loss: 1.5786\n",
      "Batch 421, Loss: 1.6046\n",
      "Batch 422, Loss: 1.5833\n",
      "Batch 423, Loss: 1.5924\n",
      "Batch 424, Loss: 1.5991\n",
      "Batch 425, Loss: 1.6111\n",
      "Batch 426, Loss: 1.5705\n",
      "Batch 427, Loss: 1.5710\n",
      "Batch 428, Loss: 1.5960\n",
      "Batch 429, Loss: 1.6020\n",
      "Batch 430, Loss: 1.6147\n",
      "Batch 431, Loss: 1.5663\n",
      "Batch 432, Loss: 1.5836\n",
      "Batch 433, Loss: 1.6262\n",
      "Batch 434, Loss: 1.5840\n",
      "Batch 435, Loss: 1.6019\n",
      "Batch 436, Loss: 1.5806\n",
      "Batch 437, Loss: 1.5809\n",
      "Batch 438, Loss: 1.5860\n",
      "Batch 439, Loss: 1.5829\n",
      "Batch 440, Loss: 1.5991\n",
      "Batch 441, Loss: 1.5986\n",
      "Batch 442, Loss: 1.5575\n",
      "Batch 443, Loss: 1.5954\n",
      "Batch 444, Loss: 1.5762\n",
      "Batch 445, Loss: 1.5866\n",
      "Batch 446, Loss: 1.5906\n",
      "Batch 447, Loss: 1.5736\n",
      "Batch 448, Loss: 1.5662\n",
      "Batch 449, Loss: 1.5917\n",
      "Batch 450, Loss: 1.5872\n",
      "Batch 451, Loss: 1.5711\n",
      "Batch 452, Loss: 1.6116\n",
      "Batch 453, Loss: 1.5709\n",
      "Batch 454, Loss: 1.5831\n",
      "Batch 455, Loss: 1.5869\n",
      "Batch 456, Loss: 1.5582\n",
      "Batch 457, Loss: 1.5854\n",
      "Batch 458, Loss: 1.5904\n",
      "Batch 459, Loss: 1.5767\n",
      "Batch 460, Loss: 1.5821\n",
      "Batch 461, Loss: 1.5659\n",
      "Batch 462, Loss: 1.5786\n",
      "Batch 463, Loss: 1.5645\n",
      "Batch 464, Loss: 1.5852\n",
      "Batch 465, Loss: 1.5783\n",
      "Batch 466, Loss: 1.5852\n",
      "Batch 467, Loss: 1.5833\n",
      "Batch 468, Loss: 1.5952\n",
      "Batch 469, Loss: 1.5856\n",
      "Batch 470, Loss: 1.5842\n",
      "Batch 471, Loss: 1.5525\n",
      "Batch 472, Loss: 1.5668\n",
      "Batch 473, Loss: 1.5839\n",
      "Batch 474, Loss: 1.6124\n",
      "Batch 475, Loss: 1.5654\n",
      "Batch 476, Loss: 1.5817\n",
      "Batch 477, Loss: 1.5758\n",
      "Batch 478, Loss: 1.5777\n",
      "Batch 479, Loss: 1.5913\n",
      "Batch 480, Loss: 1.5456\n",
      "Batch 481, Loss: 1.5616\n",
      "Batch 482, Loss: 1.5738\n",
      "Batch 483, Loss: 1.5855\n",
      "Once upon a time, there was a little boy named Timmy. Timmy loved to play on the snowsill. He sang a song every day with \n",
      "many other kids and boys. One day, Timmy and his mom went to the park to play. They had so much fun. Timmy's mom saw \n",
      "the snowflace because he happened with yummy snow. She asked the snow, \"Where are we going in the snow?\" The snow didn't hear him. Timmy \n",
      "was so happy in his bag, he felt louder and large again. From that day on, Timmy remembered visit his friend their home, Sarah and \n",
      "her bag stopped playing with the snowflace. Sarah fell asleep white carrying the great days of a snowman Ja. The snowmann her thought it was \n",
      "so cool to go fast and got terrible. Timmy was so happy that he proudly could let on his friend's snowman come trust her friends. \n",
      "He remembered how happy things he had found the snowman always comfortable grew and people lesson but he knew he could always be remembered to \n",
      "keep his snowmant on his favorite side. \n",
      "\n",
      "--------------------\n",
      "Batch 484, Loss: 1.5612\n",
      "Batch 485, Loss: 1.6143\n",
      "Batch 486, Loss: 1.5641\n",
      "Batch 487, Loss: 1.5710\n",
      "Batch 488, Loss: 1.5748\n",
      "Batch 489, Loss: 1.5898\n",
      "Batch 490, Loss: 1.5595\n",
      "Batch 491, Loss: 1.5582\n",
      "Batch 492, Loss: 1.5991\n",
      "Batch 493, Loss: 1.5848\n",
      "Batch 494, Loss: 1.5735\n",
      "Batch 495, Loss: 1.5757\n",
      "Batch 496, Loss: 1.5824\n",
      "Batch 497, Loss: 1.5692\n",
      "Batch 498, Loss: 1.5920\n",
      "Batch 499, Loss: 1.5797\n",
      "Batch 500, Loss: 1.5494\n",
      "Batch 501, Loss: 1.5765\n",
      "Batch 502, Loss: 1.5427\n",
      "Batch 503, Loss: 1.5587\n",
      "Batch 504, Loss: 1.5845\n",
      "Batch 505, Loss: 1.6068\n",
      "Batch 506, Loss: 1.5738\n",
      "Batch 507, Loss: 1.5734\n",
      "Batch 508, Loss: 1.5675\n",
      "Batch 509, Loss: 1.5810\n",
      "Batch 510, Loss: 1.5549\n",
      "Batch 511, Loss: 1.6020\n",
      "Batch 512, Loss: 1.5749\n",
      "Batch 513, Loss: 1.6134\n",
      "Batch 514, Loss: 1.5819\n",
      "Batch 515, Loss: 1.5801\n",
      "Batch 516, Loss: 1.5973\n",
      "Batch 517, Loss: 1.5972\n",
      "Batch 518, Loss: 1.5949\n",
      "Batch 519, Loss: 1.5809\n",
      "Batch 520, Loss: 1.5684\n",
      "Batch 521, Loss: 1.5631\n",
      "Batch 522, Loss: 1.5892\n",
      "Batch 523, Loss: 1.5961\n",
      "Batch 524, Loss: 1.5580\n",
      "Batch 525, Loss: 1.5761\n",
      "Batch 526, Loss: 1.5536\n",
      "Batch 527, Loss: 1.5934\n",
      "Batch 528, Loss: 1.5857\n",
      "Batch 529, Loss: 1.5787\n",
      "Batch 530, Loss: 1.5581\n",
      "Batch 531, Loss: 1.5862\n",
      "Batch 532, Loss: 1.5969\n",
      "Batch 533, Loss: 1.5870\n",
      "Batch 534, Loss: 1.5848\n",
      "Batch 535, Loss: 1.5347\n",
      "Batch 536, Loss: 1.5655\n",
      "Batch 537, Loss: 1.5539\n",
      "Batch 538, Loss: 1.5609\n",
      "Batch 539, Loss: 1.5751\n",
      "Batch 540, Loss: 1.5365\n",
      "Batch 541, Loss: 1.5603\n",
      "Batch 542, Loss: 1.5844\n",
      "Batch 543, Loss: 1.5759\n",
      "Batch 544, Loss: 1.6075\n",
      "Batch 545, Loss: 1.5690\n",
      "Batch 546, Loss: 1.5753\n",
      "Batch 547, Loss: 1.6049\n",
      "Batch 548, Loss: 1.5580\n",
      "Batch 549, Loss: 1.5822\n",
      "Batch 550, Loss: 1.5542\n",
      "Batch 551, Loss: 1.5819\n",
      "Batch 552, Loss: 1.5480\n",
      "Batch 553, Loss: 1.5844\n",
      "Batch 554, Loss: 1.5407\n",
      "Batch 555, Loss: 1.5770\n",
      "Batch 556, Loss: 1.5563\n",
      "Batch 557, Loss: 1.5827\n",
      "Batch 558, Loss: 1.5808\n",
      "Batch 559, Loss: 1.5985\n",
      "Batch 560, Loss: 1.5698\n",
      "Batch 561, Loss: 1.5512\n",
      "Batch 562, Loss: 1.5657\n",
      "Batch 563, Loss: 1.5890\n",
      "Batch 564, Loss: 1.5880\n",
      "Batch 565, Loss: 1.6040\n",
      "Batch 566, Loss: 1.5609\n",
      "Batch 567, Loss: 1.5734\n",
      "Batch 568, Loss: 1.5843\n",
      "Batch 569, Loss: 1.5808\n",
      "Batch 570, Loss: 1.5946\n",
      "Batch 571, Loss: 1.5922\n",
      "Batch 572, Loss: 1.5890\n",
      "Batch 573, Loss: 1.5660\n",
      "Batch 574, Loss: 1.5625\n",
      "Batch 575, Loss: 1.5759\n",
      "Batch 576, Loss: 1.5511\n",
      "Batch 577, Loss: 1.5895\n",
      "Batch 578, Loss: 1.5673\n",
      "Batch 579, Loss: 1.5500\n",
      "Batch 580, Loss: 1.5589\n",
      "Batch 581, Loss: 1.5848\n",
      "Batch 582, Loss: 1.5803\n",
      "Batch 583, Loss: 1.5947\n",
      "Batch 584, Loss: 1.5767\n",
      "Batch 585, Loss: 1.6022\n",
      "Batch 586, Loss: 1.5829\n",
      "Batch 587, Loss: 1.5857\n",
      "Batch 588, Loss: 1.5865\n",
      "Batch 589, Loss: 1.5586\n",
      "Batch 590, Loss: 1.5595\n",
      "Batch 591, Loss: 1.6047\n",
      "Batch 592, Loss: 1.5831\n",
      "Batch 593, Loss: 1.5632\n",
      "Batch 594, Loss: 1.5938\n",
      "Batch 595, Loss: 1.5804\n",
      "Batch 596, Loss: 1.5529\n",
      "Batch 597, Loss: 1.5181\n",
      "Batch 598, Loss: 1.5829\n",
      "Batch 599, Loss: 1.5774\n",
      "Batch 600, Loss: 1.5656\n",
      "Batch 601, Loss: 1.5879\n",
      "Batch 602, Loss: 1.5850\n",
      "Batch 603, Loss: 1.5687\n",
      "Batch 604, Loss: 1.5541\n",
      "Batch 605, Loss: 1.5470\n",
      "Batch 606, Loss: 1.5596\n",
      "Batch 607, Loss: 1.5951\n",
      "Batch 608, Loss: 1.5651\n",
      "Batch 609, Loss: 1.5769\n",
      "Batch 610, Loss: 1.5665\n",
      "Batch 611, Loss: 1.5775\n",
      "Batch 612, Loss: 1.5814\n",
      "Batch 613, Loss: 1.5667\n",
      "Batch 614, Loss: 1.5751\n",
      "Batch 615, Loss: 1.6008\n",
      "Batch 616, Loss: 1.5603\n",
      "Batch 617, Loss: 1.6007\n",
      "Batch 618, Loss: 1.5659\n",
      "Batch 619, Loss: 1.5629\n",
      "Batch 620, Loss: 1.5577\n",
      "Batch 621, Loss: 1.5610\n",
      "Batch 622, Loss: 1.5992\n",
      "Batch 623, Loss: 1.5882\n",
      "Batch 624, Loss: 1.5617\n",
      "Batch 625, Loss: 1.5707\n",
      "Batch 626, Loss: 1.5317\n",
      "Batch 627, Loss: 1.5867\n",
      "Batch 628, Loss: 1.5621\n",
      "Batch 629, Loss: 1.5701\n",
      "Batch 630, Loss: 1.5524\n",
      "Batch 631, Loss: 1.5543\n",
      "Batch 632, Loss: 1.5778\n",
      "Batch 633, Loss: 1.5776\n",
      "Batch 634, Loss: 1.5923\n",
      "Batch 635, Loss: 1.5804\n",
      "Batch 636, Loss: 1.5746\n",
      "Batch 637, Loss: 1.5638\n",
      "Batch 638, Loss: 1.5725\n",
      "Batch 639, Loss: 1.6026\n",
      "Batch 640, Loss: 1.5773\n",
      "Batch 641, Loss: 1.5404\n",
      "Batch 642, Loss: 1.5529\n",
      "Batch 643, Loss: 1.5678\n",
      "Batch 644, Loss: 1.5916\n",
      "Batch 645, Loss: 1.5626\n",
      "Batch 646, Loss: 1.5836\n",
      "Batch 647, Loss: 1.5569\n",
      "Batch 648, Loss: 1.5868\n",
      "Batch 649, Loss: 1.5472\n",
      "Batch 650, Loss: 1.5883\n",
      "Batch 651, Loss: 1.5464\n",
      "Batch 652, Loss: 1.5626\n",
      "Batch 653, Loss: 1.5500\n",
      "Batch 654, Loss: 1.5744\n",
      "Batch 655, Loss: 1.5762\n",
      "Batch 656, Loss: 1.5687\n",
      "Batch 657, Loss: 1.5735\n",
      "Batch 658, Loss: 1.5545\n",
      "Batch 659, Loss: 1.6067\n",
      "Batch 660, Loss: 1.5730\n",
      "Batch 661, Loss: 1.5498\n",
      "Batch 662, Loss: 1.5753\n",
      "Batch 663, Loss: 1.5764\n",
      "Batch 664, Loss: 1.5672\n",
      "Batch 665, Loss: 1.5721\n",
      "Batch 666, Loss: 1.5385\n",
      "Batch 667, Loss: 1.5745\n",
      "Batch 668, Loss: 1.5537\n",
      "Batch 669, Loss: 1.5625\n",
      "Batch 670, Loss: 1.5565\n",
      "Batch 671, Loss: 1.5790\n",
      "Batch 672, Loss: 1.5593\n",
      "Batch 673, Loss: 1.5751\n",
      "Batch 674, Loss: 1.5731\n",
      "Batch 675, Loss: 1.5370\n",
      "Batch 676, Loss: 1.5701\n",
      "Batch 677, Loss: 1.5749\n",
      "Batch 678, Loss: 1.5414\n",
      "Batch 679, Loss: 1.5787\n",
      "Batch 680, Loss: 1.5643\n",
      "Batch 681, Loss: 1.5887\n",
      "Batch 682, Loss: 1.5704\n",
      "Batch 683, Loss: 1.5632\n",
      "Batch 684, Loss: 1.5841\n",
      "Batch 685, Loss: 1.6040\n",
      "Batch 686, Loss: 1.5684\n",
      "Batch 687, Loss: 1.5602\n",
      "Batch 688, Loss: 1.5591\n",
      "Batch 689, Loss: 1.5353\n",
      "Batch 690, Loss: 1.5309\n",
      "Batch 691, Loss: 1.5603\n",
      "Batch 692, Loss: 1.5863\n",
      "Batch 693, Loss: 1.5661\n",
      "Batch 694, Loss: 1.5666\n",
      "Batch 695, Loss: 1.5508\n",
      "Batch 696, Loss: 1.5652\n",
      "Batch 697, Loss: 1.5796\n",
      "Batch 698, Loss: 1.5851\n",
      "Batch 699, Loss: 1.5656\n",
      "Batch 700, Loss: 1.5776\n",
      "Batch 701, Loss: 1.5534\n",
      "Batch 702, Loss: 1.5765\n",
      "Batch 703, Loss: 1.5838\n",
      "Batch 704, Loss: 1.5580\n",
      "Batch 705, Loss: 1.5800\n",
      "Batch 706, Loss: 1.5782\n",
      "Batch 707, Loss: 1.5520\n",
      "Batch 708, Loss: 1.5432\n",
      "Batch 709, Loss: 1.5751\n",
      "Batch 710, Loss: 1.5813\n",
      "Batch 711, Loss: 1.5764\n",
      "Batch 712, Loss: 1.5743\n",
      "Batch 713, Loss: 1.5595\n",
      "Batch 714, Loss: 1.5692\n",
      "Batch 715, Loss: 1.5585\n",
      "Batch 716, Loss: 1.5520\n",
      "Batch 717, Loss: 1.5479\n",
      "Batch 718, Loss: 1.5663\n",
      "Batch 719, Loss: 1.5769\n",
      "Batch 720, Loss: 1.5636\n",
      "Batch 721, Loss: 1.5675\n",
      "Batch 722, Loss: 1.5797\n",
      "Batch 723, Loss: 1.5595\n",
      "Batch 724, Loss: 1.5596\n",
      "Batch 725, Loss: 1.5571\n",
      "Batch 726, Loss: 1.5714\n",
      "Batch 727, Loss: 1.5470\n",
      "Batch 728, Loss: 1.5807\n",
      "Batch 729, Loss: 1.5632\n",
      "Batch 730, Loss: 1.5367\n",
      "Batch 731, Loss: 1.5567\n",
      "Batch 732, Loss: 1.5984\n",
      "Batch 733, Loss: 1.5781\n",
      "Batch 734, Loss: 1.5883\n",
      "Batch 735, Loss: 1.5657\n",
      "Batch 736, Loss: 1.5324\n",
      "Batch 737, Loss: 1.6006\n",
      "Batch 738, Loss: 1.5607\n",
      "Batch 739, Loss: 1.5848\n",
      "Batch 740, Loss: 1.5593\n",
      "Batch 741, Loss: 1.5627\n",
      "Batch 742, Loss: 1.5589\n",
      "Batch 743, Loss: 1.5813\n",
      "Batch 744, Loss: 1.5648\n",
      "Batch 745, Loss: 1.5939\n",
      "Batch 746, Loss: 1.5473\n",
      "Batch 747, Loss: 1.5257\n",
      "Batch 748, Loss: 1.5882\n",
      "Batch 749, Loss: 1.5590\n",
      "Batch 750, Loss: 1.5889\n",
      "Batch 751, Loss: 1.5829\n",
      "Batch 752, Loss: 1.5838\n",
      "Batch 753, Loss: 1.5694\n",
      "Batch 754, Loss: 1.5763\n",
      "Batch 755, Loss: 1.5347\n",
      "Batch 756, Loss: 1.5605\n",
      "Batch 757, Loss: 1.5834\n",
      "Batch 758, Loss: 1.5762\n",
      "Batch 759, Loss: 1.5437\n",
      "Batch 760, Loss: 1.5646\n",
      "Batch 761, Loss: 1.5410\n",
      "Batch 762, Loss: 1.5175\n",
      "Batch 763, Loss: 1.5613\n",
      "Batch 764, Loss: 1.5507\n",
      "Batch 765, Loss: 1.5203\n",
      "Batch 766, Loss: 1.5769\n",
      "Batch 767, Loss: 1.5656\n",
      "Batch 768, Loss: 1.5766\n",
      "Batch 769, Loss: 1.5368\n",
      "Batch 770, Loss: 1.5381\n",
      "Batch 771, Loss: 1.5660\n",
      "Batch 772, Loss: 1.5667\n",
      "Batch 773, Loss: 1.5645\n",
      "Batch 774, Loss: 1.5663\n",
      "Batch 775, Loss: 1.5502\n",
      "Batch 776, Loss: 1.5774\n",
      "Batch 777, Loss: 1.5838\n",
      "Batch 778, Loss: 1.5626\n",
      "Batch 779, Loss: 1.5426\n",
      "Batch 780, Loss: 1.5600\n",
      "Batch 781, Loss: 1.5624\n",
      "Batch 782, Loss: 1.5466\n",
      "Batch 783, Loss: 1.5856\n",
      "Batch 784, Loss: 1.5562\n",
      "Batch 785, Loss: 1.5530\n",
      "Batch 786, Loss: 1.5575\n",
      "Batch 787, Loss: 1.5734\n",
      "Batch 788, Loss: 1.5202\n",
      "Batch 789, Loss: 1.5931\n",
      "Batch 790, Loss: 1.5882\n",
      "Batch 791, Loss: 1.5575\n",
      "Batch 792, Loss: 1.5450\n",
      "Batch 793, Loss: 1.5577\n",
      "Batch 794, Loss: 1.5628\n",
      "Batch 795, Loss: 1.5472\n",
      "Batch 796, Loss: 1.5549\n",
      "Batch 797, Loss: 1.5478\n",
      "Batch 798, Loss: 1.5426\n",
      "Batch 799, Loss: 1.5509\n",
      "Batch 800, Loss: 1.5539\n",
      "Batch 801, Loss: 1.5548\n",
      "Batch 802, Loss: 1.5449\n",
      "Batch 803, Loss: 1.5651\n",
      "Batch 804, Loss: 1.5633\n",
      "Batch 805, Loss: 1.5427\n",
      "Batch 806, Loss: 1.5501\n",
      "Batch 807, Loss: 1.5452\n",
      "Batch 808, Loss: 1.5655\n",
      "Batch 809, Loss: 1.5348\n",
      "Batch 810, Loss: 1.5751\n",
      "Batch 811, Loss: 1.5800\n",
      "Batch 812, Loss: 1.5688\n",
      "Batch 813, Loss: 1.5665\n",
      "Batch 814, Loss: 1.5522\n",
      "Batch 815, Loss: 1.5375\n",
      "Batch 816, Loss: 1.5578\n",
      "Batch 817, Loss: 1.5424\n",
      "Batch 818, Loss: 1.5499\n",
      "Batch 819, Loss: 1.5575\n",
      "Batch 820, Loss: 1.5760\n",
      "Batch 821, Loss: 1.5374\n",
      "Batch 822, Loss: 1.5356\n",
      "Batch 823, Loss: 1.5540\n",
      "Batch 824, Loss: 1.5514\n",
      "Batch 825, Loss: 1.5755\n",
      "Batch 826, Loss: 1.5467\n",
      "Batch 827, Loss: 1.5609\n",
      "Batch 828, Loss: 1.5742\n",
      "Batch 829, Loss: 1.5370\n",
      "Batch 830, Loss: 1.5612\n",
      "Batch 831, Loss: 1.5781\n",
      "Batch 832, Loss: 1.5585\n",
      "Batch 833, Loss: 1.5214\n",
      "Batch 834, Loss: 1.5285\n",
      "Batch 835, Loss: 1.5554\n",
      "Batch 836, Loss: 1.5533\n",
      "Batch 837, Loss: 1.5545\n",
      "Batch 838, Loss: 1.5601\n",
      "Batch 839, Loss: 1.5287\n",
      "Batch 840, Loss: 1.5622\n",
      "Batch 841, Loss: 1.5710\n",
      "Batch 842, Loss: 1.5708\n",
      "Batch 843, Loss: 1.5606\n",
      "Batch 844, Loss: 1.5672\n",
      "Batch 845, Loss: 1.5316\n",
      "Batch 846, Loss: 1.5642\n",
      "Batch 847, Loss: 1.5334\n",
      "Batch 848, Loss: 1.5752\n",
      "Batch 849, Loss: 1.5782\n",
      "Batch 850, Loss: 1.5634\n",
      "Batch 851, Loss: 1.5800\n",
      "Batch 852, Loss: 1.5515\n",
      "Batch 853, Loss: 1.5823\n",
      "Batch 854, Loss: 1.5620\n",
      "Batch 855, Loss: 1.5769\n",
      "Batch 856, Loss: 1.5875\n",
      "Batch 857, Loss: 1.5564\n",
      "Batch 858, Loss: 1.5374\n",
      "Batch 859, Loss: 1.5514\n",
      "Batch 860, Loss: 1.5569\n",
      "Batch 861, Loss: 1.5362\n",
      "Batch 862, Loss: 1.5520\n",
      "Batch 863, Loss: 1.5263\n",
      "Batch 864, Loss: 1.5529\n",
      "Batch 865, Loss: 1.5610\n",
      "Batch 866, Loss: 1.5544\n",
      "Batch 867, Loss: 1.5584\n",
      "Batch 868, Loss: 1.5645\n",
      "Batch 869, Loss: 1.5727\n",
      "Batch 870, Loss: 1.5711\n",
      "Batch 871, Loss: 1.5367\n",
      "Batch 872, Loss: 1.5686\n",
      "Batch 873, Loss: 1.5567\n",
      "Batch 874, Loss: 1.5242\n",
      "Batch 875, Loss: 1.5678\n",
      "Batch 876, Loss: 1.5619\n",
      "Batch 877, Loss: 1.5384\n",
      "Batch 878, Loss: 1.5476\n",
      "Batch 879, Loss: 1.5691\n",
      "Batch 880, Loss: 1.5478\n",
      "Batch 881, Loss: 1.5497\n",
      "Batch 882, Loss: 1.5485\n",
      "Batch 883, Loss: 1.5459\n",
      "Batch 884, Loss: 1.5472\n",
      "Batch 885, Loss: 1.5695\n",
      "Batch 886, Loss: 1.5206\n",
      "Batch 887, Loss: 1.5545\n",
      "Batch 888, Loss: 1.5485\n",
      "Batch 889, Loss: 1.5348\n",
      "Batch 890, Loss: 1.5142\n",
      "Batch 891, Loss: 1.5434\n",
      "Batch 892, Loss: 1.5489\n",
      "Batch 893, Loss: 1.5773\n",
      "Batch 894, Loss: 1.5205\n",
      "Batch 895, Loss: 1.5635\n",
      "Batch 896, Loss: 1.5541\n",
      "Batch 897, Loss: 1.5312\n",
      "Batch 898, Loss: 1.5506\n",
      "Batch 899, Loss: 1.5811\n",
      "Batch 900, Loss: 1.5501\n",
      "Batch 901, Loss: 1.5765\n",
      "Batch 902, Loss: 1.5513\n",
      "Batch 903, Loss: 1.5330\n",
      "Batch 904, Loss: 1.5636\n",
      "Batch 905, Loss: 1.5804\n",
      "Batch 906, Loss: 1.5397\n",
      "Batch 907, Loss: 1.5348\n",
      "Batch 908, Loss: 1.5656\n",
      "Batch 909, Loss: 1.5411\n",
      "Batch 910, Loss: 1.5518\n",
      "Batch 911, Loss: 1.5485\n",
      "Batch 912, Loss: 1.5798\n",
      "Batch 913, Loss: 1.5245\n",
      "Batch 914, Loss: 1.5313\n",
      "Batch 915, Loss: 1.5677\n",
      "Batch 916, Loss: 1.5636\n",
      "Batch 917, Loss: 1.5506\n",
      "Batch 918, Loss: 1.5121\n",
      "Batch 919, Loss: 1.5720\n",
      "Batch 920, Loss: 1.5454\n",
      "Batch 921, Loss: 1.5636\n",
      "Batch 922, Loss: 1.5518\n",
      "Batch 923, Loss: 1.5670\n",
      "Batch 924, Loss: 1.5581\n",
      "Batch 925, Loss: 1.5551\n",
      "Batch 926, Loss: 1.5397\n",
      "Batch 927, Loss: 1.5433\n",
      "Batch 928, Loss: 1.5478\n",
      "Batch 929, Loss: 1.5613\n",
      "Batch 930, Loss: 1.5694\n",
      "Batch 931, Loss: 1.5782\n",
      "Batch 932, Loss: 1.5578\n",
      "Batch 933, Loss: 1.5723\n",
      "Batch 934, Loss: 1.5426\n",
      "Batch 935, Loss: 1.5353\n",
      "Batch 936, Loss: 1.5613\n",
      "Batch 937, Loss: 1.5312\n",
      "Batch 938, Loss: 1.5398\n",
      "Batch 939, Loss: 1.5631\n",
      "Batch 940, Loss: 1.5537\n",
      "Batch 941, Loss: 1.5517\n",
      "Batch 942, Loss: 1.5522\n",
      "Batch 943, Loss: 1.5466\n",
      "Batch 944, Loss: 1.5445\n",
      "Batch 945, Loss: 1.5785\n",
      "Batch 946, Loss: 1.5438\n",
      "Batch 947, Loss: 1.5448\n",
      "Batch 948, Loss: 1.5699\n",
      "Batch 949, Loss: 1.5467\n",
      "Batch 950, Loss: 1.5359\n",
      "Batch 951, Loss: 1.5722\n",
      "Batch 952, Loss: 1.5460\n",
      "Batch 953, Loss: 1.5050\n",
      "Batch 954, Loss: 1.5887\n",
      "Batch 955, Loss: 1.5206\n",
      "Batch 956, Loss: 1.5231\n",
      "Batch 957, Loss: 1.5400\n",
      "Batch 958, Loss: 1.5942\n",
      "Batch 959, Loss: 1.5384\n",
      "Batch 960, Loss: 1.5406\n",
      "Batch 961, Loss: 1.5775\n",
      "Batch 962, Loss: 1.5457\n",
      "Batch 963, Loss: 1.5454\n",
      "Batch 964, Loss: 1.5460\n",
      "Batch 965, Loss: 1.5637\n",
      "Epoch 3, Average Loss: 1.5812\n",
      "Once upon a time, there was a little boy named Timmy. Timmy loved to play outside with his friends. One day, Timmy's mom told him \n",
      "that they were going to behave and quiet. Timmy thought about how he was behaving so friendly. When they arrived at the elephair, Timmy sat \n",
      "at the honey for first. He said, \"Let's make a beautiful honey\". Timmy was so happy to be and helped!\" This time they worked to \n",
      "mix the honey together without pretending everyone to be a shape. After ding of mama washing the they'd birthday of way. Inside, Timmy where he \n",
      "went as taking all of his friends were quiet. Finally, his mom taught him a lot of magic stars to the counts. The prettiest stars \n",
      "were very creative, and even play by the way to soft often beautiful wins. He couldn't stop thinking about his mom. \"Can we make my \n",
      "dream scores to enjoy the more of perment and carrying with him every time they went just person.\" He watched every weeks and wished he \n",
      "could do anyone behave. \n",
      "\n",
      "--------------------\n",
      "Batch 0, Loss: 1.5255\n",
      "Batch 1, Loss: 1.5460\n",
      "Batch 2, Loss: 1.5492\n",
      "Batch 3, Loss: 1.5655\n",
      "Batch 4, Loss: 1.5173\n",
      "Batch 5, Loss: 1.5527\n",
      "Batch 6, Loss: 1.5174\n",
      "Batch 7, Loss: 1.5322\n",
      "Batch 8, Loss: 1.5018\n",
      "Batch 9, Loss: 1.5640\n",
      "Batch 10, Loss: 1.5339\n",
      "Batch 11, Loss: 1.5381\n",
      "Batch 12, Loss: 1.5425\n",
      "Batch 13, Loss: 1.5578\n",
      "Batch 14, Loss: 1.5100\n",
      "Batch 15, Loss: 1.5525\n",
      "Batch 16, Loss: 1.5633\n",
      "Batch 17, Loss: 1.5236\n",
      "Batch 18, Loss: 1.5114\n",
      "Batch 19, Loss: 1.5259\n",
      "Batch 20, Loss: 1.5311\n",
      "Batch 21, Loss: 1.5377\n",
      "Batch 22, Loss: 1.5509\n",
      "Batch 23, Loss: 1.5124\n",
      "Batch 24, Loss: 1.5767\n",
      "Batch 25, Loss: 1.5365\n",
      "Batch 26, Loss: 1.5481\n",
      "Batch 27, Loss: 1.5488\n",
      "Batch 28, Loss: 1.5654\n",
      "Batch 29, Loss: 1.5228\n",
      "Batch 30, Loss: 1.5204\n",
      "Batch 31, Loss: 1.5232\n",
      "Batch 32, Loss: 1.5298\n",
      "Batch 33, Loss: 1.5103\n",
      "Batch 34, Loss: 1.5298\n",
      "Batch 35, Loss: 1.5340\n",
      "Batch 36, Loss: 1.5155\n",
      "Batch 37, Loss: 1.5431\n",
      "Batch 38, Loss: 1.5257\n",
      "Batch 39, Loss: 1.5655\n",
      "Batch 40, Loss: 1.5407\n",
      "Batch 41, Loss: 1.5248\n",
      "Batch 42, Loss: 1.5100\n",
      "Batch 43, Loss: 1.5243\n",
      "Batch 44, Loss: 1.5379\n",
      "Batch 45, Loss: 1.5449\n",
      "Batch 46, Loss: 1.5178\n",
      "Batch 47, Loss: 1.5458\n",
      "Batch 48, Loss: 1.5624\n",
      "Batch 49, Loss: 1.5578\n",
      "Batch 50, Loss: 1.5122\n",
      "Batch 51, Loss: 1.5457\n",
      "Batch 52, Loss: 1.5357\n",
      "Batch 53, Loss: 1.5469\n",
      "Batch 54, Loss: 1.5312\n",
      "Batch 55, Loss: 1.5489\n",
      "Batch 56, Loss: 1.5420\n",
      "Batch 57, Loss: 1.5699\n",
      "Batch 58, Loss: 1.5542\n",
      "Batch 59, Loss: 1.5443\n",
      "Batch 60, Loss: 1.5590\n",
      "Batch 61, Loss: 1.5190\n",
      "Batch 62, Loss: 1.5300\n",
      "Batch 63, Loss: 1.5223\n",
      "Batch 64, Loss: 1.5532\n",
      "Batch 65, Loss: 1.5168\n",
      "Batch 66, Loss: 1.5518\n",
      "Batch 67, Loss: 1.5462\n",
      "Batch 68, Loss: 1.5178\n",
      "Batch 69, Loss: 1.5392\n",
      "Batch 70, Loss: 1.5390\n",
      "Batch 71, Loss: 1.5600\n",
      "Batch 72, Loss: 1.5230\n",
      "Batch 73, Loss: 1.5378\n",
      "Batch 74, Loss: 1.5171\n",
      "Batch 75, Loss: 1.5522\n",
      "Batch 76, Loss: 1.5301\n",
      "Batch 77, Loss: 1.5680\n",
      "Batch 78, Loss: 1.5300\n",
      "Batch 79, Loss: 1.5082\n",
      "Batch 80, Loss: 1.5200\n",
      "Batch 81, Loss: 1.5419\n",
      "Batch 82, Loss: 1.5722\n",
      "Batch 83, Loss: 1.5353\n",
      "Batch 84, Loss: 1.5145\n",
      "Batch 85, Loss: 1.5350\n",
      "Batch 86, Loss: 1.5206\n",
      "Batch 87, Loss: 1.5133\n",
      "Batch 88, Loss: 1.5421\n",
      "Batch 89, Loss: 1.5442\n",
      "Batch 90, Loss: 1.5410\n",
      "Batch 91, Loss: 1.5373\n",
      "Batch 92, Loss: 1.5415\n",
      "Batch 93, Loss: 1.5345\n",
      "Batch 94, Loss: 1.5673\n",
      "Batch 95, Loss: 1.5106\n",
      "Batch 96, Loss: 1.5521\n",
      "Batch 97, Loss: 1.5430\n",
      "Batch 98, Loss: 1.5458\n",
      "Batch 99, Loss: 1.5176\n",
      "Batch 100, Loss: 1.5529\n",
      "Batch 101, Loss: 1.5311\n",
      "Batch 102, Loss: 1.5339\n",
      "Batch 103, Loss: 1.5375\n",
      "Batch 104, Loss: 1.4963\n",
      "Batch 105, Loss: 1.5315\n",
      "Batch 106, Loss: 1.5338\n",
      "Batch 107, Loss: 1.5130\n",
      "Batch 108, Loss: 1.5315\n",
      "Batch 109, Loss: 1.5294\n",
      "Batch 110, Loss: 1.5361\n",
      "Batch 111, Loss: 1.5276\n",
      "Batch 112, Loss: 1.5425\n",
      "Batch 113, Loss: 1.5324\n",
      "Batch 114, Loss: 1.5083\n",
      "Batch 115, Loss: 1.5306\n",
      "Batch 116, Loss: 1.5280\n",
      "Batch 117, Loss: 1.5429\n",
      "Batch 118, Loss: 1.5579\n",
      "Batch 119, Loss: 1.5470\n",
      "Batch 120, Loss: 1.5623\n",
      "Batch 121, Loss: 1.5487\n",
      "Batch 122, Loss: 1.5444\n",
      "Batch 123, Loss: 1.5147\n",
      "Batch 124, Loss: 1.5297\n",
      "Batch 125, Loss: 1.5537\n",
      "Batch 126, Loss: 1.5150\n",
      "Batch 127, Loss: 1.5206\n",
      "Batch 128, Loss: 1.5418\n",
      "Batch 129, Loss: 1.5362\n",
      "Batch 130, Loss: 1.5157\n",
      "Batch 131, Loss: 1.5229\n",
      "Batch 132, Loss: 1.5586\n",
      "Batch 133, Loss: 1.5408\n",
      "Batch 134, Loss: 1.5345\n",
      "Batch 135, Loss: 1.5456\n",
      "Batch 136, Loss: 1.5692\n",
      "Batch 137, Loss: 1.5274\n",
      "Batch 138, Loss: 1.5651\n",
      "Batch 139, Loss: 1.5223\n",
      "Batch 140, Loss: 1.5274\n",
      "Batch 141, Loss: 1.5111\n",
      "Batch 142, Loss: 1.5119\n",
      "Batch 143, Loss: 1.5304\n",
      "Batch 144, Loss: 1.5524\n",
      "Batch 145, Loss: 1.5485\n",
      "Batch 146, Loss: 1.5467\n",
      "Batch 147, Loss: 1.5465\n",
      "Batch 148, Loss: 1.5469\n",
      "Batch 149, Loss: 1.5078\n",
      "Batch 150, Loss: 1.5500\n",
      "Batch 151, Loss: 1.5593\n",
      "Batch 152, Loss: 1.5217\n",
      "Batch 153, Loss: 1.5203\n",
      "Batch 154, Loss: 1.5327\n",
      "Batch 155, Loss: 1.5124\n",
      "Batch 156, Loss: 1.5530\n",
      "Batch 157, Loss: 1.5153\n",
      "Batch 158, Loss: 1.5317\n",
      "Batch 159, Loss: 1.5204\n",
      "Batch 160, Loss: 1.5441\n",
      "Batch 161, Loss: 1.5222\n",
      "Batch 162, Loss: 1.5483\n",
      "Batch 163, Loss: 1.5551\n",
      "Batch 164, Loss: 1.5289\n",
      "Batch 165, Loss: 1.5383\n",
      "Batch 166, Loss: 1.5309\n",
      "Batch 167, Loss: 1.5404\n",
      "Batch 168, Loss: 1.5434\n",
      "Batch 169, Loss: 1.5195\n",
      "Batch 170, Loss: 1.5521\n",
      "Batch 171, Loss: 1.5150\n",
      "Batch 172, Loss: 1.5503\n",
      "Batch 173, Loss: 1.5236\n",
      "Batch 174, Loss: 1.5435\n",
      "Batch 175, Loss: 1.5218\n",
      "Batch 176, Loss: 1.5160\n",
      "Batch 177, Loss: 1.5040\n",
      "Batch 178, Loss: 1.5336\n",
      "Batch 179, Loss: 1.5389\n",
      "Batch 180, Loss: 1.5394\n",
      "Batch 181, Loss: 1.5210\n",
      "Batch 182, Loss: 1.5489\n",
      "Batch 183, Loss: 1.5361\n",
      "Batch 184, Loss: 1.5224\n",
      "Batch 185, Loss: 1.5692\n",
      "Batch 186, Loss: 1.5516\n",
      "Batch 187, Loss: 1.5503\n",
      "Batch 188, Loss: 1.5398\n",
      "Batch 189, Loss: 1.5220\n",
      "Batch 190, Loss: 1.5275\n",
      "Batch 191, Loss: 1.5310\n",
      "Batch 192, Loss: 1.5277\n",
      "Batch 193, Loss: 1.5349\n",
      "Batch 194, Loss: 1.5296\n",
      "Batch 195, Loss: 1.5447\n",
      "Batch 196, Loss: 1.5161\n",
      "Batch 197, Loss: 1.5318\n",
      "Batch 198, Loss: 1.5482\n",
      "Batch 199, Loss: 1.5045\n",
      "Batch 200, Loss: 1.5547\n",
      "Batch 201, Loss: 1.5235\n",
      "Batch 202, Loss: 1.5325\n",
      "Batch 203, Loss: 1.5242\n",
      "Batch 204, Loss: 1.5535\n",
      "Batch 205, Loss: 1.5200\n",
      "Batch 206, Loss: 1.5397\n",
      "Batch 207, Loss: 1.5220\n",
      "Batch 208, Loss: 1.5127\n",
      "Batch 209, Loss: 1.5364\n",
      "Batch 210, Loss: 1.5140\n",
      "Batch 211, Loss: 1.5336\n",
      "Batch 212, Loss: 1.5129\n",
      "Batch 213, Loss: 1.5595\n",
      "Batch 214, Loss: 1.5467\n",
      "Batch 215, Loss: 1.5303\n",
      "Batch 216, Loss: 1.5532\n",
      "Batch 217, Loss: 1.5302\n",
      "Batch 218, Loss: 1.5462\n",
      "Batch 219, Loss: 1.5412\n",
      "Batch 220, Loss: 1.5408\n",
      "Batch 221, Loss: 1.5017\n",
      "Batch 222, Loss: 1.5327\n",
      "Batch 223, Loss: 1.5434\n",
      "Batch 224, Loss: 1.5352\n",
      "Batch 225, Loss: 1.5409\n",
      "Batch 226, Loss: 1.5205\n",
      "Batch 227, Loss: 1.5231\n",
      "Batch 228, Loss: 1.5276\n",
      "Batch 229, Loss: 1.5646\n",
      "Batch 230, Loss: 1.5560\n",
      "Batch 231, Loss: 1.5155\n",
      "Batch 232, Loss: 1.5310\n",
      "Batch 233, Loss: 1.5186\n",
      "Batch 234, Loss: 1.5023\n",
      "Batch 235, Loss: 1.5422\n",
      "Batch 236, Loss: 1.5209\n",
      "Batch 237, Loss: 1.5235\n",
      "Batch 238, Loss: 1.5347\n",
      "Batch 239, Loss: 1.5270\n",
      "Batch 240, Loss: 1.5291\n",
      "Batch 241, Loss: 1.5085\n",
      "Batch 242, Loss: 1.5131\n",
      "Batch 243, Loss: 1.5287\n",
      "Batch 244, Loss: 1.5260\n",
      "Batch 245, Loss: 1.5582\n",
      "Batch 246, Loss: 1.5241\n",
      "Batch 247, Loss: 1.5304\n",
      "Batch 248, Loss: 1.5300\n",
      "Batch 249, Loss: 1.5379\n",
      "Batch 250, Loss: 1.5662\n",
      "Batch 251, Loss: 1.5130\n",
      "Batch 252, Loss: 1.5327\n",
      "Batch 253, Loss: 1.5389\n",
      "Batch 254, Loss: 1.5174\n",
      "Batch 255, Loss: 1.5522\n",
      "Batch 256, Loss: 1.5225\n",
      "Batch 257, Loss: 1.5509\n",
      "Batch 258, Loss: 1.5193\n",
      "Batch 259, Loss: 1.5092\n",
      "Batch 260, Loss: 1.5163\n",
      "Batch 261, Loss: 1.5167\n",
      "Batch 262, Loss: 1.4889\n",
      "Batch 263, Loss: 1.5402\n",
      "Batch 264, Loss: 1.5242\n",
      "Batch 265, Loss: 1.5344\n",
      "Batch 266, Loss: 1.5400\n",
      "Batch 267, Loss: 1.5360\n",
      "Batch 268, Loss: 1.5251\n",
      "Batch 269, Loss: 1.5171\n",
      "Batch 270, Loss: 1.5376\n",
      "Batch 271, Loss: 1.5465\n",
      "Batch 272, Loss: 1.5233\n",
      "Batch 273, Loss: 1.5075\n",
      "Batch 274, Loss: 1.5258\n",
      "Batch 275, Loss: 1.5457\n",
      "Batch 276, Loss: 1.5251\n",
      "Batch 277, Loss: 1.5224\n",
      "Batch 278, Loss: 1.5273\n",
      "Batch 279, Loss: 1.5457\n",
      "Batch 280, Loss: 1.5056\n",
      "Batch 281, Loss: 1.5538\n",
      "Batch 282, Loss: 1.5112\n",
      "Batch 283, Loss: 1.5310\n",
      "Batch 284, Loss: 1.5342\n",
      "Batch 285, Loss: 1.5511\n",
      "Batch 286, Loss: 1.5315\n",
      "Batch 287, Loss: 1.5242\n",
      "Batch 288, Loss: 1.5437\n",
      "Batch 289, Loss: 1.5234\n",
      "Batch 290, Loss: 1.5441\n",
      "Batch 291, Loss: 1.5237\n",
      "Batch 292, Loss: 1.5162\n",
      "Batch 293, Loss: 1.5417\n",
      "Batch 294, Loss: 1.5208\n",
      "Batch 295, Loss: 1.5274\n",
      "Batch 296, Loss: 1.5149\n",
      "Batch 297, Loss: 1.5414\n",
      "Batch 298, Loss: 1.4984\n",
      "Batch 299, Loss: 1.5244\n",
      "Batch 300, Loss: 1.5296\n",
      "Batch 301, Loss: 1.5275\n",
      "Batch 302, Loss: 1.5443\n",
      "Batch 303, Loss: 1.5198\n",
      "Batch 304, Loss: 1.5369\n",
      "Batch 305, Loss: 1.5595\n",
      "Batch 306, Loss: 1.5324\n",
      "Batch 307, Loss: 1.5266\n",
      "Batch 308, Loss: 1.5264\n",
      "Batch 309, Loss: 1.5328\n",
      "Batch 310, Loss: 1.5428\n",
      "Batch 311, Loss: 1.5267\n",
      "Batch 312, Loss: 1.5179\n",
      "Batch 313, Loss: 1.5600\n",
      "Batch 314, Loss: 1.5351\n",
      "Batch 315, Loss: 1.5544\n",
      "Batch 316, Loss: 1.5136\n",
      "Batch 317, Loss: 1.5006\n",
      "Batch 318, Loss: 1.5254\n",
      "Batch 319, Loss: 1.5396\n",
      "Batch 320, Loss: 1.5268\n",
      "Batch 321, Loss: 1.5359\n",
      "Batch 322, Loss: 1.5253\n",
      "Batch 323, Loss: 1.5336\n",
      "Batch 324, Loss: 1.5551\n",
      "Batch 325, Loss: 1.5115\n",
      "Batch 326, Loss: 1.5214\n",
      "Batch 327, Loss: 1.5309\n",
      "Batch 328, Loss: 1.5337\n",
      "Batch 329, Loss: 1.5517\n",
      "Batch 330, Loss: 1.5353\n",
      "Batch 331, Loss: 1.5413\n",
      "Batch 332, Loss: 1.5268\n",
      "Batch 333, Loss: 1.5334\n",
      "Batch 334, Loss: 1.5309\n",
      "Batch 335, Loss: 1.5197\n",
      "Batch 336, Loss: 1.5552\n",
      "Batch 337, Loss: 1.5119\n",
      "Batch 338, Loss: 1.5018\n",
      "Batch 339, Loss: 1.5284\n",
      "Batch 340, Loss: 1.5342\n",
      "Batch 341, Loss: 1.5188\n",
      "Batch 342, Loss: 1.5618\n",
      "Batch 343, Loss: 1.5323\n",
      "Batch 344, Loss: 1.5179\n",
      "Batch 345, Loss: 1.5204\n",
      "Batch 346, Loss: 1.5509\n",
      "Batch 347, Loss: 1.5172\n",
      "Batch 348, Loss: 1.5268\n",
      "Batch 349, Loss: 1.5139\n",
      "Batch 350, Loss: 1.5230\n",
      "Batch 351, Loss: 1.5512\n",
      "Batch 352, Loss: 1.5177\n",
      "Batch 353, Loss: 1.5080\n",
      "Batch 354, Loss: 1.5250\n",
      "Batch 355, Loss: 1.5367\n",
      "Batch 356, Loss: 1.5180\n",
      "Batch 357, Loss: 1.5385\n",
      "Batch 358, Loss: 1.5258\n",
      "Batch 359, Loss: 1.5230\n",
      "Batch 360, Loss: 1.5103\n",
      "Batch 361, Loss: 1.5360\n",
      "Batch 362, Loss: 1.5343\n",
      "Batch 363, Loss: 1.5417\n",
      "Batch 364, Loss: 1.5073\n",
      "Batch 365, Loss: 1.5113\n",
      "Batch 366, Loss: 1.5478\n",
      "Batch 367, Loss: 1.5588\n",
      "Batch 368, Loss: 1.5408\n",
      "Batch 369, Loss: 1.5431\n",
      "Batch 370, Loss: 1.5386\n",
      "Batch 371, Loss: 1.5422\n",
      "Batch 372, Loss: 1.5522\n",
      "Batch 373, Loss: 1.5412\n",
      "Batch 374, Loss: 1.5147\n",
      "Batch 375, Loss: 1.5318\n",
      "Batch 376, Loss: 1.5127\n",
      "Batch 377, Loss: 1.5124\n",
      "Batch 378, Loss: 1.5398\n",
      "Batch 379, Loss: 1.5407\n",
      "Batch 380, Loss: 1.5123\n",
      "Batch 381, Loss: 1.5051\n",
      "Batch 382, Loss: 1.5082\n",
      "Batch 383, Loss: 1.5307\n",
      "Batch 384, Loss: 1.5239\n",
      "Batch 385, Loss: 1.5457\n",
      "Batch 386, Loss: 1.5395\n",
      "Batch 387, Loss: 1.5506\n",
      "Batch 388, Loss: 1.5326\n",
      "Batch 389, Loss: 1.5264\n",
      "Batch 390, Loss: 1.5370\n",
      "Batch 391, Loss: 1.5272\n",
      "Batch 392, Loss: 1.5300\n",
      "Batch 393, Loss: 1.5221\n",
      "Batch 394, Loss: 1.5363\n",
      "Batch 395, Loss: 1.5185\n",
      "Batch 396, Loss: 1.5280\n",
      "Batch 397, Loss: 1.5411\n",
      "Batch 398, Loss: 1.5512\n",
      "Batch 399, Loss: 1.5287\n",
      "Batch 400, Loss: 1.5206\n",
      "Batch 401, Loss: 1.5451\n",
      "Batch 402, Loss: 1.5181\n",
      "Batch 403, Loss: 1.5458\n",
      "Batch 404, Loss: 1.5162\n",
      "Batch 405, Loss: 1.5139\n",
      "Batch 406, Loss: 1.5114\n",
      "Batch 407, Loss: 1.5244\n",
      "Batch 408, Loss: 1.5118\n",
      "Batch 409, Loss: 1.5197\n",
      "Batch 410, Loss: 1.5274\n",
      "Batch 411, Loss: 1.5434\n",
      "Batch 412, Loss: 1.5401\n",
      "Batch 413, Loss: 1.5222\n",
      "Batch 414, Loss: 1.5350\n",
      "Batch 415, Loss: 1.5442\n",
      "Batch 416, Loss: 1.5298\n",
      "Batch 417, Loss: 1.5440\n",
      "Batch 418, Loss: 1.5172\n",
      "Batch 419, Loss: 1.5539\n",
      "Batch 420, Loss: 1.5281\n",
      "Batch 421, Loss: 1.5037\n",
      "Batch 422, Loss: 1.5189\n",
      "Batch 423, Loss: 1.5154\n",
      "Batch 424, Loss: 1.5251\n",
      "Batch 425, Loss: 1.5335\n",
      "Batch 426, Loss: 1.5076\n",
      "Batch 427, Loss: 1.5226\n",
      "Batch 428, Loss: 1.5312\n",
      "Batch 429, Loss: 1.5455\n",
      "Batch 430, Loss: 1.5251\n",
      "Batch 431, Loss: 1.5224\n",
      "Batch 432, Loss: 1.5110\n",
      "Batch 433, Loss: 1.5179\n",
      "Batch 434, Loss: 1.5312\n",
      "Batch 435, Loss: 1.5261\n",
      "Batch 436, Loss: 1.5409\n",
      "Batch 437, Loss: 1.5090\n",
      "Batch 438, Loss: 1.5264\n",
      "Batch 439, Loss: 1.5239\n",
      "Batch 440, Loss: 1.5260\n",
      "Batch 441, Loss: 1.5189\n",
      "Batch 442, Loss: 1.4990\n",
      "Batch 443, Loss: 1.5262\n",
      "Batch 444, Loss: 1.5204\n",
      "Batch 445, Loss: 1.5437\n",
      "Batch 446, Loss: 1.5441\n",
      "Batch 447, Loss: 1.5288\n",
      "Batch 448, Loss: 1.5088\n",
      "Batch 449, Loss: 1.5237\n",
      "Batch 450, Loss: 1.5239\n",
      "Batch 451, Loss: 1.5123\n",
      "Batch 452, Loss: 1.5550\n",
      "Batch 453, Loss: 1.5321\n",
      "Batch 454, Loss: 1.5054\n",
      "Batch 455, Loss: 1.5209\n",
      "Batch 456, Loss: 1.5457\n",
      "Batch 457, Loss: 1.4771\n",
      "Batch 458, Loss: 1.5337\n",
      "Batch 459, Loss: 1.5215\n",
      "Batch 460, Loss: 1.4969\n",
      "Batch 461, Loss: 1.5444\n",
      "Batch 462, Loss: 1.5098\n",
      "Batch 463, Loss: 1.5234\n",
      "Batch 464, Loss: 1.5203\n",
      "Batch 465, Loss: 1.5361\n",
      "Batch 466, Loss: 1.5404\n",
      "Batch 467, Loss: 1.5247\n",
      "Batch 468, Loss: 1.5327\n",
      "Batch 469, Loss: 1.5223\n",
      "Batch 470, Loss: 1.5145\n",
      "Batch 471, Loss: 1.5470\n",
      "Batch 472, Loss: 1.5036\n",
      "Batch 473, Loss: 1.5197\n",
      "Batch 474, Loss: 1.5156\n",
      "Batch 475, Loss: 1.5441\n",
      "Batch 476, Loss: 1.5311\n",
      "Batch 477, Loss: 1.5322\n",
      "Batch 478, Loss: 1.5286\n",
      "Batch 479, Loss: 1.5284\n",
      "Batch 480, Loss: 1.5123\n",
      "Batch 481, Loss: 1.5316\n",
      "Batch 482, Loss: 1.5065\n",
      "Batch 483, Loss: 1.5506\n",
      "Once upon a time, there was a little girl named Lily. She went to a palace with her mom and dad. They ate a cake, \n",
      "kind princess, and served tall grass. Lily saw the numbers that zoomed all around her neighbor, and wanted to trust. \"Can we try out another \n",
      "words?\" asked Lily. Her mom stoought home and they walked around the palach braches. After a while, Lily said it was very big and fitch \n",
      "with candy. \"What happened?\" she asked. \"It's a bad drop, but be careful,\" repliaches. \"I'm playing. My mommy who caught me me,\" Lily said still \n",
      "said. \"I told you that zoom is very dangerous.\" she said with a lost zooming behind a grass. Suddenly, a more movement swep over the \n",
      "forest. She couldn't regreeter how happened her mom's speed. \"Mommy,\" she said. \"Do you need to try again?\" The moven dried the drying one last \n",
      "stayed and fast. \"Yes,\" she said. The moral of this made Lily feel better so danged and flew away. \n",
      "\n",
      "--------------------\n",
      "Batch 484, Loss: 1.5212\n",
      "Batch 485, Loss: 1.5211\n",
      "Batch 486, Loss: 1.5313\n",
      "Batch 487, Loss: 1.5109\n",
      "Batch 488, Loss: 1.5015\n",
      "Batch 489, Loss: 1.5340\n",
      "Batch 490, Loss: 1.5130\n",
      "Batch 491, Loss: 1.5248\n",
      "Batch 492, Loss: 1.5463\n",
      "Batch 493, Loss: 1.5266\n",
      "Batch 494, Loss: 1.5401\n",
      "Batch 495, Loss: 1.5219\n",
      "Batch 496, Loss: 1.5215\n",
      "Batch 497, Loss: 1.5393\n",
      "Batch 498, Loss: 1.5042\n",
      "Batch 499, Loss: 1.5315\n",
      "Batch 500, Loss: 1.5110\n",
      "Batch 501, Loss: 1.5296\n",
      "Batch 502, Loss: 1.5130\n",
      "Batch 503, Loss: 1.5000\n",
      "Batch 504, Loss: 1.5328\n",
      "Batch 505, Loss: 1.5194\n",
      "Batch 506, Loss: 1.5061\n",
      "Batch 507, Loss: 1.4965\n",
      "Batch 508, Loss: 1.5329\n",
      "Batch 509, Loss: 1.5504\n",
      "Batch 510, Loss: 1.5542\n",
      "Batch 511, Loss: 1.5294\n",
      "Batch 512, Loss: 1.5313\n",
      "Batch 513, Loss: 1.5252\n",
      "Batch 514, Loss: 1.5289\n",
      "Batch 515, Loss: 1.5325\n",
      "Batch 516, Loss: 1.5036\n",
      "Batch 517, Loss: 1.5204\n",
      "Batch 518, Loss: 1.5433\n",
      "Batch 519, Loss: 1.5310\n",
      "Batch 520, Loss: 1.5101\n",
      "Batch 521, Loss: 1.5045\n",
      "Batch 522, Loss: 1.5306\n",
      "Batch 523, Loss: 1.4871\n",
      "Batch 524, Loss: 1.5008\n",
      "Batch 525, Loss: 1.5176\n",
      "Batch 526, Loss: 1.5200\n",
      "Batch 527, Loss: 1.5502\n",
      "Batch 528, Loss: 1.4974\n",
      "Batch 529, Loss: 1.5463\n",
      "Batch 530, Loss: 1.4993\n",
      "Batch 531, Loss: 1.5019\n",
      "Batch 532, Loss: 1.5207\n",
      "Batch 533, Loss: 1.5378\n",
      "Batch 534, Loss: 1.5346\n",
      "Batch 535, Loss: 1.5332\n",
      "Batch 536, Loss: 1.4912\n",
      "Batch 537, Loss: 1.5308\n",
      "Batch 538, Loss: 1.5200\n",
      "Batch 539, Loss: 1.5366\n",
      "Batch 540, Loss: 1.5245\n",
      "Batch 541, Loss: 1.5282\n",
      "Batch 542, Loss: 1.5398\n",
      "Batch 543, Loss: 1.4949\n",
      "Batch 544, Loss: 1.5110\n",
      "Batch 545, Loss: 1.5585\n",
      "Batch 546, Loss: 1.5144\n",
      "Batch 547, Loss: 1.5402\n",
      "Batch 548, Loss: 1.5404\n",
      "Batch 549, Loss: 1.5211\n",
      "Batch 550, Loss: 1.5297\n",
      "Batch 551, Loss: 1.5333\n",
      "Batch 552, Loss: 1.4993\n",
      "Batch 553, Loss: 1.5342\n",
      "Batch 554, Loss: 1.4828\n",
      "Batch 555, Loss: 1.5003\n",
      "Batch 556, Loss: 1.5153\n",
      "Batch 557, Loss: 1.5217\n",
      "Batch 558, Loss: 1.5320\n",
      "Batch 559, Loss: 1.5269\n",
      "Batch 560, Loss: 1.5172\n",
      "Batch 561, Loss: 1.5270\n",
      "Batch 562, Loss: 1.5233\n",
      "Batch 563, Loss: 1.5421\n",
      "Batch 564, Loss: 1.5094\n",
      "Batch 565, Loss: 1.5190\n",
      "Batch 566, Loss: 1.5219\n",
      "Batch 567, Loss: 1.5317\n",
      "Batch 568, Loss: 1.5154\n",
      "Batch 569, Loss: 1.5101\n",
      "Batch 570, Loss: 1.5223\n",
      "Batch 571, Loss: 1.5188\n",
      "Batch 572, Loss: 1.5041\n",
      "Batch 573, Loss: 1.5241\n",
      "Batch 574, Loss: 1.5241\n",
      "Batch 575, Loss: 1.5156\n",
      "Batch 576, Loss: 1.5088\n",
      "Batch 577, Loss: 1.4870\n",
      "Batch 578, Loss: 1.5056\n",
      "Batch 579, Loss: 1.5348\n",
      "Batch 580, Loss: 1.5509\n",
      "Batch 581, Loss: 1.5377\n",
      "Batch 582, Loss: 1.5078\n",
      "Batch 583, Loss: 1.5174\n",
      "Batch 584, Loss: 1.5193\n",
      "Batch 585, Loss: 1.5019\n",
      "Batch 586, Loss: 1.5188\n",
      "Batch 587, Loss: 1.5428\n",
      "Batch 588, Loss: 1.5283\n",
      "Batch 589, Loss: 1.4962\n",
      "Batch 590, Loss: 1.5262\n",
      "Batch 591, Loss: 1.5003\n",
      "Batch 592, Loss: 1.5096\n",
      "Batch 593, Loss: 1.5049\n",
      "Batch 594, Loss: 1.5228\n",
      "Batch 595, Loss: 1.4983\n",
      "Batch 596, Loss: 1.5104\n",
      "Batch 597, Loss: 1.5185\n",
      "Batch 598, Loss: 1.4843\n",
      "Batch 599, Loss: 1.5215\n",
      "Batch 600, Loss: 1.5203\n",
      "Batch 601, Loss: 1.4716\n",
      "Batch 602, Loss: 1.5230\n",
      "Batch 603, Loss: 1.5250\n",
      "Batch 604, Loss: 1.5080\n",
      "Batch 605, Loss: 1.5119\n",
      "Batch 606, Loss: 1.5458\n",
      "Batch 607, Loss: 1.5205\n",
      "Batch 608, Loss: 1.5250\n",
      "Batch 609, Loss: 1.5295\n",
      "Batch 610, Loss: 1.5193\n",
      "Batch 611, Loss: 1.5054\n",
      "Batch 612, Loss: 1.5114\n",
      "Batch 613, Loss: 1.5425\n",
      "Batch 614, Loss: 1.5219\n",
      "Batch 615, Loss: 1.5197\n",
      "Batch 616, Loss: 1.4962\n",
      "Batch 617, Loss: 1.5295\n",
      "Batch 618, Loss: 1.5200\n",
      "Batch 619, Loss: 1.5153\n",
      "Batch 620, Loss: 1.5096\n",
      "Batch 621, Loss: 1.5171\n",
      "Batch 622, Loss: 1.5531\n",
      "Batch 623, Loss: 1.5282\n",
      "Batch 624, Loss: 1.4892\n",
      "Batch 625, Loss: 1.5070\n",
      "Batch 626, Loss: 1.5143\n",
      "Batch 627, Loss: 1.5103\n",
      "Batch 628, Loss: 1.5005\n",
      "Batch 629, Loss: 1.5349\n",
      "Batch 630, Loss: 1.5394\n",
      "Batch 631, Loss: 1.5065\n",
      "Batch 632, Loss: 1.5184\n",
      "Batch 633, Loss: 1.5151\n",
      "Batch 634, Loss: 1.5100\n",
      "Batch 635, Loss: 1.5063\n",
      "Batch 636, Loss: 1.5292\n",
      "Batch 637, Loss: 1.5086\n",
      "Batch 638, Loss: 1.5575\n",
      "Batch 639, Loss: 1.5104\n",
      "Batch 640, Loss: 1.5218\n",
      "Batch 641, Loss: 1.5343\n",
      "Batch 642, Loss: 1.5513\n",
      "Batch 643, Loss: 1.5038\n",
      "Batch 644, Loss: 1.5238\n",
      "Batch 645, Loss: 1.5380\n",
      "Batch 646, Loss: 1.5457\n",
      "Batch 647, Loss: 1.5209\n",
      "Batch 648, Loss: 1.5211\n",
      "Batch 649, Loss: 1.5226\n",
      "Batch 650, Loss: 1.5183\n",
      "Batch 651, Loss: 1.5212\n",
      "Batch 652, Loss: 1.5313\n",
      "Batch 653, Loss: 1.5284\n",
      "Batch 654, Loss: 1.4938\n",
      "Batch 655, Loss: 1.5464\n",
      "Batch 656, Loss: 1.5111\n",
      "Batch 657, Loss: 1.5129\n",
      "Batch 658, Loss: 1.5354\n",
      "Batch 659, Loss: 1.5027\n",
      "Batch 660, Loss: 1.5275\n",
      "Batch 661, Loss: 1.5040\n",
      "Batch 662, Loss: 1.5188\n",
      "Batch 663, Loss: 1.5134\n",
      "Batch 664, Loss: 1.5152\n",
      "Batch 665, Loss: 1.4930\n",
      "Batch 666, Loss: 1.5246\n",
      "Batch 667, Loss: 1.5221\n",
      "Batch 668, Loss: 1.5483\n",
      "Batch 669, Loss: 1.5130\n",
      "Batch 670, Loss: 1.4875\n",
      "Batch 671, Loss: 1.5141\n",
      "Batch 672, Loss: 1.5344\n",
      "Batch 673, Loss: 1.5147\n",
      "Batch 674, Loss: 1.5348\n",
      "Batch 675, Loss: 1.5029\n",
      "Batch 676, Loss: 1.5049\n",
      "Batch 677, Loss: 1.5148\n",
      "Batch 678, Loss: 1.5086\n",
      "Batch 679, Loss: 1.4991\n",
      "Batch 680, Loss: 1.5116\n",
      "Batch 681, Loss: 1.5326\n",
      "Batch 682, Loss: 1.5149\n",
      "Batch 683, Loss: 1.5157\n",
      "Batch 684, Loss: 1.5264\n",
      "Batch 685, Loss: 1.5035\n",
      "Batch 686, Loss: 1.5033\n",
      "Batch 687, Loss: 1.5069\n",
      "Batch 688, Loss: 1.5229\n",
      "Batch 689, Loss: 1.5155\n",
      "Batch 690, Loss: 1.5267\n",
      "Batch 691, Loss: 1.5193\n",
      "Batch 692, Loss: 1.4953\n",
      "Batch 693, Loss: 1.5523\n",
      "Batch 694, Loss: 1.5303\n",
      "Batch 695, Loss: 1.5041\n",
      "Batch 696, Loss: 1.5328\n",
      "Batch 697, Loss: 1.5053\n",
      "Batch 698, Loss: 1.5382\n",
      "Batch 699, Loss: 1.5265\n",
      "Batch 700, Loss: 1.4951\n",
      "Batch 701, Loss: 1.5162\n",
      "Batch 702, Loss: 1.5377\n",
      "Batch 703, Loss: 1.5139\n",
      "Batch 704, Loss: 1.5244\n",
      "Batch 705, Loss: 1.5484\n",
      "Batch 706, Loss: 1.5157\n",
      "Batch 707, Loss: 1.5556\n",
      "Batch 708, Loss: 1.4816\n",
      "Batch 709, Loss: 1.5249\n",
      "Batch 710, Loss: 1.5182\n",
      "Batch 711, Loss: 1.5123\n",
      "Batch 712, Loss: 1.5239\n",
      "Batch 713, Loss: 1.5478\n",
      "Batch 714, Loss: 1.5231\n",
      "Batch 715, Loss: 1.5310\n",
      "Batch 716, Loss: 1.5313\n",
      "Batch 717, Loss: 1.5250\n",
      "Batch 718, Loss: 1.5225\n",
      "Batch 719, Loss: 1.5022\n",
      "Batch 720, Loss: 1.4957\n",
      "Batch 721, Loss: 1.5152\n",
      "Batch 722, Loss: 1.5038\n",
      "Batch 723, Loss: 1.5219\n",
      "Batch 724, Loss: 1.5037\n",
      "Batch 725, Loss: 1.5027\n",
      "Batch 726, Loss: 1.4948\n",
      "Batch 727, Loss: 1.5291\n",
      "Batch 728, Loss: 1.5178\n",
      "Batch 729, Loss: 1.5236\n",
      "Batch 730, Loss: 1.5178\n",
      "Batch 731, Loss: 1.5030\n",
      "Batch 732, Loss: 1.5211\n",
      "Batch 733, Loss: 1.5394\n",
      "Batch 734, Loss: 1.5183\n",
      "Batch 735, Loss: 1.5202\n",
      "Batch 736, Loss: 1.5158\n",
      "Batch 737, Loss: 1.5164\n",
      "Batch 738, Loss: 1.5189\n",
      "Batch 739, Loss: 1.5104\n",
      "Batch 740, Loss: 1.5074\n",
      "Batch 741, Loss: 1.5591\n",
      "Batch 742, Loss: 1.5022\n",
      "Batch 743, Loss: 1.5407\n",
      "Batch 744, Loss: 1.5162\n",
      "Batch 745, Loss: 1.5033\n",
      "Batch 746, Loss: 1.5128\n",
      "Batch 747, Loss: 1.5032\n",
      "Batch 748, Loss: 1.4940\n",
      "Batch 749, Loss: 1.5264\n",
      "Batch 750, Loss: 1.5160\n",
      "Batch 751, Loss: 1.5221\n",
      "Batch 752, Loss: 1.5394\n",
      "Batch 753, Loss: 1.5173\n",
      "Batch 754, Loss: 1.5174\n",
      "Batch 755, Loss: 1.4950\n",
      "Batch 756, Loss: 1.4910\n",
      "Batch 757, Loss: 1.5281\n",
      "Batch 758, Loss: 1.5094\n",
      "Batch 759, Loss: 1.5246\n",
      "Batch 760, Loss: 1.5238\n",
      "Batch 761, Loss: 1.5117\n",
      "Batch 762, Loss: 1.5370\n",
      "Batch 763, Loss: 1.5036\n",
      "Batch 764, Loss: 1.5015\n",
      "Batch 765, Loss: 1.5285\n",
      "Batch 766, Loss: 1.5288\n",
      "Batch 767, Loss: 1.4890\n",
      "Batch 768, Loss: 1.5012\n",
      "Batch 769, Loss: 1.4959\n",
      "Batch 770, Loss: 1.5362\n",
      "Batch 771, Loss: 1.5046\n",
      "Batch 772, Loss: 1.5358\n",
      "Batch 773, Loss: 1.5386\n",
      "Batch 774, Loss: 1.4963\n",
      "Batch 775, Loss: 1.5176\n",
      "Batch 776, Loss: 1.5249\n",
      "Batch 777, Loss: 1.5151\n",
      "Batch 778, Loss: 1.5067\n",
      "Batch 779, Loss: 1.5374\n",
      "Batch 780, Loss: 1.5182\n",
      "Batch 781, Loss: 1.5451\n",
      "Batch 782, Loss: 1.4849\n",
      "Batch 783, Loss: 1.5155\n",
      "Batch 784, Loss: 1.4794\n",
      "Batch 785, Loss: 1.5163\n",
      "Batch 786, Loss: 1.5313\n",
      "Batch 787, Loss: 1.5115\n",
      "Batch 788, Loss: 1.5194\n",
      "Batch 789, Loss: 1.5367\n",
      "Batch 790, Loss: 1.5331\n",
      "Batch 791, Loss: 1.4935\n",
      "Batch 792, Loss: 1.4957\n",
      "Batch 793, Loss: 1.4829\n",
      "Batch 794, Loss: 1.4803\n",
      "Batch 795, Loss: 1.5208\n",
      "Batch 796, Loss: 1.5116\n",
      "Batch 797, Loss: 1.5056\n",
      "Batch 798, Loss: 1.4928\n",
      "Batch 799, Loss: 1.4940\n",
      "Batch 800, Loss: 1.5119\n",
      "Batch 801, Loss: 1.5349\n",
      "Batch 802, Loss: 1.4973\n",
      "Batch 803, Loss: 1.4945\n",
      "Batch 804, Loss: 1.4894\n",
      "Batch 805, Loss: 1.5056\n",
      "Batch 806, Loss: 1.5271\n",
      "Batch 807, Loss: 1.4896\n",
      "Batch 808, Loss: 1.4891\n",
      "Batch 809, Loss: 1.5015\n",
      "Batch 810, Loss: 1.5110\n",
      "Batch 811, Loss: 1.5138\n",
      "Batch 812, Loss: 1.5238\n",
      "Batch 813, Loss: 1.4990\n",
      "Batch 814, Loss: 1.5035\n",
      "Batch 815, Loss: 1.5380\n",
      "Batch 816, Loss: 1.4860\n",
      "Batch 817, Loss: 1.4943\n",
      "Batch 818, Loss: 1.5112\n",
      "Batch 819, Loss: 1.5278\n",
      "Batch 820, Loss: 1.5225\n",
      "Batch 821, Loss: 1.5190\n",
      "Batch 822, Loss: 1.5139\n",
      "Batch 823, Loss: 1.5142\n",
      "Batch 824, Loss: 1.5075\n",
      "Batch 825, Loss: 1.5183\n",
      "Batch 826, Loss: 1.5197\n",
      "Batch 827, Loss: 1.5257\n",
      "Batch 828, Loss: 1.5117\n",
      "Batch 829, Loss: 1.5068\n",
      "Batch 830, Loss: 1.5212\n",
      "Batch 831, Loss: 1.5173\n",
      "Batch 832, Loss: 1.4979\n",
      "Batch 833, Loss: 1.5318\n",
      "Batch 834, Loss: 1.5421\n",
      "Batch 835, Loss: 1.5033\n",
      "Batch 836, Loss: 1.4515\n",
      "Batch 837, Loss: 1.4981\n",
      "Batch 838, Loss: 1.5078\n",
      "Batch 839, Loss: 1.5405\n",
      "Batch 840, Loss: 1.5265\n",
      "Batch 841, Loss: 1.5270\n",
      "Batch 842, Loss: 1.5187\n",
      "Batch 843, Loss: 1.5116\n",
      "Batch 844, Loss: 1.5041\n",
      "Batch 845, Loss: 1.5027\n",
      "Batch 846, Loss: 1.5388\n",
      "Batch 847, Loss: 1.5124\n",
      "Batch 848, Loss: 1.5050\n",
      "Batch 849, Loss: 1.4923\n",
      "Batch 850, Loss: 1.5158\n",
      "Batch 851, Loss: 1.4885\n",
      "Batch 852, Loss: 1.5076\n",
      "Batch 853, Loss: 1.5226\n",
      "Batch 854, Loss: 1.5015\n",
      "Batch 855, Loss: 1.5015\n",
      "Batch 856, Loss: 1.5035\n",
      "Batch 857, Loss: 1.5041\n",
      "Batch 858, Loss: 1.5224\n",
      "Batch 859, Loss: 1.5038\n",
      "Batch 860, Loss: 1.4973\n",
      "Batch 861, Loss: 1.5143\n",
      "Batch 862, Loss: 1.4893\n",
      "Batch 863, Loss: 1.4956\n",
      "Batch 864, Loss: 1.5259\n",
      "Batch 865, Loss: 1.5181\n",
      "Batch 866, Loss: 1.5019\n",
      "Batch 867, Loss: 1.5166\n",
      "Batch 868, Loss: 1.4815\n",
      "Batch 869, Loss: 1.4976\n",
      "Batch 870, Loss: 1.5284\n",
      "Batch 871, Loss: 1.5381\n",
      "Batch 872, Loss: 1.4857\n",
      "Batch 873, Loss: 1.5311\n",
      "Batch 874, Loss: 1.4891\n",
      "Batch 875, Loss: 1.5014\n",
      "Batch 876, Loss: 1.5118\n",
      "Batch 877, Loss: 1.4886\n",
      "Batch 878, Loss: 1.4938\n",
      "Batch 879, Loss: 1.5190\n",
      "Batch 880, Loss: 1.5175\n",
      "Batch 881, Loss: 1.4837\n",
      "Batch 882, Loss: 1.5311\n",
      "Batch 883, Loss: 1.5136\n",
      "Batch 884, Loss: 1.5071\n",
      "Batch 885, Loss: 1.5336\n",
      "Batch 886, Loss: 1.5117\n",
      "Batch 887, Loss: 1.5180\n",
      "Batch 888, Loss: 1.5015\n",
      "Batch 889, Loss: 1.4929\n",
      "Batch 890, Loss: 1.4994\n",
      "Batch 891, Loss: 1.5205\n",
      "Batch 892, Loss: 1.5137\n",
      "Batch 893, Loss: 1.5218\n",
      "Batch 894, Loss: 1.5135\n",
      "Batch 895, Loss: 1.5037\n",
      "Batch 896, Loss: 1.5089\n",
      "Batch 897, Loss: 1.5167\n",
      "Batch 898, Loss: 1.5319\n",
      "Batch 899, Loss: 1.4963\n",
      "Batch 900, Loss: 1.5027\n",
      "Batch 901, Loss: 1.4868\n",
      "Batch 902, Loss: 1.4989\n",
      "Batch 903, Loss: 1.4742\n",
      "Batch 904, Loss: 1.5151\n",
      "Batch 905, Loss: 1.5430\n",
      "Batch 906, Loss: 1.4929\n",
      "Batch 907, Loss: 1.5113\n",
      "Batch 908, Loss: 1.4751\n",
      "Batch 909, Loss: 1.4953\n",
      "Batch 910, Loss: 1.5211\n",
      "Batch 911, Loss: 1.4828\n",
      "Batch 912, Loss: 1.5011\n",
      "Batch 913, Loss: 1.5019\n",
      "Batch 914, Loss: 1.4922\n",
      "Batch 915, Loss: 1.5042\n",
      "Batch 916, Loss: 1.4986\n",
      "Batch 917, Loss: 1.5192\n",
      "Batch 918, Loss: 1.4869\n",
      "Batch 919, Loss: 1.5512\n",
      "Batch 920, Loss: 1.4874\n",
      "Batch 921, Loss: 1.5073\n",
      "Batch 922, Loss: 1.5136\n",
      "Batch 923, Loss: 1.4969\n",
      "Batch 924, Loss: 1.4859\n",
      "Batch 925, Loss: 1.5025\n",
      "Batch 926, Loss: 1.5339\n",
      "Batch 927, Loss: 1.4760\n",
      "Batch 928, Loss: 1.5348\n",
      "Batch 929, Loss: 1.5150\n",
      "Batch 930, Loss: 1.4986\n",
      "Batch 931, Loss: 1.5165\n",
      "Batch 932, Loss: 1.4934\n",
      "Batch 933, Loss: 1.4901\n",
      "Batch 934, Loss: 1.5123\n",
      "Batch 935, Loss: 1.5157\n",
      "Batch 936, Loss: 1.5104\n",
      "Batch 937, Loss: 1.5013\n",
      "Batch 938, Loss: 1.4679\n",
      "Batch 939, Loss: 1.4779\n",
      "Batch 940, Loss: 1.5263\n",
      "Batch 941, Loss: 1.5223\n",
      "Batch 942, Loss: 1.5171\n",
      "Batch 943, Loss: 1.5030\n",
      "Batch 944, Loss: 1.5357\n",
      "Batch 945, Loss: 1.5085\n",
      "Batch 946, Loss: 1.5116\n",
      "Batch 947, Loss: 1.5161\n",
      "Batch 948, Loss: 1.5110\n",
      "Batch 949, Loss: 1.5150\n",
      "Batch 950, Loss: 1.4929\n",
      "Batch 951, Loss: 1.4857\n",
      "Batch 952, Loss: 1.5116\n",
      "Batch 953, Loss: 1.5098\n",
      "Batch 954, Loss: 1.4908\n",
      "Batch 955, Loss: 1.5110\n",
      "Batch 956, Loss: 1.5159\n",
      "Batch 957, Loss: 1.4910\n",
      "Batch 958, Loss: 1.5205\n",
      "Batch 959, Loss: 1.5332\n",
      "Batch 960, Loss: 1.4970\n",
      "Batch 961, Loss: 1.5165\n",
      "Batch 962, Loss: 1.4829\n",
      "Batch 963, Loss: 1.5016\n",
      "Batch 964, Loss: 1.4976\n",
      "Batch 965, Loss: 1.4873\n",
      "Epoch 4, Average Loss: 1.5233\n",
      "Once upon a time, there was a little girl named Lily. She loved to spinace on the ranger and on her bedroom. One day, she \n",
      "got out of the toy car and her favorite toy show. Lily went to the river and she was still excited. She saw a big \n",
      "spin and she wanted to throw a rope. She asked her mom, \"if we can wait to spin too! Can I repase your shoes?\" Her \n",
      "mom studying and then went to the kitchen firm of sit and spins. When they finally came home, Lily saw the rope that she didn't \n",
      "know. She was happy that her toy was not happy. \"I found Lily, Mommy,\" she said. \"I want to have a snack.\" \"Okay, we can \n",
      "finish our shoes the spine together!\" Lily thought for a moment. Their mom said, \"Don't worry ate me!\" Lily felt warm and felt much better \n",
      "friends. From that day on, her toys played with shoes and enjoyed their beautiful rope. They talked hard and became a nice, just like every \n",
      "day. \n",
      "\n",
      "--------------------\n",
      "Batch 0, Loss: 1.4981\n",
      "Batch 1, Loss: 1.4757\n",
      "Batch 2, Loss: 1.5015\n",
      "Batch 3, Loss: 1.4972\n",
      "Batch 4, Loss: 1.4856\n",
      "Batch 5, Loss: 1.4995\n",
      "Batch 6, Loss: 1.4663\n",
      "Batch 7, Loss: 1.4879\n",
      "Batch 8, Loss: 1.4994\n",
      "Batch 9, Loss: 1.4814\n",
      "Batch 10, Loss: 1.4692\n",
      "Batch 11, Loss: 1.4622\n",
      "Batch 12, Loss: 1.4849\n",
      "Batch 13, Loss: 1.4762\n",
      "Batch 14, Loss: 1.4947\n",
      "Batch 15, Loss: 1.4844\n",
      "Batch 16, Loss: 1.4782\n",
      "Batch 17, Loss: 1.4911\n",
      "Batch 18, Loss: 1.4965\n",
      "Batch 19, Loss: 1.4875\n",
      "Batch 20, Loss: 1.5025\n",
      "Batch 21, Loss: 1.4660\n",
      "Batch 22, Loss: 1.4825\n",
      "Batch 23, Loss: 1.4935\n",
      "Batch 24, Loss: 1.4986\n",
      "Batch 25, Loss: 1.5122\n",
      "Batch 26, Loss: 1.4726\n",
      "Batch 27, Loss: 1.4859\n",
      "Batch 28, Loss: 1.4778\n",
      "Batch 29, Loss: 1.4927\n",
      "Batch 30, Loss: 1.4886\n",
      "Batch 31, Loss: 1.4901\n",
      "Batch 32, Loss: 1.5130\n",
      "Batch 33, Loss: 1.4841\n",
      "Batch 34, Loss: 1.4780\n",
      "Batch 35, Loss: 1.5024\n",
      "Batch 36, Loss: 1.4751\n",
      "Batch 37, Loss: 1.4916\n",
      "Batch 38, Loss: 1.5308\n",
      "Batch 39, Loss: 1.4923\n",
      "Batch 40, Loss: 1.5079\n",
      "Batch 41, Loss: 1.4664\n",
      "Batch 42, Loss: 1.4990\n",
      "Batch 43, Loss: 1.5036\n",
      "Batch 44, Loss: 1.5090\n",
      "Batch 45, Loss: 1.4904\n",
      "Batch 46, Loss: 1.4912\n",
      "Batch 47, Loss: 1.4733\n",
      "Batch 48, Loss: 1.5128\n",
      "Batch 49, Loss: 1.4874\n",
      "Batch 50, Loss: 1.5244\n",
      "Batch 51, Loss: 1.4783\n",
      "Batch 52, Loss: 1.4918\n",
      "Batch 53, Loss: 1.5422\n",
      "Batch 54, Loss: 1.4901\n",
      "Batch 55, Loss: 1.4793\n",
      "Batch 56, Loss: 1.5073\n",
      "Batch 57, Loss: 1.5055\n",
      "Batch 58, Loss: 1.5137\n",
      "Batch 59, Loss: 1.4513\n",
      "Batch 60, Loss: 1.5069\n",
      "Batch 61, Loss: 1.4826\n",
      "Batch 62, Loss: 1.4905\n",
      "Batch 63, Loss: 1.4848\n",
      "Batch 64, Loss: 1.4689\n",
      "Batch 65, Loss: 1.4983\n",
      "Batch 66, Loss: 1.4791\n",
      "Batch 67, Loss: 1.4727\n",
      "Batch 68, Loss: 1.5115\n",
      "Batch 69, Loss: 1.4824\n",
      "Batch 70, Loss: 1.5386\n",
      "Batch 71, Loss: 1.4688\n",
      "Batch 72, Loss: 1.4959\n",
      "Batch 73, Loss: 1.5055\n",
      "Batch 74, Loss: 1.4552\n",
      "Batch 75, Loss: 1.4965\n",
      "Batch 76, Loss: 1.5135\n",
      "Batch 77, Loss: 1.5007\n",
      "Batch 78, Loss: 1.4882\n",
      "Batch 79, Loss: 1.4708\n",
      "Batch 80, Loss: 1.5097\n",
      "Batch 81, Loss: 1.4928\n",
      "Batch 82, Loss: 1.4978\n",
      "Batch 83, Loss: 1.4738\n",
      "Batch 84, Loss: 1.5048\n",
      "Batch 85, Loss: 1.4902\n",
      "Batch 86, Loss: 1.5290\n",
      "Batch 87, Loss: 1.4881\n",
      "Batch 88, Loss: 1.4818\n",
      "Batch 89, Loss: 1.5137\n",
      "Batch 90, Loss: 1.4956\n",
      "Batch 91, Loss: 1.4920\n",
      "Batch 92, Loss: 1.5039\n",
      "Batch 93, Loss: 1.4756\n",
      "Batch 94, Loss: 1.5075\n",
      "Batch 95, Loss: 1.4913\n",
      "Batch 96, Loss: 1.5233\n",
      "Batch 97, Loss: 1.4800\n",
      "Batch 98, Loss: 1.4972\n",
      "Batch 99, Loss: 1.4829\n",
      "Batch 100, Loss: 1.4789\n",
      "Batch 101, Loss: 1.5003\n",
      "Batch 102, Loss: 1.5275\n",
      "Batch 103, Loss: 1.4999\n",
      "Batch 104, Loss: 1.4824\n",
      "Batch 105, Loss: 1.5016\n",
      "Batch 106, Loss: 1.5144\n",
      "Batch 107, Loss: 1.5174\n",
      "Batch 108, Loss: 1.4972\n",
      "Batch 109, Loss: 1.4769\n",
      "Batch 110, Loss: 1.5126\n",
      "Batch 111, Loss: 1.4973\n",
      "Batch 112, Loss: 1.4944\n",
      "Batch 113, Loss: 1.5122\n",
      "Batch 114, Loss: 1.4905\n",
      "Batch 115, Loss: 1.4993\n",
      "Batch 116, Loss: 1.5314\n",
      "Batch 117, Loss: 1.5051\n",
      "Batch 118, Loss: 1.5141\n",
      "Batch 119, Loss: 1.5092\n",
      "Batch 120, Loss: 1.4992\n",
      "Batch 121, Loss: 1.4924\n",
      "Batch 122, Loss: 1.4931\n",
      "Batch 123, Loss: 1.4778\n",
      "Batch 124, Loss: 1.4936\n",
      "Batch 125, Loss: 1.4643\n",
      "Batch 126, Loss: 1.4685\n",
      "Batch 127, Loss: 1.5171\n",
      "Batch 128, Loss: 1.4830\n",
      "Batch 129, Loss: 1.4805\n",
      "Batch 130, Loss: 1.4881\n",
      "Batch 131, Loss: 1.5100\n",
      "Batch 132, Loss: 1.5079\n",
      "Batch 133, Loss: 1.4818\n",
      "Batch 134, Loss: 1.4601\n",
      "Batch 135, Loss: 1.4953\n",
      "Batch 136, Loss: 1.5290\n",
      "Batch 137, Loss: 1.4741\n",
      "Batch 138, Loss: 1.5177\n",
      "Batch 139, Loss: 1.4848\n",
      "Batch 140, Loss: 1.4738\n",
      "Batch 141, Loss: 1.5065\n",
      "Batch 142, Loss: 1.4435\n",
      "Batch 143, Loss: 1.4995\n",
      "Batch 144, Loss: 1.5199\n",
      "Batch 145, Loss: 1.4750\n",
      "Batch 146, Loss: 1.4913\n",
      "Batch 147, Loss: 1.5139\n",
      "Batch 148, Loss: 1.4567\n",
      "Batch 149, Loss: 1.5124\n",
      "Batch 150, Loss: 1.5078\n",
      "Batch 151, Loss: 1.4892\n",
      "Batch 152, Loss: 1.5153\n",
      "Batch 153, Loss: 1.5072\n",
      "Batch 154, Loss: 1.5067\n",
      "Batch 155, Loss: 1.5011\n",
      "Batch 156, Loss: 1.4939\n",
      "Batch 157, Loss: 1.5118\n",
      "Batch 158, Loss: 1.5081\n",
      "Batch 159, Loss: 1.4852\n",
      "Batch 160, Loss: 1.4871\n",
      "Batch 161, Loss: 1.5103\n",
      "Batch 162, Loss: 1.5191\n",
      "Batch 163, Loss: 1.4773\n",
      "Batch 164, Loss: 1.4982\n",
      "Batch 165, Loss: 1.4777\n",
      "Batch 166, Loss: 1.4775\n",
      "Batch 167, Loss: 1.4661\n",
      "Batch 168, Loss: 1.5139\n",
      "Batch 169, Loss: 1.5017\n",
      "Batch 170, Loss: 1.5142\n",
      "Batch 171, Loss: 1.4666\n",
      "Batch 172, Loss: 1.4985\n",
      "Batch 173, Loss: 1.4704\n",
      "Batch 174, Loss: 1.5228\n",
      "Batch 175, Loss: 1.4896\n",
      "Batch 176, Loss: 1.5068\n",
      "Batch 177, Loss: 1.4943\n",
      "Batch 178, Loss: 1.4818\n",
      "Batch 179, Loss: 1.4903\n",
      "Batch 180, Loss: 1.4958\n",
      "Batch 181, Loss: 1.4653\n",
      "Batch 182, Loss: 1.5080\n",
      "Batch 183, Loss: 1.5005\n",
      "Batch 184, Loss: 1.4869\n",
      "Batch 185, Loss: 1.5187\n",
      "Batch 186, Loss: 1.4885\n",
      "Batch 187, Loss: 1.4780\n",
      "Batch 188, Loss: 1.5045\n",
      "Batch 189, Loss: 1.4932\n",
      "Batch 190, Loss: 1.4970\n",
      "Batch 191, Loss: 1.4995\n",
      "Batch 192, Loss: 1.4787\n",
      "Batch 193, Loss: 1.5103\n",
      "Batch 194, Loss: 1.4721\n",
      "Batch 195, Loss: 1.4860\n",
      "Batch 196, Loss: 1.5083\n",
      "Batch 197, Loss: 1.4611\n",
      "Batch 198, Loss: 1.4827\n",
      "Batch 199, Loss: 1.5029\n",
      "Batch 200, Loss: 1.4998\n",
      "Batch 201, Loss: 1.5159\n",
      "Batch 202, Loss: 1.4854\n",
      "Batch 203, Loss: 1.5011\n",
      "Batch 204, Loss: 1.5078\n",
      "Batch 205, Loss: 1.4683\n",
      "Batch 206, Loss: 1.5072\n",
      "Batch 207, Loss: 1.4846\n",
      "Batch 208, Loss: 1.4751\n",
      "Batch 209, Loss: 1.4959\n",
      "Batch 210, Loss: 1.4928\n",
      "Batch 211, Loss: 1.4659\n",
      "Batch 212, Loss: 1.4757\n",
      "Batch 213, Loss: 1.4720\n",
      "Batch 214, Loss: 1.4984\n",
      "Batch 215, Loss: 1.4704\n",
      "Batch 216, Loss: 1.5106\n",
      "Batch 217, Loss: 1.4847\n",
      "Batch 218, Loss: 1.4945\n",
      "Batch 219, Loss: 1.5141\n",
      "Batch 220, Loss: 1.4820\n",
      "Batch 221, Loss: 1.4930\n",
      "Batch 222, Loss: 1.4784\n",
      "Batch 223, Loss: 1.5030\n",
      "Batch 224, Loss: 1.4761\n",
      "Batch 225, Loss: 1.5004\n",
      "Batch 226, Loss: 1.4897\n",
      "Batch 227, Loss: 1.5011\n",
      "Batch 228, Loss: 1.5223\n",
      "Batch 229, Loss: 1.4690\n",
      "Batch 230, Loss: 1.5057\n",
      "Batch 231, Loss: 1.4992\n",
      "Batch 232, Loss: 1.4972\n",
      "Batch 233, Loss: 1.4887\n",
      "Batch 234, Loss: 1.4681\n",
      "Batch 235, Loss: 1.5040\n",
      "Batch 236, Loss: 1.4985\n",
      "Batch 237, Loss: 1.4638\n",
      "Batch 238, Loss: 1.4944\n",
      "Batch 239, Loss: 1.4882\n",
      "Batch 240, Loss: 1.4953\n",
      "Batch 241, Loss: 1.4702\n",
      "Batch 242, Loss: 1.5064\n",
      "Batch 243, Loss: 1.5011\n",
      "Batch 244, Loss: 1.5056\n",
      "Batch 245, Loss: 1.4739\n",
      "Batch 246, Loss: 1.5058\n",
      "Batch 247, Loss: 1.4969\n",
      "Batch 248, Loss: 1.5086\n",
      "Batch 249, Loss: 1.5088\n",
      "Batch 250, Loss: 1.4815\n",
      "Batch 251, Loss: 1.5211\n",
      "Batch 252, Loss: 1.4859\n",
      "Batch 253, Loss: 1.5156\n",
      "Batch 254, Loss: 1.5002\n",
      "Batch 255, Loss: 1.4781\n",
      "Batch 256, Loss: 1.5154\n",
      "Batch 257, Loss: 1.4931\n",
      "Batch 258, Loss: 1.4964\n",
      "Batch 259, Loss: 1.4844\n",
      "Batch 260, Loss: 1.4772\n",
      "Batch 261, Loss: 1.5017\n",
      "Batch 262, Loss: 1.4639\n",
      "Batch 263, Loss: 1.4998\n",
      "Batch 264, Loss: 1.4922\n",
      "Batch 265, Loss: 1.5000\n",
      "Batch 266, Loss: 1.5188\n",
      "Batch 267, Loss: 1.4892\n",
      "Batch 268, Loss: 1.5051\n",
      "Batch 269, Loss: 1.4886\n",
      "Batch 270, Loss: 1.4777\n",
      "Batch 271, Loss: 1.4995\n",
      "Batch 272, Loss: 1.4683\n",
      "Batch 273, Loss: 1.4858\n",
      "Batch 274, Loss: 1.4974\n",
      "Batch 275, Loss: 1.5059\n",
      "Batch 276, Loss: 1.5130\n",
      "Batch 277, Loss: 1.4976\n",
      "Batch 278, Loss: 1.4871\n",
      "Batch 279, Loss: 1.5232\n",
      "Batch 280, Loss: 1.4664\n",
      "Batch 281, Loss: 1.4855\n",
      "Batch 282, Loss: 1.4970\n",
      "Batch 283, Loss: 1.4914\n",
      "Batch 284, Loss: 1.4723\n",
      "Batch 285, Loss: 1.5071\n",
      "Batch 286, Loss: 1.4750\n",
      "Batch 287, Loss: 1.5178\n",
      "Batch 288, Loss: 1.5086\n",
      "Batch 289, Loss: 1.4801\n",
      "Batch 290, Loss: 1.4954\n",
      "Batch 291, Loss: 1.5038\n",
      "Batch 292, Loss: 1.4870\n",
      "Batch 293, Loss: 1.5144\n",
      "Batch 294, Loss: 1.4816\n",
      "Batch 295, Loss: 1.4955\n",
      "Batch 296, Loss: 1.5018\n",
      "Batch 297, Loss: 1.4776\n",
      "Batch 298, Loss: 1.4759\n",
      "Batch 299, Loss: 1.5036\n",
      "Batch 300, Loss: 1.5191\n",
      "Batch 301, Loss: 1.4889\n",
      "Batch 302, Loss: 1.5011\n",
      "Batch 303, Loss: 1.4760\n",
      "Batch 304, Loss: 1.5148\n",
      "Batch 305, Loss: 1.4892\n",
      "Batch 306, Loss: 1.4949\n",
      "Batch 307, Loss: 1.4950\n",
      "Batch 308, Loss: 1.4751\n",
      "Batch 309, Loss: 1.4876\n",
      "Batch 310, Loss: 1.4946\n",
      "Batch 311, Loss: 1.4801\n",
      "Batch 312, Loss: 1.4730\n",
      "Batch 313, Loss: 1.4714\n",
      "Batch 314, Loss: 1.4943\n",
      "Batch 315, Loss: 1.4837\n",
      "Batch 316, Loss: 1.4935\n",
      "Batch 317, Loss: 1.5298\n",
      "Batch 318, Loss: 1.5028\n",
      "Batch 319, Loss: 1.4903\n",
      "Batch 320, Loss: 1.4828\n",
      "Batch 321, Loss: 1.5178\n",
      "Batch 322, Loss: 1.4954\n",
      "Batch 323, Loss: 1.4696\n",
      "Batch 324, Loss: 1.4734\n",
      "Batch 325, Loss: 1.5073\n",
      "Batch 326, Loss: 1.4894\n",
      "Batch 327, Loss: 1.4749\n",
      "Batch 328, Loss: 1.4747\n",
      "Batch 329, Loss: 1.4897\n",
      "Batch 330, Loss: 1.4872\n",
      "Batch 331, Loss: 1.4983\n",
      "Batch 332, Loss: 1.4854\n",
      "Batch 333, Loss: 1.4979\n",
      "Batch 334, Loss: 1.5237\n",
      "Batch 335, Loss: 1.4766\n",
      "Batch 336, Loss: 1.4838\n",
      "Batch 337, Loss: 1.4806\n",
      "Batch 338, Loss: 1.5121\n",
      "Batch 339, Loss: 1.4853\n",
      "Batch 340, Loss: 1.4780\n",
      "Batch 341, Loss: 1.4728\n",
      "Batch 342, Loss: 1.4713\n",
      "Batch 343, Loss: 1.4874\n",
      "Batch 344, Loss: 1.4915\n",
      "Batch 345, Loss: 1.5081\n",
      "Batch 346, Loss: 1.5175\n",
      "Batch 347, Loss: 1.5021\n",
      "Batch 348, Loss: 1.4763\n",
      "Batch 349, Loss: 1.4945\n",
      "Batch 350, Loss: 1.5259\n",
      "Batch 351, Loss: 1.4934\n",
      "Batch 352, Loss: 1.4896\n",
      "Batch 353, Loss: 1.4866\n",
      "Batch 354, Loss: 1.4953\n",
      "Batch 355, Loss: 1.4879\n",
      "Batch 356, Loss: 1.4938\n",
      "Batch 357, Loss: 1.4804\n",
      "Batch 358, Loss: 1.4617\n",
      "Batch 359, Loss: 1.4727\n",
      "Batch 360, Loss: 1.4727\n",
      "Batch 361, Loss: 1.4848\n",
      "Batch 362, Loss: 1.4737\n",
      "Batch 363, Loss: 1.4734\n",
      "Batch 364, Loss: 1.4909\n",
      "Batch 365, Loss: 1.4714\n",
      "Batch 366, Loss: 1.4706\n",
      "Batch 367, Loss: 1.4553\n",
      "Batch 368, Loss: 1.4951\n",
      "Batch 369, Loss: 1.4728\n",
      "Batch 370, Loss: 1.4889\n",
      "Batch 371, Loss: 1.4829\n",
      "Batch 372, Loss: 1.5048\n",
      "Batch 373, Loss: 1.4817\n",
      "Batch 374, Loss: 1.5031\n",
      "Batch 375, Loss: 1.5168\n",
      "Batch 376, Loss: 1.4539\n",
      "Batch 377, Loss: 1.4821\n",
      "Batch 378, Loss: 1.4969\n",
      "Batch 379, Loss: 1.4876\n",
      "Batch 380, Loss: 1.4966\n",
      "Batch 381, Loss: 1.5017\n",
      "Batch 382, Loss: 1.4877\n",
      "Batch 383, Loss: 1.5321\n",
      "Batch 384, Loss: 1.5117\n",
      "Batch 385, Loss: 1.4768\n",
      "Batch 386, Loss: 1.4826\n",
      "Batch 387, Loss: 1.4960\n",
      "Batch 388, Loss: 1.5049\n",
      "Batch 389, Loss: 1.4700\n",
      "Batch 390, Loss: 1.4834\n",
      "Batch 391, Loss: 1.5046\n",
      "Batch 392, Loss: 1.4981\n",
      "Batch 393, Loss: 1.4939\n",
      "Batch 394, Loss: 1.5002\n",
      "Batch 395, Loss: 1.4911\n",
      "Batch 396, Loss: 1.5134\n",
      "Batch 397, Loss: 1.5016\n",
      "Batch 398, Loss: 1.4955\n",
      "Batch 399, Loss: 1.4955\n",
      "Batch 400, Loss: 1.4882\n",
      "Batch 401, Loss: 1.4715\n",
      "Batch 402, Loss: 1.5231\n",
      "Batch 403, Loss: 1.4944\n",
      "Batch 404, Loss: 1.4733\n",
      "Batch 405, Loss: 1.4829\n",
      "Batch 406, Loss: 1.4591\n",
      "Batch 407, Loss: 1.4793\n",
      "Batch 408, Loss: 1.5026\n",
      "Batch 409, Loss: 1.4748\n",
      "Batch 410, Loss: 1.4887\n",
      "Batch 411, Loss: 1.4773\n",
      "Batch 412, Loss: 1.4912\n",
      "Batch 413, Loss: 1.4799\n",
      "Batch 414, Loss: 1.4923\n",
      "Batch 415, Loss: 1.4791\n",
      "Batch 416, Loss: 1.4996\n",
      "Batch 417, Loss: 1.4879\n",
      "Batch 418, Loss: 1.4807\n",
      "Batch 419, Loss: 1.4836\n",
      "Batch 420, Loss: 1.5157\n",
      "Batch 421, Loss: 1.4864\n",
      "Batch 422, Loss: 1.4832\n",
      "Batch 423, Loss: 1.5039\n",
      "Batch 424, Loss: 1.5017\n",
      "Batch 425, Loss: 1.5000\n",
      "Batch 426, Loss: 1.4922\n",
      "Batch 427, Loss: 1.4993\n",
      "Batch 428, Loss: 1.4773\n",
      "Batch 429, Loss: 1.5120\n",
      "Batch 430, Loss: 1.4860\n",
      "Batch 431, Loss: 1.4820\n",
      "Batch 432, Loss: 1.4913\n",
      "Batch 433, Loss: 1.4685\n",
      "Batch 434, Loss: 1.5069\n",
      "Batch 435, Loss: 1.4940\n",
      "Batch 436, Loss: 1.4882\n",
      "Batch 437, Loss: 1.4986\n",
      "Batch 438, Loss: 1.4964\n",
      "Batch 439, Loss: 1.5008\n",
      "Batch 440, Loss: 1.4631\n",
      "Batch 441, Loss: 1.4874\n",
      "Batch 442, Loss: 1.4791\n",
      "Batch 443, Loss: 1.5002\n",
      "Batch 444, Loss: 1.4882\n",
      "Batch 445, Loss: 1.4761\n",
      "Batch 446, Loss: 1.5045\n",
      "Batch 447, Loss: 1.4889\n",
      "Batch 448, Loss: 1.4925\n",
      "Batch 449, Loss: 1.4907\n",
      "Batch 450, Loss: 1.4859\n",
      "Batch 451, Loss: 1.5021\n",
      "Batch 452, Loss: 1.5004\n",
      "Batch 453, Loss: 1.4931\n",
      "Batch 454, Loss: 1.4740\n",
      "Batch 455, Loss: 1.4883\n",
      "Batch 456, Loss: 1.4649\n",
      "Batch 457, Loss: 1.5116\n",
      "Batch 458, Loss: 1.4889\n",
      "Batch 459, Loss: 1.4975\n",
      "Batch 460, Loss: 1.5085\n",
      "Batch 461, Loss: 1.4657\n",
      "Batch 462, Loss: 1.5072\n",
      "Batch 463, Loss: 1.4611\n",
      "Batch 464, Loss: 1.5135\n",
      "Batch 465, Loss: 1.4951\n",
      "Batch 466, Loss: 1.4807\n",
      "Batch 467, Loss: 1.4737\n",
      "Batch 468, Loss: 1.4853\n",
      "Batch 469, Loss: 1.4643\n",
      "Batch 470, Loss: 1.4882\n",
      "Batch 471, Loss: 1.4993\n",
      "Batch 472, Loss: 1.4722\n",
      "Batch 473, Loss: 1.4699\n",
      "Batch 474, Loss: 1.4715\n",
      "Batch 475, Loss: 1.4945\n",
      "Batch 476, Loss: 1.4705\n",
      "Batch 477, Loss: 1.4620\n",
      "Batch 478, Loss: 1.4843\n",
      "Batch 479, Loss: 1.4625\n",
      "Batch 480, Loss: 1.4951\n",
      "Batch 481, Loss: 1.4912\n",
      "Batch 482, Loss: 1.4477\n",
      "Batch 483, Loss: 1.4941\n",
      "Once upon a time, there was a little girl named Grace. Grace liked to play in the garden and run together to find new places. \n",
      "But after a while, she got stuck in a big, jug coming and Jane's leg house without feeling weak. In the garden the corner's legs \n",
      "head yellow, a child: \"Grace, I'll help you wipe this garden, Grace, I'm just a change us!' Just then, Grace will be here to help \n",
      "her. She asked if she would help me make something said he could help her. Jane thought for a moment and then asked Grace if \n",
      "she could help. The 3 grace, nodded and grabbed her appro of his arms in the garden. Grace was relieved to be careful now and \n",
      "helpful. She picked up all the way they led them and bolded them closely inside. Then, a kind old lady said: \"Grace and you have \n",
      "lots of fun!\" The leg smile ran in and the other changed all the other change worm vanillage. They wor all like helps together. \n",
      "\n",
      "--------------------\n",
      "Batch 484, Loss: 1.5047\n",
      "Batch 485, Loss: 1.5086\n",
      "Batch 486, Loss: 1.4718\n",
      "Batch 487, Loss: 1.4844\n",
      "Batch 488, Loss: 1.5233\n",
      "Batch 489, Loss: 1.4534\n",
      "Batch 490, Loss: 1.4776\n",
      "Batch 491, Loss: 1.4951\n",
      "Batch 492, Loss: 1.5089\n",
      "Batch 493, Loss: 1.4983\n",
      "Batch 494, Loss: 1.5116\n",
      "Batch 495, Loss: 1.4900\n",
      "Batch 496, Loss: 1.4771\n",
      "Batch 497, Loss: 1.4949\n",
      "Batch 498, Loss: 1.4676\n",
      "Batch 499, Loss: 1.4783\n",
      "Batch 500, Loss: 1.4692\n",
      "Batch 501, Loss: 1.4978\n",
      "Batch 502, Loss: 1.4983\n",
      "Batch 503, Loss: 1.4926\n",
      "Batch 504, Loss: 1.4721\n",
      "Batch 505, Loss: 1.4902\n",
      "Batch 506, Loss: 1.4910\n",
      "Batch 507, Loss: 1.4947\n",
      "Batch 508, Loss: 1.4739\n",
      "Batch 509, Loss: 1.4715\n",
      "Batch 510, Loss: 1.4658\n",
      "Batch 511, Loss: 1.4887\n",
      "Batch 512, Loss: 1.4639\n",
      "Batch 513, Loss: 1.4965\n",
      "Batch 514, Loss: 1.4834\n",
      "Batch 515, Loss: 1.4967\n",
      "Batch 516, Loss: 1.5022\n",
      "Batch 517, Loss: 1.4912\n",
      "Batch 518, Loss: 1.5063\n",
      "Batch 519, Loss: 1.4922\n",
      "Batch 520, Loss: 1.4865\n",
      "Batch 521, Loss: 1.4929\n",
      "Batch 522, Loss: 1.4704\n",
      "Batch 523, Loss: 1.4678\n",
      "Batch 524, Loss: 1.4610\n",
      "Batch 525, Loss: 1.4886\n",
      "Batch 526, Loss: 1.5147\n",
      "Batch 527, Loss: 1.4687\n",
      "Batch 528, Loss: 1.4883\n",
      "Batch 529, Loss: 1.4539\n",
      "Batch 530, Loss: 1.4884\n",
      "Batch 531, Loss: 1.4959\n",
      "Batch 532, Loss: 1.4830\n",
      "Batch 533, Loss: 1.4908\n",
      "Batch 534, Loss: 1.4825\n",
      "Batch 535, Loss: 1.5168\n",
      "Batch 536, Loss: 1.4579\n",
      "Batch 537, Loss: 1.4986\n",
      "Batch 538, Loss: 1.4866\n",
      "Batch 539, Loss: 1.5308\n",
      "Batch 540, Loss: 1.4904\n",
      "Batch 541, Loss: 1.4658\n",
      "Batch 542, Loss: 1.4960\n",
      "Batch 543, Loss: 1.4797\n",
      "Batch 544, Loss: 1.4663\n",
      "Batch 545, Loss: 1.4579\n",
      "Batch 546, Loss: 1.5200\n",
      "Batch 547, Loss: 1.4784\n",
      "Batch 548, Loss: 1.4739\n",
      "Batch 549, Loss: 1.5041\n",
      "Batch 550, Loss: 1.4903\n",
      "Batch 551, Loss: 1.5062\n",
      "Batch 552, Loss: 1.4855\n",
      "Batch 553, Loss: 1.4717\n",
      "Batch 554, Loss: 1.4904\n",
      "Batch 555, Loss: 1.5264\n",
      "Batch 556, Loss: 1.4964\n",
      "Batch 557, Loss: 1.4743\n",
      "Batch 558, Loss: 1.4782\n",
      "Batch 559, Loss: 1.5058\n",
      "Batch 560, Loss: 1.4812\n",
      "Batch 561, Loss: 1.4810\n",
      "Batch 562, Loss: 1.5004\n",
      "Batch 563, Loss: 1.4868\n",
      "Batch 564, Loss: 1.4762\n",
      "Batch 565, Loss: 1.4787\n",
      "Batch 566, Loss: 1.4790\n",
      "Batch 567, Loss: 1.5216\n",
      "Batch 568, Loss: 1.4817\n",
      "Batch 569, Loss: 1.4996\n",
      "Batch 570, Loss: 1.4883\n",
      "Batch 571, Loss: 1.4984\n",
      "Batch 572, Loss: 1.5473\n",
      "Batch 573, Loss: 1.4485\n",
      "Batch 574, Loss: 1.4659\n",
      "Batch 575, Loss: 1.5117\n",
      "Batch 576, Loss: 1.4830\n",
      "Batch 577, Loss: 1.4558\n",
      "Batch 578, Loss: 1.4886\n",
      "Batch 579, Loss: 1.4802\n",
      "Batch 580, Loss: 1.4510\n",
      "Batch 581, Loss: 1.4574\n",
      "Batch 582, Loss: 1.4613\n",
      "Batch 583, Loss: 1.4867\n",
      "Batch 584, Loss: 1.4817\n",
      "Batch 585, Loss: 1.4904\n",
      "Batch 586, Loss: 1.4990\n",
      "Batch 587, Loss: 1.4856\n",
      "Batch 588, Loss: 1.4884\n",
      "Batch 589, Loss: 1.4641\n",
      "Batch 590, Loss: 1.4995\n",
      "Batch 591, Loss: 1.4608\n",
      "Batch 592, Loss: 1.5099\n",
      "Batch 593, Loss: 1.5188\n",
      "Batch 594, Loss: 1.4672\n",
      "Batch 595, Loss: 1.4746\n",
      "Batch 596, Loss: 1.4665\n",
      "Batch 597, Loss: 1.4959\n",
      "Batch 598, Loss: 1.5090\n",
      "Batch 599, Loss: 1.4712\n",
      "Batch 600, Loss: 1.4785\n",
      "Batch 601, Loss: 1.4698\n",
      "Batch 602, Loss: 1.4992\n",
      "Batch 603, Loss: 1.4834\n",
      "Batch 604, Loss: 1.4747\n",
      "Batch 605, Loss: 1.5063\n",
      "Batch 606, Loss: 1.5036\n",
      "Batch 607, Loss: 1.4703\n",
      "Batch 608, Loss: 1.5024\n",
      "Batch 609, Loss: 1.5195\n",
      "Batch 610, Loss: 1.4966\n",
      "Batch 611, Loss: 1.4560\n",
      "Batch 612, Loss: 1.4834\n",
      "Batch 613, Loss: 1.4963\n",
      "Batch 614, Loss: 1.4704\n",
      "Batch 615, Loss: 1.4563\n",
      "Batch 616, Loss: 1.4939\n",
      "Batch 617, Loss: 1.4862\n",
      "Batch 618, Loss: 1.4826\n",
      "Batch 619, Loss: 1.4599\n",
      "Batch 620, Loss: 1.4949\n",
      "Batch 621, Loss: 1.4794\n",
      "Batch 622, Loss: 1.4285\n",
      "Batch 623, Loss: 1.4856\n",
      "Batch 624, Loss: 1.4983\n",
      "Batch 625, Loss: 1.4827\n",
      "Batch 626, Loss: 1.5113\n",
      "Batch 627, Loss: 1.4771\n",
      "Batch 628, Loss: 1.4958\n",
      "Batch 629, Loss: 1.5057\n",
      "Batch 630, Loss: 1.4899\n",
      "Batch 631, Loss: 1.4816\n",
      "Batch 632, Loss: 1.4530\n",
      "Batch 633, Loss: 1.4821\n",
      "Batch 634, Loss: 1.4936\n",
      "Batch 635, Loss: 1.4749\n",
      "Batch 636, Loss: 1.4555\n",
      "Batch 637, Loss: 1.4946\n",
      "Batch 638, Loss: 1.4912\n",
      "Batch 639, Loss: 1.5164\n",
      "Batch 640, Loss: 1.4890\n",
      "Batch 641, Loss: 1.4935\n",
      "Batch 642, Loss: 1.4674\n",
      "Batch 643, Loss: 1.4617\n",
      "Batch 644, Loss: 1.4810\n",
      "Batch 645, Loss: 1.4768\n",
      "Batch 646, Loss: 1.4903\n",
      "Batch 647, Loss: 1.4829\n",
      "Batch 648, Loss: 1.5226\n",
      "Batch 649, Loss: 1.4833\n",
      "Batch 650, Loss: 1.4922\n",
      "Batch 651, Loss: 1.4880\n",
      "Batch 652, Loss: 1.4662\n",
      "Batch 653, Loss: 1.4659\n",
      "Batch 654, Loss: 1.4732\n",
      "Batch 655, Loss: 1.4715\n",
      "Batch 656, Loss: 1.4687\n",
      "Batch 657, Loss: 1.4893\n",
      "Batch 658, Loss: 1.4780\n",
      "Batch 659, Loss: 1.4975\n",
      "Batch 660, Loss: 1.4753\n",
      "Batch 661, Loss: 1.4710\n",
      "Batch 662, Loss: 1.5011\n",
      "Batch 663, Loss: 1.4776\n",
      "Batch 664, Loss: 1.4935\n",
      "Batch 665, Loss: 1.4824\n",
      "Batch 666, Loss: 1.4836\n",
      "Batch 667, Loss: 1.4631\n",
      "Batch 668, Loss: 1.4875\n",
      "Batch 669, Loss: 1.4839\n",
      "Batch 670, Loss: 1.4673\n",
      "Batch 671, Loss: 1.4735\n",
      "Batch 672, Loss: 1.4771\n",
      "Batch 673, Loss: 1.4822\n",
      "Batch 674, Loss: 1.4746\n",
      "Batch 675, Loss: 1.4992\n",
      "Batch 676, Loss: 1.4836\n",
      "Batch 677, Loss: 1.4973\n",
      "Batch 678, Loss: 1.4877\n",
      "Batch 679, Loss: 1.4948\n",
      "Batch 680, Loss: 1.4521\n",
      "Batch 681, Loss: 1.4949\n",
      "Batch 682, Loss: 1.4852\n",
      "Batch 683, Loss: 1.4727\n",
      "Batch 684, Loss: 1.4626\n",
      "Batch 685, Loss: 1.4735\n",
      "Batch 686, Loss: 1.4831\n",
      "Batch 687, Loss: 1.4878\n",
      "Batch 688, Loss: 1.4840\n",
      "Batch 689, Loss: 1.4585\n",
      "Batch 690, Loss: 1.4990\n",
      "Batch 691, Loss: 1.4812\n",
      "Batch 692, Loss: 1.4828\n",
      "Batch 693, Loss: 1.4621\n",
      "Batch 694, Loss: 1.4782\n",
      "Batch 695, Loss: 1.4733\n",
      "Batch 696, Loss: 1.4984\n",
      "Batch 697, Loss: 1.4868\n",
      "Batch 698, Loss: 1.4532\n",
      "Batch 699, Loss: 1.5055\n",
      "Batch 700, Loss: 1.4681\n",
      "Batch 701, Loss: 1.4852\n",
      "Batch 702, Loss: 1.4989\n",
      "Batch 703, Loss: 1.4713\n",
      "Batch 704, Loss: 1.4467\n",
      "Batch 705, Loss: 1.4946\n",
      "Batch 706, Loss: 1.4803\n",
      "Batch 707, Loss: 1.4743\n",
      "Batch 708, Loss: 1.4642\n",
      "Batch 709, Loss: 1.4858\n",
      "Batch 710, Loss: 1.4676\n",
      "Batch 711, Loss: 1.4669\n",
      "Batch 712, Loss: 1.4797\n",
      "Batch 713, Loss: 1.4654\n",
      "Batch 714, Loss: 1.4857\n",
      "Batch 715, Loss: 1.4966\n",
      "Batch 716, Loss: 1.4988\n",
      "Batch 717, Loss: 1.4567\n",
      "Batch 718, Loss: 1.4763\n",
      "Batch 719, Loss: 1.4909\n",
      "Batch 720, Loss: 1.4764\n",
      "Batch 721, Loss: 1.4996\n",
      "Batch 722, Loss: 1.5113\n",
      "Batch 723, Loss: 1.4908\n",
      "Batch 724, Loss: 1.4731\n",
      "Batch 725, Loss: 1.4977\n",
      "Batch 726, Loss: 1.4662\n",
      "Batch 727, Loss: 1.4816\n",
      "Batch 728, Loss: 1.4753\n",
      "Batch 729, Loss: 1.4731\n",
      "Batch 730, Loss: 1.5078\n",
      "Batch 731, Loss: 1.4808\n",
      "Batch 732, Loss: 1.4896\n",
      "Batch 733, Loss: 1.4794\n",
      "Batch 734, Loss: 1.4894\n",
      "Batch 735, Loss: 1.4762\n",
      "Batch 736, Loss: 1.4600\n",
      "Batch 737, Loss: 1.4839\n",
      "Batch 738, Loss: 1.4736\n",
      "Batch 739, Loss: 1.4664\n",
      "Batch 740, Loss: 1.4703\n",
      "Batch 741, Loss: 1.4557\n",
      "Batch 742, Loss: 1.4531\n",
      "Batch 743, Loss: 1.4576\n",
      "Batch 744, Loss: 1.4824\n",
      "Batch 745, Loss: 1.4653\n",
      "Batch 746, Loss: 1.4793\n",
      "Batch 747, Loss: 1.5031\n",
      "Batch 748, Loss: 1.4857\n",
      "Batch 749, Loss: 1.4941\n",
      "Batch 750, Loss: 1.4629\n",
      "Batch 751, Loss: 1.4808\n",
      "Batch 752, Loss: 1.4636\n",
      "Batch 753, Loss: 1.4863\n",
      "Batch 754, Loss: 1.5040\n",
      "Batch 755, Loss: 1.4868\n",
      "Batch 756, Loss: 1.4869\n",
      "Batch 757, Loss: 1.4778\n",
      "Batch 758, Loss: 1.4650\n",
      "Batch 759, Loss: 1.4626\n",
      "Batch 760, Loss: 1.4764\n",
      "Batch 761, Loss: 1.4687\n",
      "Batch 762, Loss: 1.4723\n",
      "Batch 763, Loss: 1.4757\n",
      "Batch 764, Loss: 1.4734\n",
      "Batch 765, Loss: 1.4941\n",
      "Batch 766, Loss: 1.5116\n",
      "Batch 767, Loss: 1.4753\n",
      "Batch 768, Loss: 1.4727\n",
      "Batch 769, Loss: 1.4725\n",
      "Batch 770, Loss: 1.4878\n",
      "Batch 771, Loss: 1.4888\n",
      "Batch 772, Loss: 1.4799\n",
      "Batch 773, Loss: 1.4684\n",
      "Batch 774, Loss: 1.4315\n",
      "Batch 775, Loss: 1.4792\n",
      "Batch 776, Loss: 1.4663\n",
      "Batch 777, Loss: 1.4859\n",
      "Batch 778, Loss: 1.4638\n",
      "Batch 779, Loss: 1.4525\n",
      "Batch 780, Loss: 1.4784\n",
      "Batch 781, Loss: 1.4815\n",
      "Batch 782, Loss: 1.4783\n",
      "Batch 783, Loss: 1.4746\n",
      "Batch 784, Loss: 1.4732\n",
      "Batch 785, Loss: 1.4858\n",
      "Batch 786, Loss: 1.4915\n",
      "Batch 787, Loss: 1.4682\n",
      "Batch 788, Loss: 1.4815\n",
      "Batch 789, Loss: 1.4602\n",
      "Batch 790, Loss: 1.4465\n",
      "Batch 791, Loss: 1.4799\n",
      "Batch 792, Loss: 1.4912\n",
      "Batch 793, Loss: 1.4665\n",
      "Batch 794, Loss: 1.4739\n",
      "Batch 795, Loss: 1.4866\n",
      "Batch 796, Loss: 1.5048\n",
      "Batch 797, Loss: 1.4989\n",
      "Batch 798, Loss: 1.4559\n",
      "Batch 799, Loss: 1.4893\n",
      "Batch 800, Loss: 1.5140\n",
      "Batch 801, Loss: 1.4850\n",
      "Batch 802, Loss: 1.4702\n",
      "Batch 803, Loss: 1.4748\n",
      "Batch 804, Loss: 1.4606\n",
      "Batch 805, Loss: 1.4735\n",
      "Batch 806, Loss: 1.4640\n",
      "Batch 807, Loss: 1.4905\n",
      "Batch 808, Loss: 1.5297\n",
      "Batch 809, Loss: 1.4568\n",
      "Batch 810, Loss: 1.4679\n",
      "Batch 811, Loss: 1.4723\n",
      "Batch 812, Loss: 1.4995\n",
      "Batch 813, Loss: 1.4823\n",
      "Batch 814, Loss: 1.4929\n",
      "Batch 815, Loss: 1.4526\n",
      "Batch 816, Loss: 1.4800\n",
      "Batch 817, Loss: 1.5114\n",
      "Batch 818, Loss: 1.4544\n",
      "Batch 819, Loss: 1.4783\n",
      "Batch 820, Loss: 1.4843\n",
      "Batch 821, Loss: 1.4672\n",
      "Batch 822, Loss: 1.4799\n",
      "Batch 823, Loss: 1.4602\n",
      "Batch 824, Loss: 1.4675\n",
      "Batch 825, Loss: 1.4824\n",
      "Batch 826, Loss: 1.4794\n",
      "Batch 827, Loss: 1.4647\n",
      "Batch 828, Loss: 1.4691\n",
      "Batch 829, Loss: 1.4601\n",
      "Batch 830, Loss: 1.4612\n",
      "Batch 831, Loss: 1.4793\n",
      "Batch 832, Loss: 1.4921\n",
      "Batch 833, Loss: 1.4784\n",
      "Batch 834, Loss: 1.4906\n",
      "Batch 835, Loss: 1.4653\n",
      "Batch 836, Loss: 1.4920\n",
      "Batch 837, Loss: 1.4864\n",
      "Batch 838, Loss: 1.4977\n",
      "Batch 839, Loss: 1.4704\n",
      "Batch 840, Loss: 1.5035\n",
      "Batch 841, Loss: 1.4789\n",
      "Batch 842, Loss: 1.4603\n",
      "Batch 843, Loss: 1.4657\n",
      "Batch 844, Loss: 1.4597\n",
      "Batch 845, Loss: 1.4591\n",
      "Batch 846, Loss: 1.4919\n",
      "Batch 847, Loss: 1.4533\n",
      "Batch 848, Loss: 1.4980\n",
      "Batch 849, Loss: 1.4844\n",
      "Batch 850, Loss: 1.4727\n",
      "Batch 851, Loss: 1.4482\n",
      "Batch 852, Loss: 1.4688\n",
      "Batch 853, Loss: 1.4848\n",
      "Batch 854, Loss: 1.4977\n",
      "Batch 855, Loss: 1.4519\n",
      "Batch 856, Loss: 1.4762\n",
      "Batch 857, Loss: 1.4722\n",
      "Batch 858, Loss: 1.4348\n",
      "Batch 859, Loss: 1.5001\n",
      "Batch 860, Loss: 1.4611\n",
      "Batch 861, Loss: 1.4805\n",
      "Batch 862, Loss: 1.4701\n",
      "Batch 863, Loss: 1.4623\n",
      "Batch 864, Loss: 1.4603\n",
      "Batch 865, Loss: 1.4660\n",
      "Batch 866, Loss: 1.4526\n",
      "Batch 867, Loss: 1.4548\n",
      "Batch 868, Loss: 1.4768\n",
      "Batch 869, Loss: 1.4865\n",
      "Batch 870, Loss: 1.4705\n",
      "Batch 871, Loss: 1.4736\n",
      "Batch 872, Loss: 1.4649\n",
      "Batch 873, Loss: 1.4934\n",
      "Batch 874, Loss: 1.4840\n",
      "Batch 875, Loss: 1.4721\n",
      "Batch 876, Loss: 1.4778\n",
      "Batch 877, Loss: 1.4456\n",
      "Batch 878, Loss: 1.5050\n",
      "Batch 879, Loss: 1.5158\n",
      "Batch 880, Loss: 1.4641\n",
      "Batch 881, Loss: 1.4852\n",
      "Batch 882, Loss: 1.4318\n",
      "Batch 883, Loss: 1.4575\n",
      "Batch 884, Loss: 1.4658\n",
      "Batch 885, Loss: 1.4596\n",
      "Batch 886, Loss: 1.4928\n",
      "Batch 887, Loss: 1.4386\n",
      "Batch 888, Loss: 1.4718\n",
      "Batch 889, Loss: 1.4837\n",
      "Batch 890, Loss: 1.4731\n",
      "Batch 891, Loss: 1.4708\n",
      "Batch 892, Loss: 1.4942\n",
      "Batch 893, Loss: 1.4669\n",
      "Batch 894, Loss: 1.4638\n",
      "Batch 895, Loss: 1.4911\n",
      "Batch 896, Loss: 1.4367\n",
      "Batch 897, Loss: 1.4805\n",
      "Batch 898, Loss: 1.4692\n",
      "Batch 899, Loss: 1.4750\n",
      "Batch 900, Loss: 1.4556\n",
      "Batch 901, Loss: 1.4907\n",
      "Batch 902, Loss: 1.4546\n",
      "Batch 903, Loss: 1.5000\n",
      "Batch 904, Loss: 1.4551\n",
      "Batch 905, Loss: 1.4694\n",
      "Batch 906, Loss: 1.4903\n",
      "Batch 907, Loss: 1.4412\n",
      "Batch 908, Loss: 1.4887\n",
      "Batch 909, Loss: 1.4763\n",
      "Batch 910, Loss: 1.4890\n",
      "Batch 911, Loss: 1.4829\n",
      "Batch 912, Loss: 1.4954\n",
      "Batch 913, Loss: 1.4618\n",
      "Batch 914, Loss: 1.4761\n",
      "Batch 915, Loss: 1.4773\n",
      "Batch 916, Loss: 1.4723\n",
      "Batch 917, Loss: 1.4732\n",
      "Batch 918, Loss: 1.4740\n",
      "Batch 919, Loss: 1.4932\n",
      "Batch 920, Loss: 1.4696\n",
      "Batch 921, Loss: 1.4653\n",
      "Batch 922, Loss: 1.5062\n",
      "Batch 923, Loss: 1.4694\n",
      "Batch 924, Loss: 1.4851\n",
      "Batch 925, Loss: 1.4764\n",
      "Batch 926, Loss: 1.4756\n",
      "Batch 927, Loss: 1.4800\n",
      "Batch 928, Loss: 1.4614\n",
      "Batch 929, Loss: 1.4728\n",
      "Batch 930, Loss: 1.4817\n",
      "Batch 931, Loss: 1.4665\n",
      "Batch 932, Loss: 1.4978\n",
      "Batch 933, Loss: 1.4883\n",
      "Batch 934, Loss: 1.4526\n",
      "Batch 935, Loss: 1.4706\n",
      "Batch 936, Loss: 1.4867\n",
      "Batch 937, Loss: 1.4741\n",
      "Batch 938, Loss: 1.4801\n",
      "Batch 939, Loss: 1.4764\n",
      "Batch 940, Loss: 1.4865\n",
      "Batch 941, Loss: 1.4457\n",
      "Batch 942, Loss: 1.4682\n",
      "Batch 943, Loss: 1.4791\n",
      "Batch 944, Loss: 1.4511\n",
      "Batch 945, Loss: 1.4633\n",
      "Batch 946, Loss: 1.4792\n",
      "Batch 947, Loss: 1.4959\n",
      "Batch 948, Loss: 1.4941\n",
      "Batch 949, Loss: 1.4652\n",
      "Batch 950, Loss: 1.4947\n",
      "Batch 951, Loss: 1.4477\n",
      "Batch 952, Loss: 1.4925\n",
      "Batch 953, Loss: 1.4547\n",
      "Batch 954, Loss: 1.4724\n",
      "Batch 955, Loss: 1.4796\n",
      "Batch 956, Loss: 1.4875\n",
      "Batch 957, Loss: 1.4707\n",
      "Batch 958, Loss: 1.4591\n",
      "Batch 959, Loss: 1.4559\n",
      "Batch 960, Loss: 1.4767\n",
      "Batch 961, Loss: 1.4702\n",
      "Batch 962, Loss: 1.4732\n",
      "Batch 963, Loss: 1.4665\n",
      "Batch 964, Loss: 1.4873\n",
      "Batch 965, Loss: 1.4829\n",
      "Epoch 5, Average Loss: 1.4858\n",
      "Once upon a time, there was a small bunny named Liso. He was very hungry and wanted to east somes. Liso was so surprised and \n",
      "hugged Liso to see the big, brown tree. Liso asked Liso what kind of tree to like. Instead, he could use lots of pieces. Liso \n",
      "felt so excited. He decided to take a duck far away from Liso. All of a sudden, Liso noticed it was annusy nearby. He barked \n",
      "and picked up the brownning and called him over to his ducks. They both ate the tree all by making sure there was a little \n",
      "butterflies. Suddenly, Liso started to rise away forever. Liso was so surprised that he looked acting new and remembered what the brightest first mech of \n",
      "the guest duck in his gard. He barked in agreement and shouted, \"I could use your mappet the cloudhes!\" Liso said, \"I can easily my \n",
      "little one. It felt a huge game of how deep deep she was your friend. I can help you!\" Liso was so thanked Liso and \n",
      "hopped his finger. She knew that this is a moral power of friends, and the shower the time we're hungry. \n",
      "\n",
      "--------------------\n",
      "Batch 0, Loss: 1.4678\n",
      "Batch 1, Loss: 1.4573\n",
      "Batch 2, Loss: 1.4642\n",
      "Batch 3, Loss: 1.4811\n",
      "Batch 4, Loss: 1.4506\n",
      "Batch 5, Loss: 1.4325\n",
      "Batch 6, Loss: 1.4560\n",
      "Batch 7, Loss: 1.4788\n",
      "Batch 8, Loss: 1.4368\n",
      "Batch 9, Loss: 1.4472\n",
      "Batch 10, Loss: 1.4647\n",
      "Batch 11, Loss: 1.4551\n",
      "Batch 12, Loss: 1.4755\n",
      "Batch 13, Loss: 1.4700\n",
      "Batch 14, Loss: 1.4440\n",
      "Batch 15, Loss: 1.4773\n",
      "Batch 16, Loss: 1.4600\n",
      "Batch 17, Loss: 1.4753\n",
      "Batch 18, Loss: 1.4353\n",
      "Batch 19, Loss: 1.4942\n",
      "Batch 20, Loss: 1.4655\n",
      "Batch 21, Loss: 1.4458\n",
      "Batch 22, Loss: 1.4496\n",
      "Batch 23, Loss: 1.4789\n",
      "Batch 24, Loss: 1.4747\n",
      "Batch 25, Loss: 1.4487\n",
      "Batch 26, Loss: 1.4722\n",
      "Batch 27, Loss: 1.4475\n",
      "Batch 28, Loss: 1.4467\n",
      "Batch 29, Loss: 1.4494\n",
      "Batch 30, Loss: 1.4805\n",
      "Batch 31, Loss: 1.4649\n",
      "Batch 32, Loss: 1.4582\n",
      "Batch 33, Loss: 1.4351\n",
      "Batch 34, Loss: 1.4775\n",
      "Batch 35, Loss: 1.4577\n",
      "Batch 36, Loss: 1.4775\n",
      "Batch 37, Loss: 1.4766\n",
      "Batch 38, Loss: 1.4974\n",
      "Batch 39, Loss: 1.4535\n",
      "Batch 40, Loss: 1.4694\n",
      "Batch 41, Loss: 1.4447\n",
      "Batch 42, Loss: 1.4440\n",
      "Batch 43, Loss: 1.4585\n",
      "Batch 44, Loss: 1.4511\n",
      "Batch 45, Loss: 1.4854\n",
      "Batch 46, Loss: 1.4789\n",
      "Batch 47, Loss: 1.4585\n",
      "Batch 48, Loss: 1.4808\n",
      "Batch 49, Loss: 1.4868\n",
      "Batch 50, Loss: 1.4716\n",
      "Batch 51, Loss: 1.4836\n",
      "Batch 52, Loss: 1.4295\n",
      "Batch 53, Loss: 1.4639\n",
      "Batch 54, Loss: 1.4710\n",
      "Batch 55, Loss: 1.4665\n",
      "Batch 56, Loss: 1.4592\n",
      "Batch 57, Loss: 1.4646\n",
      "Batch 58, Loss: 1.4332\n",
      "Batch 59, Loss: 1.4557\n",
      "Batch 60, Loss: 1.4691\n",
      "Batch 61, Loss: 1.4826\n",
      "Batch 62, Loss: 1.4601\n",
      "Batch 63, Loss: 1.4668\n",
      "Batch 64, Loss: 1.4555\n",
      "Batch 65, Loss: 1.4654\n",
      "Batch 66, Loss: 1.4684\n",
      "Batch 67, Loss: 1.4690\n",
      "Batch 68, Loss: 1.4520\n",
      "Batch 69, Loss: 1.4681\n",
      "Batch 70, Loss: 1.4648\n",
      "Batch 71, Loss: 1.4242\n",
      "Batch 72, Loss: 1.4757\n",
      "Batch 73, Loss: 1.4761\n",
      "Batch 74, Loss: 1.4547\n",
      "Batch 75, Loss: 1.4626\n",
      "Batch 76, Loss: 1.5030\n",
      "Batch 77, Loss: 1.4668\n",
      "Batch 78, Loss: 1.4900\n",
      "Batch 79, Loss: 1.4791\n",
      "Batch 80, Loss: 1.4716\n",
      "Batch 81, Loss: 1.4648\n",
      "Batch 82, Loss: 1.4698\n",
      "Batch 83, Loss: 1.4398\n",
      "Batch 84, Loss: 1.4821\n",
      "Batch 85, Loss: 1.4640\n",
      "Batch 86, Loss: 1.4672\n",
      "Batch 87, Loss: 1.4737\n",
      "Batch 88, Loss: 1.4647\n",
      "Batch 89, Loss: 1.4541\n",
      "Batch 90, Loss: 1.4540\n",
      "Batch 91, Loss: 1.4620\n",
      "Batch 92, Loss: 1.4841\n",
      "Batch 93, Loss: 1.4746\n",
      "Batch 94, Loss: 1.4722\n",
      "Batch 95, Loss: 1.4443\n",
      "Batch 96, Loss: 1.4708\n",
      "Batch 97, Loss: 1.4600\n",
      "Batch 98, Loss: 1.4396\n",
      "Batch 99, Loss: 1.4702\n",
      "Batch 100, Loss: 1.4695\n",
      "Batch 101, Loss: 1.4595\n",
      "Batch 102, Loss: 1.4691\n",
      "Batch 103, Loss: 1.4491\n",
      "Batch 104, Loss: 1.4689\n",
      "Batch 105, Loss: 1.4654\n",
      "Batch 106, Loss: 1.4645\n",
      "Batch 107, Loss: 1.4740\n",
      "Batch 108, Loss: 1.4591\n",
      "Batch 109, Loss: 1.4489\n",
      "Batch 110, Loss: 1.4711\n",
      "Batch 111, Loss: 1.4804\n",
      "Batch 112, Loss: 1.4819\n",
      "Batch 113, Loss: 1.4709\n",
      "Batch 114, Loss: 1.4989\n",
      "Batch 115, Loss: 1.4268\n",
      "Batch 116, Loss: 1.4485\n",
      "Batch 117, Loss: 1.4422\n",
      "Batch 118, Loss: 1.4706\n",
      "Batch 119, Loss: 1.4663\n",
      "Batch 120, Loss: 1.4700\n",
      "Batch 121, Loss: 1.4686\n",
      "Batch 122, Loss: 1.4531\n",
      "Batch 123, Loss: 1.4379\n",
      "Batch 124, Loss: 1.4611\n",
      "Batch 125, Loss: 1.4733\n",
      "Batch 126, Loss: 1.4586\n",
      "Batch 127, Loss: 1.4691\n",
      "Batch 128, Loss: 1.4487\n",
      "Batch 129, Loss: 1.4517\n",
      "Batch 130, Loss: 1.4456\n",
      "Batch 131, Loss: 1.4782\n",
      "Batch 132, Loss: 1.4732\n",
      "Batch 133, Loss: 1.4392\n",
      "Batch 134, Loss: 1.4505\n",
      "Batch 135, Loss: 1.4555\n",
      "Batch 136, Loss: 1.4542\n",
      "Batch 137, Loss: 1.4573\n",
      "Batch 138, Loss: 1.4862\n",
      "Batch 139, Loss: 1.4689\n",
      "Batch 140, Loss: 1.4779\n",
      "Batch 141, Loss: 1.4352\n",
      "Batch 142, Loss: 1.4705\n",
      "Batch 143, Loss: 1.4364\n",
      "Batch 144, Loss: 1.4555\n",
      "Batch 145, Loss: 1.4883\n",
      "Batch 146, Loss: 1.4779\n",
      "Batch 147, Loss: 1.4535\n",
      "Batch 148, Loss: 1.4860\n",
      "Batch 149, Loss: 1.4474\n",
      "Batch 150, Loss: 1.4499\n",
      "Batch 151, Loss: 1.4445\n",
      "Batch 152, Loss: 1.4678\n",
      "Batch 153, Loss: 1.4857\n",
      "Batch 154, Loss: 1.4708\n",
      "Batch 155, Loss: 1.4541\n",
      "Batch 156, Loss: 1.4815\n",
      "Batch 157, Loss: 1.4562\n",
      "Batch 158, Loss: 1.4768\n",
      "Batch 159, Loss: 1.4744\n",
      "Batch 160, Loss: 1.4571\n",
      "Batch 161, Loss: 1.4495\n",
      "Batch 162, Loss: 1.4615\n",
      "Batch 163, Loss: 1.4558\n",
      "Batch 164, Loss: 1.4686\n",
      "Batch 165, Loss: 1.4342\n",
      "Batch 166, Loss: 1.4586\n",
      "Batch 167, Loss: 1.4524\n",
      "Batch 168, Loss: 1.4496\n",
      "Batch 169, Loss: 1.4839\n",
      "Batch 170, Loss: 1.4720\n",
      "Batch 171, Loss: 1.4843\n",
      "Batch 172, Loss: 1.4316\n",
      "Batch 173, Loss: 1.4779\n",
      "Batch 174, Loss: 1.4549\n",
      "Batch 175, Loss: 1.4251\n",
      "Batch 176, Loss: 1.4501\n",
      "Batch 177, Loss: 1.4693\n",
      "Batch 178, Loss: 1.4886\n",
      "Batch 179, Loss: 1.4739\n",
      "Batch 180, Loss: 1.4811\n",
      "Batch 181, Loss: 1.4730\n",
      "Batch 182, Loss: 1.4728\n",
      "Batch 183, Loss: 1.4510\n",
      "Batch 184, Loss: 1.4615\n",
      "Batch 185, Loss: 1.4424\n",
      "Batch 186, Loss: 1.4441\n",
      "Batch 187, Loss: 1.4661\n",
      "Batch 188, Loss: 1.4546\n",
      "Batch 189, Loss: 1.4737\n",
      "Batch 190, Loss: 1.4682\n",
      "Batch 191, Loss: 1.4426\n",
      "Batch 192, Loss: 1.4646\n",
      "Batch 193, Loss: 1.4559\n",
      "Batch 194, Loss: 1.4769\n",
      "Batch 195, Loss: 1.4762\n",
      "Batch 196, Loss: 1.4448\n",
      "Batch 197, Loss: 1.4505\n",
      "Batch 198, Loss: 1.4527\n",
      "Batch 199, Loss: 1.4581\n",
      "Batch 200, Loss: 1.4718\n",
      "Batch 201, Loss: 1.4527\n",
      "Batch 202, Loss: 1.4491\n",
      "Batch 203, Loss: 1.4823\n",
      "Batch 204, Loss: 1.4683\n",
      "Batch 205, Loss: 1.4627\n",
      "Batch 206, Loss: 1.4605\n",
      "Batch 207, Loss: 1.4818\n",
      "Batch 208, Loss: 1.4773\n",
      "Batch 209, Loss: 1.4560\n",
      "Batch 210, Loss: 1.4564\n",
      "Batch 211, Loss: 1.4622\n",
      "Batch 212, Loss: 1.4581\n",
      "Batch 213, Loss: 1.4969\n",
      "Batch 214, Loss: 1.4610\n",
      "Batch 215, Loss: 1.4707\n",
      "Batch 216, Loss: 1.4901\n",
      "Batch 217, Loss: 1.4736\n",
      "Batch 218, Loss: 1.4582\n",
      "Batch 219, Loss: 1.4745\n",
      "Batch 220, Loss: 1.4396\n",
      "Batch 221, Loss: 1.4825\n",
      "Batch 222, Loss: 1.4377\n",
      "Batch 223, Loss: 1.4451\n",
      "Batch 224, Loss: 1.4390\n",
      "Batch 225, Loss: 1.4442\n",
      "Batch 226, Loss: 1.4491\n",
      "Batch 227, Loss: 1.4586\n",
      "Batch 228, Loss: 1.4678\n",
      "Batch 229, Loss: 1.4494\n",
      "Batch 230, Loss: 1.4554\n",
      "Batch 231, Loss: 1.4632\n",
      "Batch 232, Loss: 1.4630\n",
      "Batch 233, Loss: 1.4341\n",
      "Batch 234, Loss: 1.4833\n",
      "Batch 235, Loss: 1.4835\n",
      "Batch 236, Loss: 1.4793\n",
      "Batch 237, Loss: 1.4379\n",
      "Batch 238, Loss: 1.4707\n",
      "Batch 239, Loss: 1.4907\n",
      "Batch 240, Loss: 1.4343\n",
      "Batch 241, Loss: 1.4636\n",
      "Batch 242, Loss: 1.4477\n",
      "Batch 243, Loss: 1.4636\n",
      "Batch 244, Loss: 1.4405\n",
      "Batch 245, Loss: 1.4724\n",
      "Batch 246, Loss: 1.4511\n",
      "Batch 247, Loss: 1.4469\n",
      "Batch 248, Loss: 1.4738\n",
      "Batch 249, Loss: 1.4693\n",
      "Batch 250, Loss: 1.4586\n",
      "Batch 251, Loss: 1.4588\n",
      "Batch 252, Loss: 1.4617\n",
      "Batch 253, Loss: 1.4632\n",
      "Batch 254, Loss: 1.4583\n",
      "Batch 255, Loss: 1.4639\n",
      "Batch 256, Loss: 1.4513\n",
      "Batch 257, Loss: 1.4801\n",
      "Batch 258, Loss: 1.4921\n",
      "Batch 259, Loss: 1.4803\n",
      "Batch 260, Loss: 1.4506\n",
      "Batch 261, Loss: 1.4711\n",
      "Batch 262, Loss: 1.4471\n",
      "Batch 263, Loss: 1.4793\n",
      "Batch 264, Loss: 1.4610\n",
      "Batch 265, Loss: 1.4511\n",
      "Batch 266, Loss: 1.4549\n",
      "Batch 267, Loss: 1.4527\n",
      "Batch 268, Loss: 1.4732\n",
      "Batch 269, Loss: 1.4669\n",
      "Batch 270, Loss: 1.4588\n",
      "Batch 271, Loss: 1.4711\n",
      "Batch 272, Loss: 1.4783\n",
      "Batch 273, Loss: 1.4306\n",
      "Batch 274, Loss: 1.4743\n",
      "Batch 275, Loss: 1.4702\n",
      "Batch 276, Loss: 1.4574\n",
      "Batch 277, Loss: 1.4532\n",
      "Batch 278, Loss: 1.4609\n",
      "Batch 279, Loss: 1.4646\n",
      "Batch 280, Loss: 1.4543\n",
      "Batch 281, Loss: 1.4358\n",
      "Batch 282, Loss: 1.4389\n",
      "Batch 283, Loss: 1.4536\n",
      "Batch 284, Loss: 1.4525\n",
      "Batch 285, Loss: 1.4568\n",
      "Batch 286, Loss: 1.4755\n",
      "Batch 287, Loss: 1.4787\n",
      "Batch 288, Loss: 1.4765\n",
      "Batch 289, Loss: 1.4887\n",
      "Batch 290, Loss: 1.4583\n",
      "Batch 291, Loss: 1.4862\n",
      "Batch 292, Loss: 1.4546\n",
      "Batch 293, Loss: 1.4616\n",
      "Batch 294, Loss: 1.4737\n",
      "Batch 295, Loss: 1.4892\n",
      "Batch 296, Loss: 1.4680\n",
      "Batch 297, Loss: 1.4572\n",
      "Batch 298, Loss: 1.4565\n",
      "Batch 299, Loss: 1.4559\n",
      "Batch 300, Loss: 1.4693\n",
      "Batch 301, Loss: 1.4774\n",
      "Batch 302, Loss: 1.4748\n",
      "Batch 303, Loss: 1.4467\n",
      "Batch 304, Loss: 1.4616\n",
      "Batch 305, Loss: 1.4428\n",
      "Batch 306, Loss: 1.4418\n",
      "Batch 307, Loss: 1.4403\n",
      "Batch 308, Loss: 1.4934\n",
      "Batch 309, Loss: 1.4369\n",
      "Batch 310, Loss: 1.4871\n",
      "Batch 311, Loss: 1.4687\n",
      "Batch 312, Loss: 1.4809\n",
      "Batch 313, Loss: 1.4701\n",
      "Batch 314, Loss: 1.4777\n",
      "Batch 315, Loss: 1.4449\n",
      "Batch 316, Loss: 1.4618\n",
      "Batch 317, Loss: 1.4616\n",
      "Batch 318, Loss: 1.4739\n",
      "Batch 319, Loss: 1.4778\n",
      "Batch 320, Loss: 1.4395\n",
      "Batch 321, Loss: 1.4444\n",
      "Batch 322, Loss: 1.4383\n",
      "Batch 323, Loss: 1.4725\n",
      "Batch 324, Loss: 1.4846\n",
      "Batch 325, Loss: 1.4489\n",
      "Batch 326, Loss: 1.5015\n",
      "Batch 327, Loss: 1.4504\n",
      "Batch 328, Loss: 1.4328\n",
      "Batch 329, Loss: 1.4361\n",
      "Batch 330, Loss: 1.4290\n",
      "Batch 331, Loss: 1.4555\n",
      "Batch 332, Loss: 1.4288\n",
      "Batch 333, Loss: 1.4804\n",
      "Batch 334, Loss: 1.4712\n",
      "Batch 335, Loss: 1.4697\n",
      "Batch 336, Loss: 1.4759\n",
      "Batch 337, Loss: 1.4366\n",
      "Batch 338, Loss: 1.4441\n",
      "Batch 339, Loss: 1.4547\n",
      "Batch 340, Loss: 1.4468\n",
      "Batch 341, Loss: 1.4838\n",
      "Batch 342, Loss: 1.4719\n",
      "Batch 343, Loss: 1.4510\n",
      "Batch 344, Loss: 1.4585\n",
      "Batch 345, Loss: 1.4550\n",
      "Batch 346, Loss: 1.4385\n",
      "Batch 347, Loss: 1.4588\n",
      "Batch 348, Loss: 1.4501\n",
      "Batch 349, Loss: 1.4664\n",
      "Batch 350, Loss: 1.4669\n",
      "Batch 351, Loss: 1.4626\n",
      "Batch 352, Loss: 1.4567\n",
      "Batch 353, Loss: 1.4580\n",
      "Batch 354, Loss: 1.4644\n",
      "Batch 355, Loss: 1.4615\n",
      "Batch 356, Loss: 1.4522\n",
      "Batch 357, Loss: 1.4408\n",
      "Batch 358, Loss: 1.4377\n",
      "Batch 359, Loss: 1.4827\n",
      "Batch 360, Loss: 1.4597\n",
      "Batch 361, Loss: 1.4405\n",
      "Batch 362, Loss: 1.4355\n",
      "Batch 363, Loss: 1.4671\n",
      "Batch 364, Loss: 1.4796\n",
      "Batch 365, Loss: 1.4831\n",
      "Batch 366, Loss: 1.4316\n",
      "Batch 367, Loss: 1.4525\n",
      "Batch 368, Loss: 1.4605\n",
      "Batch 369, Loss: 1.4761\n",
      "Batch 370, Loss: 1.4838\n",
      "Batch 371, Loss: 1.4625\n",
      "Batch 372, Loss: 1.4729\n",
      "Batch 373, Loss: 1.4487\n",
      "Batch 374, Loss: 1.4573\n",
      "Batch 375, Loss: 1.4486\n",
      "Batch 376, Loss: 1.4720\n",
      "Batch 377, Loss: 1.4630\n",
      "Batch 378, Loss: 1.4519\n",
      "Batch 379, Loss: 1.4789\n",
      "Batch 380, Loss: 1.4586\n",
      "Batch 381, Loss: 1.4681\n",
      "Batch 382, Loss: 1.4815\n",
      "Batch 383, Loss: 1.4497\n",
      "Batch 384, Loss: 1.4726\n",
      "Batch 385, Loss: 1.4412\n",
      "Batch 386, Loss: 1.4436\n",
      "Batch 387, Loss: 1.4554\n",
      "Batch 388, Loss: 1.4310\n",
      "Batch 389, Loss: 1.4486\n",
      "Batch 390, Loss: 1.4710\n",
      "Batch 391, Loss: 1.4737\n",
      "Batch 392, Loss: 1.4575\n",
      "Batch 393, Loss: 1.4713\n",
      "Batch 394, Loss: 1.4711\n",
      "Batch 395, Loss: 1.4616\n",
      "Batch 396, Loss: 1.4759\n",
      "Batch 397, Loss: 1.4735\n",
      "Batch 398, Loss: 1.4748\n",
      "Batch 399, Loss: 1.4647\n",
      "Batch 400, Loss: 1.4648\n",
      "Batch 401, Loss: 1.4850\n",
      "Batch 402, Loss: 1.4383\n",
      "Batch 403, Loss: 1.4559\n",
      "Batch 404, Loss: 1.4700\n",
      "Batch 405, Loss: 1.4758\n",
      "Batch 406, Loss: 1.4502\n",
      "Batch 407, Loss: 1.4685\n",
      "Batch 408, Loss: 1.4712\n",
      "Batch 409, Loss: 1.4323\n",
      "Batch 410, Loss: 1.4714\n",
      "Batch 411, Loss: 1.4772\n",
      "Batch 412, Loss: 1.4421\n",
      "Batch 413, Loss: 1.4888\n",
      "Batch 414, Loss: 1.4151\n",
      "Batch 415, Loss: 1.4660\n",
      "Batch 416, Loss: 1.4477\n",
      "Batch 417, Loss: 1.4530\n",
      "Batch 418, Loss: 1.4757\n",
      "Batch 419, Loss: 1.4405\n",
      "Batch 420, Loss: 1.4837\n",
      "Batch 421, Loss: 1.4628\n",
      "Batch 422, Loss: 1.4576\n",
      "Batch 423, Loss: 1.4808\n",
      "Batch 424, Loss: 1.4404\n",
      "Batch 425, Loss: 1.4735\n",
      "Batch 426, Loss: 1.4496\n",
      "Batch 427, Loss: 1.4501\n",
      "Batch 428, Loss: 1.4471\n",
      "Batch 429, Loss: 1.4557\n",
      "Batch 430, Loss: 1.4726\n",
      "Batch 431, Loss: 1.4350\n",
      "Batch 432, Loss: 1.4778\n",
      "Batch 433, Loss: 1.4615\n",
      "Batch 434, Loss: 1.4552\n",
      "Batch 435, Loss: 1.4673\n",
      "Batch 436, Loss: 1.4889\n",
      "Batch 437, Loss: 1.4464\n",
      "Batch 438, Loss: 1.4384\n",
      "Batch 439, Loss: 1.4504\n",
      "Batch 440, Loss: 1.4627\n",
      "Batch 441, Loss: 1.4566\n",
      "Batch 442, Loss: 1.4463\n",
      "Batch 443, Loss: 1.4729\n",
      "Batch 444, Loss: 1.4558\n",
      "Batch 445, Loss: 1.4611\n",
      "Batch 446, Loss: 1.4737\n",
      "Batch 447, Loss: 1.4641\n",
      "Batch 448, Loss: 1.4638\n",
      "Batch 449, Loss: 1.4445\n",
      "Batch 450, Loss: 1.4497\n",
      "Batch 451, Loss: 1.4397\n",
      "Batch 452, Loss: 1.4728\n",
      "Batch 453, Loss: 1.4790\n",
      "Batch 454, Loss: 1.4721\n",
      "Batch 455, Loss: 1.4662\n",
      "Batch 456, Loss: 1.4500\n",
      "Batch 457, Loss: 1.4987\n",
      "Batch 458, Loss: 1.4711\n",
      "Batch 459, Loss: 1.4717\n",
      "Batch 460, Loss: 1.4750\n",
      "Batch 461, Loss: 1.4586\n",
      "Batch 462, Loss: 1.4571\n",
      "Batch 463, Loss: 1.4628\n",
      "Batch 464, Loss: 1.4408\n",
      "Batch 465, Loss: 1.4402\n",
      "Batch 466, Loss: 1.4401\n",
      "Batch 467, Loss: 1.4539\n",
      "Batch 468, Loss: 1.4863\n",
      "Batch 469, Loss: 1.4551\n",
      "Batch 470, Loss: 1.4600\n",
      "Batch 471, Loss: 1.4500\n",
      "Batch 472, Loss: 1.4708\n",
      "Batch 473, Loss: 1.4725\n",
      "Batch 474, Loss: 1.4782\n",
      "Batch 475, Loss: 1.4574\n",
      "Batch 476, Loss: 1.4251\n",
      "Batch 477, Loss: 1.4581\n",
      "Batch 478, Loss: 1.4938\n",
      "Batch 479, Loss: 1.4893\n",
      "Batch 480, Loss: 1.4393\n",
      "Batch 481, Loss: 1.4643\n",
      "Batch 482, Loss: 1.4397\n",
      "Batch 483, Loss: 1.4675\n",
      "Once there was a curious day and a fish who lived in the big ocean. The crave loved so much and loved to play in \n",
      "the ocean. One day, the fish wanted to explore the ocean when he started to climb. But the craveling was too heavy for him all \n",
      "by himself. He started to feel sad and love again. He wanted to try again and again. But he couldn't shout first but still kept \n",
      "going. He kept even following until he got back to his safely. So he kept on steperrying. The top he was playful enough to repeat \n",
      "what he could do so lettus get in water. Sometimes he leave the ocean and decided to follow his other cravest. He didn't know that, \n",
      "but he was so excited to step closer to the branches. The sad fish was important and everyone thanked the fish and replied her everyone \n",
      "in the ocean. Even though he was happy to see the crave musffall and enjoy it! \n",
      "\n",
      "--------------------\n",
      "Batch 484, Loss: 1.4269\n",
      "Batch 485, Loss: 1.4348\n",
      "Batch 486, Loss: 1.4587\n",
      "Batch 487, Loss: 1.4357\n",
      "Batch 488, Loss: 1.4920\n",
      "Batch 489, Loss: 1.4501\n",
      "Batch 490, Loss: 1.4463\n",
      "Batch 491, Loss: 1.4848\n",
      "Batch 492, Loss: 1.4567\n",
      "Batch 493, Loss: 1.4409\n",
      "Batch 494, Loss: 1.4652\n",
      "Batch 495, Loss: 1.4528\n",
      "Batch 496, Loss: 1.4619\n",
      "Batch 497, Loss: 1.4591\n",
      "Batch 498, Loss: 1.4645\n",
      "Batch 499, Loss: 1.4573\n",
      "Batch 500, Loss: 1.4694\n",
      "Batch 501, Loss: 1.4594\n",
      "Batch 502, Loss: 1.4458\n",
      "Batch 503, Loss: 1.4876\n",
      "Batch 504, Loss: 1.4581\n",
      "Batch 505, Loss: 1.4609\n",
      "Batch 506, Loss: 1.4494\n",
      "Batch 507, Loss: 1.4581\n",
      "Batch 508, Loss: 1.4700\n",
      "Batch 509, Loss: 1.4658\n",
      "Batch 510, Loss: 1.4486\n",
      "Batch 511, Loss: 1.4301\n",
      "Batch 512, Loss: 1.4510\n",
      "Batch 513, Loss: 1.4603\n",
      "Batch 514, Loss: 1.4532\n",
      "Batch 515, Loss: 1.4556\n",
      "Batch 516, Loss: 1.4501\n",
      "Batch 517, Loss: 1.4506\n",
      "Batch 518, Loss: 1.4527\n",
      "Batch 519, Loss: 1.4620\n",
      "Batch 520, Loss: 1.4564\n",
      "Batch 521, Loss: 1.4441\n",
      "Batch 522, Loss: 1.4732\n",
      "Batch 523, Loss: 1.4383\n",
      "Batch 524, Loss: 1.4570\n",
      "Batch 525, Loss: 1.4509\n",
      "Batch 526, Loss: 1.4537\n",
      "Batch 527, Loss: 1.4535\n",
      "Batch 528, Loss: 1.4469\n",
      "Batch 529, Loss: 1.4815\n",
      "Batch 530, Loss: 1.4438\n",
      "Batch 531, Loss: 1.4568\n",
      "Batch 532, Loss: 1.4435\n",
      "Batch 533, Loss: 1.4870\n",
      "Batch 534, Loss: 1.4742\n",
      "Batch 535, Loss: 1.4522\n",
      "Batch 536, Loss: 1.4431\n",
      "Batch 537, Loss: 1.4439\n",
      "Batch 538, Loss: 1.4674\n",
      "Batch 539, Loss: 1.4400\n",
      "Batch 540, Loss: 1.4232\n",
      "Batch 541, Loss: 1.4346\n",
      "Batch 542, Loss: 1.4622\n",
      "Batch 543, Loss: 1.4420\n",
      "Batch 544, Loss: 1.4531\n",
      "Batch 545, Loss: 1.4936\n",
      "Batch 546, Loss: 1.4616\n",
      "Batch 547, Loss: 1.4770\n",
      "Batch 548, Loss: 1.4616\n",
      "Batch 549, Loss: 1.4855\n",
      "Batch 550, Loss: 1.4435\n",
      "Batch 551, Loss: 1.4566\n",
      "Batch 552, Loss: 1.4598\n",
      "Batch 553, Loss: 1.4502\n",
      "Batch 554, Loss: 1.4739\n",
      "Batch 555, Loss: 1.4685\n",
      "Batch 556, Loss: 1.4823\n",
      "Batch 557, Loss: 1.4306\n",
      "Batch 558, Loss: 1.4608\n",
      "Batch 559, Loss: 1.4628\n",
      "Batch 560, Loss: 1.4499\n",
      "Batch 561, Loss: 1.4632\n",
      "Batch 562, Loss: 1.4555\n",
      "Batch 563, Loss: 1.4477\n",
      "Batch 564, Loss: 1.4745\n",
      "Batch 565, Loss: 1.4239\n",
      "Batch 566, Loss: 1.4766\n",
      "Batch 567, Loss: 1.4572\n",
      "Batch 568, Loss: 1.4704\n",
      "Batch 569, Loss: 1.4720\n",
      "Batch 570, Loss: 1.4551\n",
      "Batch 571, Loss: 1.4746\n",
      "Batch 572, Loss: 1.4678\n",
      "Batch 573, Loss: 1.4560\n",
      "Batch 574, Loss: 1.4887\n",
      "Batch 575, Loss: 1.4760\n",
      "Batch 576, Loss: 1.4653\n",
      "Batch 577, Loss: 1.4604\n",
      "Batch 578, Loss: 1.4626\n",
      "Batch 579, Loss: 1.4684\n",
      "Batch 580, Loss: 1.4342\n",
      "Batch 581, Loss: 1.4306\n",
      "Batch 582, Loss: 1.4545\n",
      "Batch 583, Loss: 1.4594\n",
      "Batch 584, Loss: 1.4712\n",
      "Batch 585, Loss: 1.4680\n",
      "Batch 586, Loss: 1.4931\n",
      "Batch 587, Loss: 1.4593\n",
      "Batch 588, Loss: 1.4494\n",
      "Batch 589, Loss: 1.4154\n",
      "Batch 590, Loss: 1.4848\n",
      "Batch 591, Loss: 1.4572\n",
      "Batch 592, Loss: 1.4720\n",
      "Batch 593, Loss: 1.4704\n",
      "Batch 594, Loss: 1.4811\n",
      "Batch 595, Loss: 1.4618\n",
      "Batch 596, Loss: 1.4653\n",
      "Batch 597, Loss: 1.4507\n",
      "Batch 598, Loss: 1.4545\n",
      "Batch 599, Loss: 1.4482\n",
      "Batch 600, Loss: 1.4339\n",
      "Batch 601, Loss: 1.4682\n",
      "Batch 602, Loss: 1.4688\n",
      "Batch 603, Loss: 1.4545\n",
      "Batch 604, Loss: 1.4828\n",
      "Batch 605, Loss: 1.4568\n",
      "Batch 606, Loss: 1.4534\n",
      "Batch 607, Loss: 1.4609\n",
      "Batch 608, Loss: 1.4481\n",
      "Batch 609, Loss: 1.4521\n",
      "Batch 610, Loss: 1.4464\n",
      "Batch 611, Loss: 1.4640\n",
      "Batch 612, Loss: 1.4684\n",
      "Batch 613, Loss: 1.4413\n",
      "Batch 614, Loss: 1.4603\n",
      "Batch 615, Loss: 1.4289\n",
      "Batch 616, Loss: 1.4778\n",
      "Batch 617, Loss: 1.4528\n",
      "Batch 618, Loss: 1.4055\n",
      "Batch 619, Loss: 1.4728\n",
      "Batch 620, Loss: 1.4476\n",
      "Batch 621, Loss: 1.4786\n",
      "Batch 622, Loss: 1.4297\n",
      "Batch 623, Loss: 1.4387\n",
      "Batch 624, Loss: 1.4485\n",
      "Batch 625, Loss: 1.4578\n",
      "Batch 626, Loss: 1.4521\n",
      "Batch 627, Loss: 1.4538\n",
      "Batch 628, Loss: 1.4245\n",
      "Batch 629, Loss: 1.4425\n",
      "Batch 630, Loss: 1.4627\n",
      "Batch 631, Loss: 1.4660\n",
      "Batch 632, Loss: 1.4492\n",
      "Batch 633, Loss: 1.4775\n",
      "Batch 634, Loss: 1.4698\n",
      "Batch 635, Loss: 1.4710\n",
      "Batch 636, Loss: 1.4524\n",
      "Batch 637, Loss: 1.4233\n",
      "Batch 638, Loss: 1.4456\n",
      "Batch 639, Loss: 1.4514\n",
      "Batch 640, Loss: 1.4743\n",
      "Batch 641, Loss: 1.4414\n",
      "Batch 642, Loss: 1.4624\n",
      "Batch 643, Loss: 1.4648\n",
      "Batch 644, Loss: 1.4607\n",
      "Batch 645, Loss: 1.4446\n",
      "Batch 646, Loss: 1.4467\n",
      "Batch 647, Loss: 1.4409\n",
      "Batch 648, Loss: 1.4807\n",
      "Batch 649, Loss: 1.4475\n",
      "Batch 650, Loss: 1.4350\n",
      "Batch 651, Loss: 1.4396\n",
      "Batch 652, Loss: 1.4717\n",
      "Batch 653, Loss: 1.4663\n",
      "Batch 654, Loss: 1.4680\n",
      "Batch 655, Loss: 1.4690\n",
      "Batch 656, Loss: 1.4791\n",
      "Batch 657, Loss: 1.4744\n",
      "Batch 658, Loss: 1.4639\n",
      "Batch 659, Loss: 1.4750\n",
      "Batch 660, Loss: 1.4624\n",
      "Batch 661, Loss: 1.4671\n",
      "Batch 662, Loss: 1.4542\n",
      "Batch 663, Loss: 1.4610\n",
      "Batch 664, Loss: 1.4742\n",
      "Batch 665, Loss: 1.4734\n",
      "Batch 666, Loss: 1.4532\n",
      "Batch 667, Loss: 1.4693\n",
      "Batch 668, Loss: 1.4557\n",
      "Batch 669, Loss: 1.4656\n",
      "Batch 670, Loss: 1.4652\n",
      "Batch 671, Loss: 1.4456\n",
      "Batch 672, Loss: 1.4647\n",
      "Batch 673, Loss: 1.4541\n",
      "Batch 674, Loss: 1.4779\n",
      "Batch 675, Loss: 1.4393\n",
      "Batch 676, Loss: 1.4566\n",
      "Batch 677, Loss: 1.4768\n",
      "Batch 678, Loss: 1.4409\n",
      "Batch 679, Loss: 1.4416\n",
      "Batch 680, Loss: 1.4900\n",
      "Batch 681, Loss: 1.4433\n",
      "Batch 682, Loss: 1.4653\n",
      "Batch 683, Loss: 1.4679\n",
      "Batch 684, Loss: 1.4534\n",
      "Batch 685, Loss: 1.4464\n",
      "Batch 686, Loss: 1.4498\n",
      "Batch 687, Loss: 1.4607\n",
      "Batch 688, Loss: 1.4456\n",
      "Batch 689, Loss: 1.4416\n",
      "Batch 690, Loss: 1.4731\n",
      "Batch 691, Loss: 1.4354\n",
      "Batch 692, Loss: 1.4408\n",
      "Batch 693, Loss: 1.4460\n",
      "Batch 694, Loss: 1.4745\n",
      "Batch 695, Loss: 1.4575\n",
      "Batch 696, Loss: 1.4525\n",
      "Batch 697, Loss: 1.4659\n",
      "Batch 698, Loss: 1.4522\n",
      "Batch 699, Loss: 1.4514\n",
      "Batch 700, Loss: 1.4407\n",
      "Batch 701, Loss: 1.4552\n",
      "Batch 702, Loss: 1.4868\n",
      "Batch 703, Loss: 1.4524\n",
      "Batch 704, Loss: 1.4352\n",
      "Batch 705, Loss: 1.4655\n",
      "Batch 706, Loss: 1.4399\n",
      "Batch 707, Loss: 1.4447\n",
      "Batch 708, Loss: 1.4408\n",
      "Batch 709, Loss: 1.4411\n",
      "Batch 710, Loss: 1.4551\n",
      "Batch 711, Loss: 1.4725\n",
      "Batch 712, Loss: 1.4603\n",
      "Batch 713, Loss: 1.4433\n",
      "Batch 714, Loss: 1.4855\n",
      "Batch 715, Loss: 1.4345\n",
      "Batch 716, Loss: 1.4886\n",
      "Batch 717, Loss: 1.4758\n",
      "Batch 718, Loss: 1.4582\n",
      "Batch 719, Loss: 1.4831\n",
      "Batch 720, Loss: 1.4557\n",
      "Batch 721, Loss: 1.4776\n",
      "Batch 722, Loss: 1.4556\n",
      "Batch 723, Loss: 1.4573\n",
      "Batch 724, Loss: 1.4801\n",
      "Batch 725, Loss: 1.4241\n",
      "Batch 726, Loss: 1.4593\n",
      "Batch 727, Loss: 1.4741\n",
      "Batch 728, Loss: 1.4684\n",
      "Batch 729, Loss: 1.4720\n",
      "Batch 730, Loss: 1.4646\n",
      "Batch 731, Loss: 1.4613\n",
      "Batch 732, Loss: 1.4682\n",
      "Batch 733, Loss: 1.4245\n",
      "Batch 734, Loss: 1.4663\n",
      "Batch 735, Loss: 1.4572\n",
      "Batch 736, Loss: 1.4403\n",
      "Batch 737, Loss: 1.4432\n",
      "Batch 738, Loss: 1.4471\n",
      "Batch 739, Loss: 1.4490\n",
      "Batch 740, Loss: 1.4493\n",
      "Batch 741, Loss: 1.4620\n",
      "Batch 742, Loss: 1.4584\n",
      "Batch 743, Loss: 1.4542\n",
      "Batch 744, Loss: 1.4410\n",
      "Batch 745, Loss: 1.4556\n",
      "Batch 746, Loss: 1.4499\n",
      "Batch 747, Loss: 1.4532\n",
      "Batch 748, Loss: 1.4648\n",
      "Batch 749, Loss: 1.4690\n",
      "Batch 750, Loss: 1.4630\n",
      "Batch 751, Loss: 1.4840\n",
      "Batch 752, Loss: 1.4665\n",
      "Batch 753, Loss: 1.4685\n",
      "Batch 754, Loss: 1.4436\n",
      "Batch 755, Loss: 1.4675\n",
      "Batch 756, Loss: 1.4470\n",
      "Batch 757, Loss: 1.4549\n",
      "Batch 758, Loss: 1.4354\n",
      "Batch 759, Loss: 1.4203\n",
      "Batch 760, Loss: 1.4366\n",
      "Batch 761, Loss: 1.4411\n",
      "Batch 762, Loss: 1.4523\n",
      "Batch 763, Loss: 1.4711\n",
      "Batch 764, Loss: 1.4716\n",
      "Batch 765, Loss: 1.4978\n",
      "Batch 766, Loss: 1.4202\n",
      "Batch 767, Loss: 1.4478\n",
      "Batch 768, Loss: 1.5046\n",
      "Batch 769, Loss: 1.4436\n",
      "Batch 770, Loss: 1.4434\n",
      "Batch 771, Loss: 1.4404\n",
      "Batch 772, Loss: 1.4600\n",
      "Batch 773, Loss: 1.4372\n",
      "Batch 774, Loss: 1.4391\n",
      "Batch 775, Loss: 1.4762\n",
      "Batch 776, Loss: 1.4557\n",
      "Batch 777, Loss: 1.4620\n",
      "Batch 778, Loss: 1.4503\n",
      "Batch 779, Loss: 1.4285\n",
      "Batch 780, Loss: 1.4676\n",
      "Batch 781, Loss: 1.4635\n",
      "Batch 782, Loss: 1.4334\n",
      "Batch 783, Loss: 1.4717\n",
      "Batch 784, Loss: 1.4750\n",
      "Batch 785, Loss: 1.4370\n",
      "Batch 786, Loss: 1.4490\n",
      "Batch 787, Loss: 1.4438\n",
      "Batch 788, Loss: 1.4639\n",
      "Batch 789, Loss: 1.4791\n",
      "Batch 790, Loss: 1.4426\n",
      "Batch 791, Loss: 1.4490\n",
      "Batch 792, Loss: 1.4681\n",
      "Batch 793, Loss: 1.4467\n",
      "Batch 794, Loss: 1.4577\n",
      "Batch 795, Loss: 1.4559\n",
      "Batch 796, Loss: 1.4658\n",
      "Batch 797, Loss: 1.4833\n",
      "Batch 798, Loss: 1.4466\n",
      "Batch 799, Loss: 1.4611\n",
      "Batch 800, Loss: 1.4330\n",
      "Batch 801, Loss: 1.4504\n",
      "Batch 802, Loss: 1.4420\n",
      "Batch 803, Loss: 1.4553\n",
      "Batch 804, Loss: 1.4568\n",
      "Batch 805, Loss: 1.4292\n",
      "Batch 806, Loss: 1.4856\n",
      "Batch 807, Loss: 1.4473\n",
      "Batch 808, Loss: 1.4478\n",
      "Batch 809, Loss: 1.4384\n",
      "Batch 810, Loss: 1.4416\n",
      "Batch 811, Loss: 1.4612\n",
      "Batch 812, Loss: 1.4600\n",
      "Batch 813, Loss: 1.4605\n",
      "Batch 814, Loss: 1.4760\n",
      "Batch 815, Loss: 1.4393\n",
      "Batch 816, Loss: 1.4391\n",
      "Batch 817, Loss: 1.4615\n",
      "Batch 818, Loss: 1.4737\n",
      "Batch 819, Loss: 1.4762\n",
      "Batch 820, Loss: 1.4662\n",
      "Batch 821, Loss: 1.4817\n",
      "Batch 822, Loss: 1.4624\n",
      "Batch 823, Loss: 1.4546\n",
      "Batch 824, Loss: 1.4629\n",
      "Batch 825, Loss: 1.4654\n",
      "Batch 826, Loss: 1.4331\n",
      "Batch 827, Loss: 1.4396\n",
      "Batch 828, Loss: 1.4373\n",
      "Batch 829, Loss: 1.4611\n",
      "Batch 830, Loss: 1.4588\n",
      "Batch 831, Loss: 1.4529\n",
      "Batch 832, Loss: 1.4443\n",
      "Batch 833, Loss: 1.4321\n",
      "Batch 834, Loss: 1.4459\n",
      "Batch 835, Loss: 1.4590\n",
      "Batch 836, Loss: 1.4591\n",
      "Batch 837, Loss: 1.4583\n",
      "Batch 838, Loss: 1.4634\n",
      "Batch 839, Loss: 1.4276\n",
      "Batch 840, Loss: 1.4595\n",
      "Batch 841, Loss: 1.4494\n",
      "Batch 842, Loss: 1.4608\n",
      "Batch 843, Loss: 1.4491\n",
      "Batch 844, Loss: 1.4484\n",
      "Batch 845, Loss: 1.4798\n",
      "Batch 846, Loss: 1.4615\n",
      "Batch 847, Loss: 1.4484\n",
      "Batch 848, Loss: 1.4555\n",
      "Batch 849, Loss: 1.4620\n",
      "Batch 850, Loss: 1.4536\n",
      "Batch 851, Loss: 1.4315\n",
      "Batch 852, Loss: 1.4508\n",
      "Batch 853, Loss: 1.4143\n",
      "Batch 854, Loss: 1.4420\n",
      "Batch 855, Loss: 1.4187\n",
      "Batch 856, Loss: 1.4699\n",
      "Batch 857, Loss: 1.4665\n",
      "Batch 858, Loss: 1.4328\n",
      "Batch 859, Loss: 1.4408\n",
      "Batch 860, Loss: 1.4468\n",
      "Batch 861, Loss: 1.4720\n",
      "Batch 862, Loss: 1.4704\n",
      "Batch 863, Loss: 1.4699\n",
      "Batch 864, Loss: 1.4370\n",
      "Batch 865, Loss: 1.4533\n",
      "Batch 866, Loss: 1.4503\n",
      "Batch 867, Loss: 1.4680\n",
      "Batch 868, Loss: 1.4694\n",
      "Batch 869, Loss: 1.4482\n",
      "Batch 870, Loss: 1.4915\n",
      "Batch 871, Loss: 1.4239\n",
      "Batch 872, Loss: 1.4480\n",
      "Batch 873, Loss: 1.4350\n",
      "Batch 874, Loss: 1.4393\n",
      "Batch 875, Loss: 1.4557\n",
      "Batch 876, Loss: 1.4551\n",
      "Batch 877, Loss: 1.4523\n",
      "Batch 878, Loss: 1.4540\n",
      "Batch 879, Loss: 1.4287\n",
      "Batch 880, Loss: 1.4716\n",
      "Batch 881, Loss: 1.4435\n",
      "Batch 882, Loss: 1.4579\n",
      "Batch 883, Loss: 1.4571\n",
      "Batch 884, Loss: 1.4698\n",
      "Batch 885, Loss: 1.4522\n",
      "Batch 886, Loss: 1.4486\n",
      "Batch 887, Loss: 1.4556\n",
      "Batch 888, Loss: 1.4684\n",
      "Batch 889, Loss: 1.4591\n",
      "Batch 890, Loss: 1.4488\n",
      "Batch 891, Loss: 1.4489\n",
      "Batch 892, Loss: 1.4083\n",
      "Batch 893, Loss: 1.4686\n",
      "Batch 894, Loss: 1.4389\n",
      "Batch 895, Loss: 1.4653\n",
      "Batch 896, Loss: 1.4516\n",
      "Batch 897, Loss: 1.4309\n",
      "Batch 898, Loss: 1.4596\n",
      "Batch 899, Loss: 1.4437\n",
      "Batch 900, Loss: 1.4493\n",
      "Batch 901, Loss: 1.4706\n",
      "Batch 902, Loss: 1.4420\n",
      "Batch 903, Loss: 1.4541\n",
      "Batch 904, Loss: 1.4581\n",
      "Batch 905, Loss: 1.4478\n",
      "Batch 906, Loss: 1.4223\n",
      "Batch 907, Loss: 1.4154\n",
      "Batch 908, Loss: 1.4529\n",
      "Batch 909, Loss: 1.4440\n",
      "Batch 910, Loss: 1.4850\n",
      "Batch 911, Loss: 1.4702\n",
      "Batch 912, Loss: 1.4398\n",
      "Batch 913, Loss: 1.4326\n",
      "Batch 914, Loss: 1.4689\n",
      "Batch 915, Loss: 1.4344\n",
      "Batch 916, Loss: 1.4820\n",
      "Batch 917, Loss: 1.4454\n",
      "Batch 918, Loss: 1.4766\n",
      "Batch 919, Loss: 1.4375\n",
      "Batch 920, Loss: 1.4500\n",
      "Batch 921, Loss: 1.4470\n",
      "Batch 922, Loss: 1.4572\n",
      "Batch 923, Loss: 1.4565\n",
      "Batch 924, Loss: 1.4487\n",
      "Batch 925, Loss: 1.4268\n",
      "Batch 926, Loss: 1.4510\n",
      "Batch 927, Loss: 1.4716\n",
      "Batch 928, Loss: 1.4476\n",
      "Batch 929, Loss: 1.4249\n",
      "Batch 930, Loss: 1.4367\n",
      "Batch 931, Loss: 1.4505\n",
      "Batch 932, Loss: 1.4400\n",
      "Batch 933, Loss: 1.4557\n",
      "Batch 934, Loss: 1.4742\n",
      "Batch 935, Loss: 1.4534\n",
      "Batch 936, Loss: 1.4601\n",
      "Batch 937, Loss: 1.4594\n",
      "Batch 938, Loss: 1.4396\n",
      "Batch 939, Loss: 1.4660\n",
      "Batch 940, Loss: 1.4477\n",
      "Batch 941, Loss: 1.4415\n",
      "Batch 942, Loss: 1.4740\n",
      "Batch 943, Loss: 1.4562\n",
      "Batch 944, Loss: 1.4427\n",
      "Batch 945, Loss: 1.4331\n",
      "Batch 946, Loss: 1.4453\n",
      "Batch 947, Loss: 1.4585\n",
      "Batch 948, Loss: 1.4687\n",
      "Batch 949, Loss: 1.4403\n",
      "Batch 950, Loss: 1.4376\n",
      "Batch 951, Loss: 1.4477\n",
      "Batch 952, Loss: 1.4745\n",
      "Batch 953, Loss: 1.4429\n",
      "Batch 954, Loss: 1.4357\n",
      "Batch 955, Loss: 1.4345\n",
      "Batch 956, Loss: 1.4694\n",
      "Batch 957, Loss: 1.4781\n",
      "Batch 958, Loss: 1.4581\n",
      "Batch 959, Loss: 1.4449\n",
      "Batch 960, Loss: 1.4504\n",
      "Batch 961, Loss: 1.4462\n",
      "Batch 962, Loss: 1.4722\n",
      "Batch 963, Loss: 1.4475\n",
      "Batch 964, Loss: 1.4513\n",
      "Batch 965, Loss: 1.4719\n",
      "Epoch 6, Average Loss: 1.4587\n",
      "Once upon a time, there was a fish. He lived near a school. He liked to swings and play with his friends and have fun. \n",
      "One day, the school moved by his neighbor, and the fish were sick. The school also wanted to stay healthy and his friends played each \n",
      "other every day. The fish sniff and bumpy met a kind little boy who was. He said, \"Let's argue and share the kindness and play \n",
      "hide and seek together.\" The boy and the boy became friendss of joy and they played together. They had a lot of fun and days. \n",
      "When it was time to go home, the boy said, \"We love kindness, that really home. We will love teach you a languag and be \n",
      "happy little boy.\" The boy waved goodbye and walked away with the children learned all the fun snack and was always an to enjoy the \n",
      "wonderful old friends. \n",
      "\n",
      "--------------------\n",
      "Batch 0, Loss: 1.4578\n",
      "Batch 1, Loss: 1.4382\n",
      "Batch 2, Loss: 1.4456\n",
      "Batch 3, Loss: 1.4458\n",
      "Batch 4, Loss: 1.4459\n",
      "Batch 5, Loss: 1.4572\n",
      "Batch 6, Loss: 1.4556\n",
      "Batch 7, Loss: 1.4130\n",
      "Batch 8, Loss: 1.4332\n",
      "Batch 9, Loss: 1.4556\n",
      "Batch 10, Loss: 1.4565\n",
      "Batch 11, Loss: 1.4383\n",
      "Batch 12, Loss: 1.4285\n",
      "Batch 13, Loss: 1.4159\n",
      "Batch 14, Loss: 1.4456\n",
      "Batch 15, Loss: 1.4216\n",
      "Batch 16, Loss: 1.4671\n",
      "Batch 17, Loss: 1.4332\n",
      "Batch 18, Loss: 1.4431\n",
      "Batch 19, Loss: 1.4505\n",
      "Batch 20, Loss: 1.4164\n",
      "Batch 21, Loss: 1.4115\n",
      "Batch 22, Loss: 1.4188\n",
      "Batch 23, Loss: 1.4490\n",
      "Batch 24, Loss: 1.4515\n",
      "Batch 25, Loss: 1.4346\n",
      "Batch 26, Loss: 1.4321\n",
      "Batch 27, Loss: 1.4262\n",
      "Batch 28, Loss: 1.4572\n",
      "Batch 29, Loss: 1.4207\n",
      "Batch 30, Loss: 1.4740\n",
      "Batch 31, Loss: 1.4104\n",
      "Batch 32, Loss: 1.4499\n",
      "Batch 33, Loss: 1.4763\n",
      "Batch 34, Loss: 1.4465\n",
      "Batch 35, Loss: 1.4515\n",
      "Batch 36, Loss: 1.4305\n",
      "Batch 37, Loss: 1.4135\n",
      "Batch 38, Loss: 1.4260\n",
      "Batch 39, Loss: 1.4388\n",
      "Batch 40, Loss: 1.4832\n",
      "Batch 41, Loss: 1.4513\n",
      "Batch 42, Loss: 1.4546\n",
      "Batch 43, Loss: 1.4505\n",
      "Batch 44, Loss: 1.4593\n",
      "Batch 45, Loss: 1.4645\n",
      "Batch 46, Loss: 1.4479\n",
      "Batch 47, Loss: 1.4518\n",
      "Batch 48, Loss: 1.4054\n",
      "Batch 49, Loss: 1.4464\n",
      "Batch 50, Loss: 1.4127\n",
      "Batch 51, Loss: 1.4010\n",
      "Batch 52, Loss: 1.4347\n",
      "Batch 53, Loss: 1.4525\n",
      "Batch 54, Loss: 1.4705\n",
      "Batch 55, Loss: 1.4467\n",
      "Batch 56, Loss: 1.4440\n",
      "Batch 57, Loss: 1.4472\n",
      "Batch 58, Loss: 1.4245\n",
      "Batch 59, Loss: 1.4474\n",
      "Batch 60, Loss: 1.4458\n",
      "Batch 61, Loss: 1.4314\n",
      "Batch 62, Loss: 1.4405\n",
      "Batch 63, Loss: 1.4530\n",
      "Batch 64, Loss: 1.4115\n",
      "Batch 65, Loss: 1.4445\n",
      "Batch 66, Loss: 1.4354\n",
      "Batch 67, Loss: 1.4184\n",
      "Batch 68, Loss: 1.4486\n",
      "Batch 69, Loss: 1.4483\n",
      "Batch 70, Loss: 1.4373\n",
      "Batch 71, Loss: 1.4248\n",
      "Batch 72, Loss: 1.4167\n",
      "Batch 73, Loss: 1.4302\n",
      "Batch 74, Loss: 1.4217\n",
      "Batch 75, Loss: 1.4333\n",
      "Batch 76, Loss: 1.4450\n",
      "Batch 77, Loss: 1.4751\n",
      "Batch 78, Loss: 1.4389\n",
      "Batch 79, Loss: 1.4396\n",
      "Batch 80, Loss: 1.4444\n",
      "Batch 81, Loss: 1.4387\n",
      "Batch 82, Loss: 1.4764\n",
      "Batch 83, Loss: 1.4310\n",
      "Batch 84, Loss: 1.4530\n",
      "Batch 85, Loss: 1.4337\n",
      "Batch 86, Loss: 1.4484\n",
      "Batch 87, Loss: 1.4549\n",
      "Batch 88, Loss: 1.4480\n",
      "Batch 89, Loss: 1.4565\n",
      "Batch 90, Loss: 1.4382\n",
      "Batch 91, Loss: 1.4445\n",
      "Batch 92, Loss: 1.4594\n",
      "Batch 93, Loss: 1.4386\n",
      "Batch 94, Loss: 1.4276\n",
      "Batch 95, Loss: 1.4520\n",
      "Batch 96, Loss: 1.4492\n",
      "Batch 97, Loss: 1.4370\n",
      "Batch 98, Loss: 1.4380\n",
      "Batch 99, Loss: 1.4402\n",
      "Batch 100, Loss: 1.4623\n",
      "Batch 101, Loss: 1.4575\n",
      "Batch 102, Loss: 1.4456\n",
      "Batch 103, Loss: 1.4250\n",
      "Batch 104, Loss: 1.4542\n",
      "Batch 105, Loss: 1.4343\n",
      "Batch 106, Loss: 1.4488\n",
      "Batch 107, Loss: 1.4560\n",
      "Batch 108, Loss: 1.4525\n",
      "Batch 109, Loss: 1.4113\n",
      "Batch 110, Loss: 1.4292\n",
      "Batch 111, Loss: 1.4465\n",
      "Batch 112, Loss: 1.4272\n",
      "Batch 113, Loss: 1.4365\n",
      "Batch 114, Loss: 1.4404\n",
      "Batch 115, Loss: 1.4226\n",
      "Batch 116, Loss: 1.4474\n",
      "Batch 117, Loss: 1.4455\n",
      "Batch 118, Loss: 1.4448\n",
      "Batch 119, Loss: 1.4354\n",
      "Batch 120, Loss: 1.4685\n",
      "Batch 121, Loss: 1.4426\n",
      "Batch 122, Loss: 1.4612\n",
      "Batch 123, Loss: 1.4455\n",
      "Batch 124, Loss: 1.4369\n",
      "Batch 125, Loss: 1.4522\n",
      "Batch 126, Loss: 1.4282\n",
      "Batch 127, Loss: 1.4359\n",
      "Batch 128, Loss: 1.4719\n",
      "Batch 129, Loss: 1.4353\n",
      "Batch 130, Loss: 1.4467\n",
      "Batch 131, Loss: 1.4471\n",
      "Batch 132, Loss: 1.4259\n",
      "Batch 133, Loss: 1.4286\n",
      "Batch 134, Loss: 1.4307\n",
      "Batch 135, Loss: 1.4152\n",
      "Batch 136, Loss: 1.4490\n",
      "Batch 137, Loss: 1.4482\n",
      "Batch 138, Loss: 1.4337\n",
      "Batch 139, Loss: 1.4555\n",
      "Batch 140, Loss: 1.4402\n",
      "Batch 141, Loss: 1.4265\n",
      "Batch 142, Loss: 1.4327\n",
      "Batch 143, Loss: 1.4648\n",
      "Batch 144, Loss: 1.4445\n",
      "Batch 145, Loss: 1.4330\n",
      "Batch 146, Loss: 1.4460\n",
      "Batch 147, Loss: 1.4288\n",
      "Batch 148, Loss: 1.4493\n",
      "Batch 149, Loss: 1.4458\n",
      "Batch 150, Loss: 1.4511\n",
      "Batch 151, Loss: 1.4587\n",
      "Batch 152, Loss: 1.4384\n",
      "Batch 153, Loss: 1.4444\n",
      "Batch 154, Loss: 1.4257\n",
      "Batch 155, Loss: 1.4381\n",
      "Batch 156, Loss: 1.4206\n",
      "Batch 157, Loss: 1.4701\n",
      "Batch 158, Loss: 1.4563\n",
      "Batch 159, Loss: 1.4054\n",
      "Batch 160, Loss: 1.4289\n",
      "Batch 161, Loss: 1.4624\n",
      "Batch 162, Loss: 1.4736\n",
      "Batch 163, Loss: 1.4270\n",
      "Batch 164, Loss: 1.4550\n",
      "Batch 165, Loss: 1.4475\n",
      "Batch 166, Loss: 1.4402\n",
      "Batch 167, Loss: 1.4612\n",
      "Batch 168, Loss: 1.4605\n",
      "Batch 169, Loss: 1.4369\n",
      "Batch 170, Loss: 1.4247\n",
      "Batch 171, Loss: 1.4470\n",
      "Batch 172, Loss: 1.4627\n",
      "Batch 173, Loss: 1.4436\n",
      "Batch 174, Loss: 1.4557\n",
      "Batch 175, Loss: 1.4564\n",
      "Batch 176, Loss: 1.4432\n",
      "Batch 177, Loss: 1.4461\n",
      "Batch 178, Loss: 1.4095\n",
      "Batch 179, Loss: 1.4453\n",
      "Batch 180, Loss: 1.4677\n",
      "Batch 181, Loss: 1.4550\n",
      "Batch 182, Loss: 1.4413\n",
      "Batch 183, Loss: 1.4336\n",
      "Batch 184, Loss: 1.4251\n",
      "Batch 185, Loss: 1.4134\n",
      "Batch 186, Loss: 1.4464\n",
      "Batch 187, Loss: 1.4381\n",
      "Batch 188, Loss: 1.4433\n",
      "Batch 189, Loss: 1.4432\n",
      "Batch 190, Loss: 1.4918\n",
      "Batch 191, Loss: 1.4203\n",
      "Batch 192, Loss: 1.4436\n",
      "Batch 193, Loss: 1.4219\n",
      "Batch 194, Loss: 1.4188\n",
      "Batch 195, Loss: 1.4566\n",
      "Batch 196, Loss: 1.4525\n",
      "Batch 197, Loss: 1.4260\n",
      "Batch 198, Loss: 1.4562\n",
      "Batch 199, Loss: 1.4473\n",
      "Batch 200, Loss: 1.4327\n",
      "Batch 201, Loss: 1.4265\n",
      "Batch 202, Loss: 1.4453\n",
      "Batch 203, Loss: 1.4679\n",
      "Batch 204, Loss: 1.4402\n",
      "Batch 205, Loss: 1.4358\n",
      "Batch 206, Loss: 1.4677\n",
      "Batch 207, Loss: 1.4663\n",
      "Batch 208, Loss: 1.4647\n",
      "Batch 209, Loss: 1.4404\n",
      "Batch 210, Loss: 1.4564\n",
      "Batch 211, Loss: 1.4301\n",
      "Batch 212, Loss: 1.4215\n",
      "Batch 213, Loss: 1.4270\n",
      "Batch 214, Loss: 1.4163\n",
      "Batch 215, Loss: 1.4307\n",
      "Batch 216, Loss: 1.4536\n",
      "Batch 217, Loss: 1.4329\n",
      "Batch 218, Loss: 1.4430\n",
      "Batch 219, Loss: 1.4365\n",
      "Batch 220, Loss: 1.4393\n",
      "Batch 221, Loss: 1.4313\n",
      "Batch 222, Loss: 1.4337\n",
      "Batch 223, Loss: 1.4384\n",
      "Batch 224, Loss: 1.4567\n",
      "Batch 225, Loss: 1.4409\n",
      "Batch 226, Loss: 1.4247\n",
      "Batch 227, Loss: 1.4321\n",
      "Batch 228, Loss: 1.4667\n",
      "Batch 229, Loss: 1.4307\n",
      "Batch 230, Loss: 1.4326\n",
      "Batch 231, Loss: 1.4168\n",
      "Batch 232, Loss: 1.4448\n",
      "Batch 233, Loss: 1.4424\n",
      "Batch 234, Loss: 1.4405\n",
      "Batch 235, Loss: 1.4659\n",
      "Batch 236, Loss: 1.4459\n",
      "Batch 237, Loss: 1.4174\n",
      "Batch 238, Loss: 1.4560\n",
      "Batch 239, Loss: 1.4557\n",
      "Batch 240, Loss: 1.4445\n",
      "Batch 241, Loss: 1.3973\n",
      "Batch 242, Loss: 1.4367\n",
      "Batch 243, Loss: 1.4389\n",
      "Batch 244, Loss: 1.4125\n",
      "Batch 245, Loss: 1.4334\n",
      "Batch 246, Loss: 1.4391\n",
      "Batch 247, Loss: 1.4425\n",
      "Batch 248, Loss: 1.4455\n",
      "Batch 249, Loss: 1.4673\n",
      "Batch 250, Loss: 1.4432\n",
      "Batch 251, Loss: 1.4126\n",
      "Batch 252, Loss: 1.4326\n",
      "Batch 253, Loss: 1.4305\n",
      "Batch 254, Loss: 1.4365\n",
      "Batch 255, Loss: 1.4186\n",
      "Batch 256, Loss: 1.4683\n",
      "Batch 257, Loss: 1.4437\n",
      "Batch 258, Loss: 1.4329\n",
      "Batch 259, Loss: 1.4316\n",
      "Batch 260, Loss: 1.4049\n",
      "Batch 261, Loss: 1.4257\n",
      "Batch 262, Loss: 1.4644\n",
      "Batch 263, Loss: 1.4445\n",
      "Batch 264, Loss: 1.4487\n",
      "Batch 265, Loss: 1.4263\n",
      "Batch 266, Loss: 1.4468\n",
      "Batch 267, Loss: 1.4921\n",
      "Batch 268, Loss: 1.4269\n",
      "Batch 269, Loss: 1.4237\n",
      "Batch 270, Loss: 1.4377\n",
      "Batch 271, Loss: 1.4464\n",
      "Batch 272, Loss: 1.4583\n",
      "Batch 273, Loss: 1.4550\n",
      "Batch 274, Loss: 1.4072\n",
      "Batch 275, Loss: 1.4384\n",
      "Batch 276, Loss: 1.4476\n",
      "Batch 277, Loss: 1.4232\n",
      "Batch 278, Loss: 1.4781\n",
      "Batch 279, Loss: 1.4349\n",
      "Batch 280, Loss: 1.4366\n",
      "Batch 281, Loss: 1.4558\n",
      "Batch 282, Loss: 1.4364\n",
      "Batch 283, Loss: 1.4526\n",
      "Batch 284, Loss: 1.4659\n",
      "Batch 285, Loss: 1.4326\n",
      "Batch 286, Loss: 1.4220\n",
      "Batch 287, Loss: 1.4918\n",
      "Batch 288, Loss: 1.4251\n",
      "Batch 289, Loss: 1.4424\n",
      "Batch 290, Loss: 1.4641\n",
      "Batch 291, Loss: 1.4022\n",
      "Batch 292, Loss: 1.4342\n",
      "Batch 293, Loss: 1.4414\n",
      "Batch 294, Loss: 1.4483\n",
      "Batch 295, Loss: 1.4489\n",
      "Batch 296, Loss: 1.4153\n",
      "Batch 297, Loss: 1.4406\n",
      "Batch 298, Loss: 1.4334\n",
      "Batch 299, Loss: 1.4411\n",
      "Batch 300, Loss: 1.4597\n",
      "Batch 301, Loss: 1.4241\n",
      "Batch 302, Loss: 1.4623\n",
      "Batch 303, Loss: 1.4353\n",
      "Batch 304, Loss: 1.4347\n",
      "Batch 305, Loss: 1.4258\n",
      "Batch 306, Loss: 1.4426\n",
      "Batch 307, Loss: 1.4387\n",
      "Batch 308, Loss: 1.4568\n",
      "Batch 309, Loss: 1.4470\n",
      "Batch 310, Loss: 1.4641\n",
      "Batch 311, Loss: 1.4629\n",
      "Batch 312, Loss: 1.4278\n",
      "Batch 313, Loss: 1.4615\n",
      "Batch 314, Loss: 1.4204\n",
      "Batch 315, Loss: 1.4388\n",
      "Batch 316, Loss: 1.4582\n",
      "Batch 317, Loss: 1.4598\n",
      "Batch 318, Loss: 1.4606\n",
      "Batch 319, Loss: 1.4044\n",
      "Batch 320, Loss: 1.4273\n",
      "Batch 321, Loss: 1.4432\n",
      "Batch 322, Loss: 1.4170\n",
      "Batch 323, Loss: 1.4306\n",
      "Batch 324, Loss: 1.4041\n",
      "Batch 325, Loss: 1.4321\n",
      "Batch 326, Loss: 1.4336\n",
      "Batch 327, Loss: 1.4398\n",
      "Batch 328, Loss: 1.4443\n",
      "Batch 329, Loss: 1.4224\n",
      "Batch 330, Loss: 1.4451\n",
      "Batch 331, Loss: 1.4666\n",
      "Batch 332, Loss: 1.4135\n",
      "Batch 333, Loss: 1.4413\n",
      "Batch 334, Loss: 1.4177\n",
      "Batch 335, Loss: 1.4329\n",
      "Batch 336, Loss: 1.4423\n",
      "Batch 337, Loss: 1.4500\n",
      "Batch 338, Loss: 1.4316\n",
      "Batch 339, Loss: 1.4198\n",
      "Batch 340, Loss: 1.4034\n",
      "Batch 341, Loss: 1.3978\n",
      "Batch 342, Loss: 1.4638\n",
      "Batch 343, Loss: 1.4429\n",
      "Batch 344, Loss: 1.4416\n",
      "Batch 345, Loss: 1.4270\n",
      "Batch 346, Loss: 1.4637\n",
      "Batch 347, Loss: 1.4334\n",
      "Batch 348, Loss: 1.4583\n",
      "Batch 349, Loss: 1.4354\n",
      "Batch 350, Loss: 1.4252\n",
      "Batch 351, Loss: 1.4271\n",
      "Batch 352, Loss: 1.4355\n",
      "Batch 353, Loss: 1.4506\n",
      "Batch 354, Loss: 1.4230\n",
      "Batch 355, Loss: 1.4608\n",
      "Batch 356, Loss: 1.4351\n",
      "Batch 357, Loss: 1.4492\n",
      "Batch 358, Loss: 1.4250\n",
      "Batch 359, Loss: 1.4382\n",
      "Batch 360, Loss: 1.4301\n",
      "Batch 361, Loss: 1.4305\n",
      "Batch 362, Loss: 1.4344\n",
      "Batch 363, Loss: 1.4266\n",
      "Batch 364, Loss: 1.4374\n",
      "Batch 365, Loss: 1.4449\n",
      "Batch 366, Loss: 1.4375\n",
      "Batch 367, Loss: 1.4519\n",
      "Batch 368, Loss: 1.4156\n",
      "Batch 369, Loss: 1.4421\n",
      "Batch 370, Loss: 1.4274\n",
      "Batch 371, Loss: 1.4199\n",
      "Batch 372, Loss: 1.4364\n",
      "Batch 373, Loss: 1.4332\n",
      "Batch 374, Loss: 1.4566\n",
      "Batch 375, Loss: 1.4488\n",
      "Batch 376, Loss: 1.4238\n",
      "Batch 377, Loss: 1.4410\n",
      "Batch 378, Loss: 1.4511\n",
      "Batch 379, Loss: 1.4323\n",
      "Batch 380, Loss: 1.4673\n",
      "Batch 381, Loss: 1.4396\n",
      "Batch 382, Loss: 1.4409\n",
      "Batch 383, Loss: 1.4151\n",
      "Batch 384, Loss: 1.4474\n",
      "Batch 385, Loss: 1.4257\n",
      "Batch 386, Loss: 1.4378\n",
      "Batch 387, Loss: 1.4631\n",
      "Batch 388, Loss: 1.4519\n",
      "Batch 389, Loss: 1.4215\n",
      "Batch 390, Loss: 1.4418\n",
      "Batch 391, Loss: 1.4683\n",
      "Batch 392, Loss: 1.4203\n",
      "Batch 393, Loss: 1.4625\n",
      "Batch 394, Loss: 1.4452\n",
      "Batch 395, Loss: 1.4482\n",
      "Batch 396, Loss: 1.4421\n",
      "Batch 397, Loss: 1.4794\n",
      "Batch 398, Loss: 1.4450\n",
      "Batch 399, Loss: 1.4404\n",
      "Batch 400, Loss: 1.4469\n",
      "Batch 401, Loss: 1.4468\n",
      "Batch 402, Loss: 1.4670\n",
      "Batch 403, Loss: 1.4470\n",
      "Batch 404, Loss: 1.4229\n",
      "Batch 405, Loss: 1.4465\n",
      "Batch 406, Loss: 1.4171\n",
      "Batch 407, Loss: 1.4290\n",
      "Batch 408, Loss: 1.4365\n",
      "Batch 409, Loss: 1.4315\n",
      "Batch 410, Loss: 1.4471\n",
      "Batch 411, Loss: 1.4392\n",
      "Batch 412, Loss: 1.4534\n",
      "Batch 413, Loss: 1.4555\n",
      "Batch 414, Loss: 1.4642\n",
      "Batch 415, Loss: 1.4074\n",
      "Batch 416, Loss: 1.4311\n",
      "Batch 417, Loss: 1.4347\n",
      "Batch 418, Loss: 1.4400\n",
      "Batch 419, Loss: 1.4447\n",
      "Batch 420, Loss: 1.4010\n",
      "Batch 421, Loss: 1.4503\n",
      "Batch 422, Loss: 1.4323\n",
      "Batch 423, Loss: 1.4399\n",
      "Batch 424, Loss: 1.4415\n",
      "Batch 425, Loss: 1.4491\n",
      "Batch 426, Loss: 1.4447\n",
      "Batch 427, Loss: 1.4208\n",
      "Batch 428, Loss: 1.4245\n",
      "Batch 429, Loss: 1.4327\n",
      "Batch 430, Loss: 1.4422\n",
      "Batch 431, Loss: 1.4376\n",
      "Batch 432, Loss: 1.4247\n",
      "Batch 433, Loss: 1.4401\n",
      "Batch 434, Loss: 1.4143\n",
      "Batch 435, Loss: 1.4375\n",
      "Batch 436, Loss: 1.4481\n",
      "Batch 437, Loss: 1.4431\n",
      "Batch 438, Loss: 1.4043\n",
      "Batch 439, Loss: 1.4387\n",
      "Batch 440, Loss: 1.4219\n",
      "Batch 441, Loss: 1.4658\n",
      "Batch 442, Loss: 1.4794\n",
      "Batch 443, Loss: 1.4351\n",
      "Batch 444, Loss: 1.4345\n",
      "Batch 445, Loss: 1.4416\n",
      "Batch 446, Loss: 1.4326\n",
      "Batch 447, Loss: 1.4276\n",
      "Batch 448, Loss: 1.4650\n",
      "Batch 449, Loss: 1.4175\n",
      "Batch 450, Loss: 1.4330\n",
      "Batch 451, Loss: 1.4683\n",
      "Batch 452, Loss: 1.4574\n",
      "Batch 453, Loss: 1.4179\n",
      "Batch 454, Loss: 1.4640\n",
      "Batch 455, Loss: 1.4168\n",
      "Batch 456, Loss: 1.4260\n",
      "Batch 457, Loss: 1.4281\n",
      "Batch 458, Loss: 1.4410\n",
      "Batch 459, Loss: 1.4344\n",
      "Batch 460, Loss: 1.4554\n",
      "Batch 461, Loss: 1.4338\n",
      "Batch 462, Loss: 1.4606\n",
      "Batch 463, Loss: 1.4507\n",
      "Batch 464, Loss: 1.4368\n",
      "Batch 465, Loss: 1.4363\n",
      "Batch 466, Loss: 1.4510\n",
      "Batch 467, Loss: 1.4196\n",
      "Batch 468, Loss: 1.4566\n",
      "Batch 469, Loss: 1.4397\n",
      "Batch 470, Loss: 1.4604\n",
      "Batch 471, Loss: 1.4217\n",
      "Batch 472, Loss: 1.4053\n",
      "Batch 473, Loss: 1.4551\n",
      "Batch 474, Loss: 1.4321\n",
      "Batch 475, Loss: 1.4542\n",
      "Batch 476, Loss: 1.4413\n",
      "Batch 477, Loss: 1.4416\n",
      "Batch 478, Loss: 1.4425\n",
      "Batch 479, Loss: 1.4242\n",
      "Batch 480, Loss: 1.4604\n",
      "Batch 481, Loss: 1.4261\n",
      "Batch 482, Loss: 1.4205\n",
      "Batch 483, Loss: 1.4358\n",
      "Once upon a time, there was a happy little girl named Annie. She was teaching massage. One day, her mommy gave her as a puliar \n",
      "kite look. Annie's little brother Tom said, \"What are you doing with it?\" Annie smiled and said, \"I'm going to kite her game. It's going \n",
      "on it all because they'd really have a high horn.\" Tom wasn't sure what to do, so he watched as the wind blue blew high \n",
      "a harsh up into a tree when he realized the colors ahead of them. From that day on, the brother was always happy. One day, \n",
      "the wind and Tom saw his mother long walking in a busage. He could see her building and grab safely because of how he could \n",
      "plan to enjoy her game so he could jump in the harsh towl. \n",
      "\n",
      "--------------------\n",
      "Batch 484, Loss: 1.4502\n",
      "Batch 485, Loss: 1.4090\n",
      "Batch 486, Loss: 1.4316\n",
      "Batch 487, Loss: 1.4223\n",
      "Batch 488, Loss: 1.4483\n",
      "Batch 489, Loss: 1.4356\n",
      "Batch 490, Loss: 1.4100\n",
      "Batch 491, Loss: 1.4299\n",
      "Batch 492, Loss: 1.4591\n",
      "Batch 493, Loss: 1.4366\n",
      "Batch 494, Loss: 1.4327\n",
      "Batch 495, Loss: 1.4418\n",
      "Batch 496, Loss: 1.4374\n",
      "Batch 497, Loss: 1.4186\n",
      "Batch 498, Loss: 1.4193\n",
      "Batch 499, Loss: 1.4503\n",
      "Batch 500, Loss: 1.4152\n",
      "Batch 501, Loss: 1.4341\n",
      "Batch 502, Loss: 1.4386\n",
      "Batch 503, Loss: 1.4305\n",
      "Batch 504, Loss: 1.4481\n",
      "Batch 505, Loss: 1.4758\n",
      "Batch 506, Loss: 1.4413\n",
      "Batch 507, Loss: 1.4491\n",
      "Batch 508, Loss: 1.4155\n",
      "Batch 509, Loss: 1.4576\n",
      "Batch 510, Loss: 1.4312\n",
      "Batch 511, Loss: 1.4436\n",
      "Batch 512, Loss: 1.4389\n",
      "Batch 513, Loss: 1.4547\n",
      "Batch 514, Loss: 1.4294\n",
      "Batch 515, Loss: 1.4497\n",
      "Batch 516, Loss: 1.4270\n",
      "Batch 517, Loss: 1.4246\n",
      "Batch 518, Loss: 1.4482\n",
      "Batch 519, Loss: 1.4607\n",
      "Batch 520, Loss: 1.4306\n",
      "Batch 521, Loss: 1.4365\n",
      "Batch 522, Loss: 1.4298\n",
      "Batch 523, Loss: 1.4542\n",
      "Batch 524, Loss: 1.4329\n",
      "Batch 525, Loss: 1.4670\n",
      "Batch 526, Loss: 1.4497\n",
      "Batch 527, Loss: 1.4384\n",
      "Batch 528, Loss: 1.4309\n",
      "Batch 529, Loss: 1.4308\n",
      "Batch 530, Loss: 1.4082\n",
      "Batch 531, Loss: 1.4317\n",
      "Batch 532, Loss: 1.4009\n",
      "Batch 533, Loss: 1.4165\n",
      "Batch 534, Loss: 1.4418\n",
      "Batch 535, Loss: 1.4411\n",
      "Batch 536, Loss: 1.4552\n",
      "Batch 537, Loss: 1.4752\n",
      "Batch 538, Loss: 1.3795\n",
      "Batch 539, Loss: 1.4496\n",
      "Batch 540, Loss: 1.4274\n",
      "Batch 541, Loss: 1.4165\n",
      "Batch 542, Loss: 1.4224\n",
      "Batch 543, Loss: 1.4256\n",
      "Batch 544, Loss: 1.4458\n",
      "Batch 545, Loss: 1.4578\n",
      "Batch 546, Loss: 1.4463\n",
      "Batch 547, Loss: 1.4448\n",
      "Batch 548, Loss: 1.4526\n",
      "Batch 549, Loss: 1.4530\n",
      "Batch 550, Loss: 1.4542\n",
      "Batch 551, Loss: 1.4522\n",
      "Batch 552, Loss: 1.4013\n",
      "Batch 553, Loss: 1.4098\n",
      "Batch 554, Loss: 1.4582\n",
      "Batch 555, Loss: 1.4628\n",
      "Batch 556, Loss: 1.4467\n",
      "Batch 557, Loss: 1.4222\n",
      "Batch 558, Loss: 1.4385\n",
      "Batch 559, Loss: 1.4737\n",
      "Batch 560, Loss: 1.4471\n",
      "Batch 561, Loss: 1.4800\n",
      "Batch 562, Loss: 1.4382\n",
      "Batch 563, Loss: 1.4420\n",
      "Batch 564, Loss: 1.4437\n",
      "Batch 565, Loss: 1.4232\n",
      "Batch 566, Loss: 1.4576\n",
      "Batch 567, Loss: 1.4272\n",
      "Batch 568, Loss: 1.4220\n",
      "Batch 569, Loss: 1.4073\n",
      "Batch 570, Loss: 1.4552\n",
      "Batch 571, Loss: 1.4687\n",
      "Batch 572, Loss: 1.4357\n",
      "Batch 573, Loss: 1.4580\n",
      "Batch 574, Loss: 1.4475\n",
      "Batch 575, Loss: 1.4223\n",
      "Batch 576, Loss: 1.4342\n",
      "Batch 577, Loss: 1.4349\n",
      "Batch 578, Loss: 1.4418\n",
      "Batch 579, Loss: 1.4210\n",
      "Batch 580, Loss: 1.4501\n",
      "Batch 581, Loss: 1.4317\n",
      "Batch 582, Loss: 1.4249\n",
      "Batch 583, Loss: 1.4320\n",
      "Batch 584, Loss: 1.4358\n",
      "Batch 585, Loss: 1.4258\n",
      "Batch 586, Loss: 1.4264\n",
      "Batch 587, Loss: 1.4477\n",
      "Batch 588, Loss: 1.4315\n",
      "Batch 589, Loss: 1.4312\n",
      "Batch 590, Loss: 1.4375\n",
      "Batch 591, Loss: 1.4697\n",
      "Batch 592, Loss: 1.4129\n",
      "Batch 593, Loss: 1.4454\n",
      "Batch 594, Loss: 1.4404\n",
      "Batch 595, Loss: 1.4433\n",
      "Batch 596, Loss: 1.4430\n",
      "Batch 597, Loss: 1.4394\n",
      "Batch 598, Loss: 1.4518\n",
      "Batch 599, Loss: 1.4261\n",
      "Batch 600, Loss: 1.4334\n",
      "Batch 601, Loss: 1.4338\n",
      "Batch 602, Loss: 1.4205\n",
      "Batch 603, Loss: 1.4385\n",
      "Batch 604, Loss: 1.4278\n",
      "Batch 605, Loss: 1.4247\n",
      "Batch 606, Loss: 1.4629\n",
      "Batch 607, Loss: 1.4296\n",
      "Batch 608, Loss: 1.4611\n",
      "Batch 609, Loss: 1.4597\n",
      "Batch 610, Loss: 1.4576\n",
      "Batch 611, Loss: 1.4344\n",
      "Batch 612, Loss: 1.4245\n",
      "Batch 613, Loss: 1.4470\n",
      "Batch 614, Loss: 1.4341\n",
      "Batch 615, Loss: 1.4249\n",
      "Batch 616, Loss: 1.4360\n",
      "Batch 617, Loss: 1.4275\n",
      "Batch 618, Loss: 1.4480\n",
      "Batch 619, Loss: 1.4476\n",
      "Batch 620, Loss: 1.4055\n",
      "Batch 621, Loss: 1.4443\n",
      "Batch 622, Loss: 1.4194\n",
      "Batch 623, Loss: 1.4471\n",
      "Batch 624, Loss: 1.4390\n",
      "Batch 625, Loss: 1.4160\n",
      "Batch 626, Loss: 1.4588\n",
      "Batch 627, Loss: 1.4163\n",
      "Batch 628, Loss: 1.4340\n",
      "Batch 629, Loss: 1.4611\n",
      "Batch 630, Loss: 1.4329\n",
      "Batch 631, Loss: 1.4471\n",
      "Batch 632, Loss: 1.4460\n",
      "Batch 633, Loss: 1.4414\n",
      "Batch 634, Loss: 1.4524\n",
      "Batch 635, Loss: 1.4194\n",
      "Batch 636, Loss: 1.4473\n",
      "Batch 637, Loss: 1.4428\n",
      "Batch 638, Loss: 1.4322\n",
      "Batch 639, Loss: 1.4394\n",
      "Batch 640, Loss: 1.4181\n",
      "Batch 641, Loss: 1.4610\n",
      "Batch 642, Loss: 1.4090\n",
      "Batch 643, Loss: 1.4635\n",
      "Batch 644, Loss: 1.4328\n",
      "Batch 645, Loss: 1.4225\n",
      "Batch 646, Loss: 1.4283\n",
      "Batch 647, Loss: 1.4511\n",
      "Batch 648, Loss: 1.4144\n",
      "Batch 649, Loss: 1.4303\n",
      "Batch 650, Loss: 1.4292\n",
      "Batch 651, Loss: 1.4726\n",
      "Batch 652, Loss: 1.4466\n",
      "Batch 653, Loss: 1.4295\n",
      "Batch 654, Loss: 1.4654\n",
      "Batch 655, Loss: 1.4513\n",
      "Batch 656, Loss: 1.4505\n",
      "Batch 657, Loss: 1.4393\n",
      "Batch 658, Loss: 1.4420\n",
      "Batch 659, Loss: 1.4073\n",
      "Batch 660, Loss: 1.4465\n",
      "Batch 661, Loss: 1.4180\n",
      "Batch 662, Loss: 1.4164\n",
      "Batch 663, Loss: 1.4147\n",
      "Batch 664, Loss: 1.4374\n",
      "Batch 665, Loss: 1.4403\n",
      "Batch 666, Loss: 1.4362\n",
      "Batch 667, Loss: 1.4172\n",
      "Batch 668, Loss: 1.4235\n",
      "Batch 669, Loss: 1.4473\n",
      "Batch 670, Loss: 1.4374\n",
      "Batch 671, Loss: 1.4085\n",
      "Batch 672, Loss: 1.4428\n",
      "Batch 673, Loss: 1.4033\n",
      "Batch 674, Loss: 1.4157\n",
      "Batch 675, Loss: 1.4444\n",
      "Batch 676, Loss: 1.4139\n",
      "Batch 677, Loss: 1.3998\n",
      "Batch 678, Loss: 1.4381\n",
      "Batch 679, Loss: 1.4376\n",
      "Batch 680, Loss: 1.4486\n",
      "Batch 681, Loss: 1.4500\n",
      "Batch 682, Loss: 1.4257\n",
      "Batch 683, Loss: 1.4199\n",
      "Batch 684, Loss: 1.4616\n",
      "Batch 685, Loss: 1.4346\n",
      "Batch 686, Loss: 1.4188\n",
      "Batch 687, Loss: 1.4086\n",
      "Batch 688, Loss: 1.4285\n",
      "Batch 689, Loss: 1.4131\n",
      "Batch 690, Loss: 1.4201\n",
      "Batch 691, Loss: 1.4348\n",
      "Batch 692, Loss: 1.4330\n",
      "Batch 693, Loss: 1.4102\n",
      "Batch 694, Loss: 1.4151\n",
      "Batch 695, Loss: 1.4575\n",
      "Batch 696, Loss: 1.4103\n",
      "Batch 697, Loss: 1.4408\n",
      "Batch 698, Loss: 1.4436\n",
      "Batch 699, Loss: 1.4345\n",
      "Batch 700, Loss: 1.4541\n",
      "Batch 701, Loss: 1.4308\n",
      "Batch 702, Loss: 1.4237\n",
      "Batch 703, Loss: 1.4139\n",
      "Batch 704, Loss: 1.4355\n",
      "Batch 705, Loss: 1.4370\n",
      "Batch 706, Loss: 1.4270\n",
      "Batch 707, Loss: 1.4372\n",
      "Batch 708, Loss: 1.4611\n",
      "Batch 709, Loss: 1.4207\n",
      "Batch 710, Loss: 1.4570\n",
      "Batch 711, Loss: 1.4461\n",
      "Batch 712, Loss: 1.4210\n",
      "Batch 713, Loss: 1.4187\n",
      "Batch 714, Loss: 1.4154\n",
      "Batch 715, Loss: 1.4390\n",
      "Batch 716, Loss: 1.4229\n",
      "Batch 717, Loss: 1.4690\n",
      "Batch 718, Loss: 1.4427\n",
      "Batch 719, Loss: 1.4291\n",
      "Batch 720, Loss: 1.4352\n",
      "Batch 721, Loss: 1.4482\n",
      "Batch 722, Loss: 1.4413\n",
      "Batch 723, Loss: 1.4692\n",
      "Batch 724, Loss: 1.4165\n",
      "Batch 725, Loss: 1.4499\n",
      "Batch 726, Loss: 1.4357\n",
      "Batch 727, Loss: 1.4326\n",
      "Batch 728, Loss: 1.4298\n",
      "Batch 729, Loss: 1.4401\n",
      "Batch 730, Loss: 1.4494\n",
      "Batch 731, Loss: 1.4457\n",
      "Batch 732, Loss: 1.4519\n",
      "Batch 733, Loss: 1.4144\n",
      "Batch 734, Loss: 1.4549\n",
      "Batch 735, Loss: 1.4030\n",
      "Batch 736, Loss: 1.4160\n",
      "Batch 737, Loss: 1.3986\n",
      "Batch 738, Loss: 1.4356\n",
      "Batch 739, Loss: 1.4458\n",
      "Batch 740, Loss: 1.4500\n",
      "Batch 741, Loss: 1.4346\n",
      "Batch 742, Loss: 1.4143\n",
      "Batch 743, Loss: 1.4324\n",
      "Batch 744, Loss: 1.4107\n",
      "Batch 745, Loss: 1.4235\n",
      "Batch 746, Loss: 1.4084\n",
      "Batch 747, Loss: 1.4436\n",
      "Batch 748, Loss: 1.4257\n",
      "Batch 749, Loss: 1.4407\n",
      "Batch 750, Loss: 1.4186\n",
      "Batch 751, Loss: 1.4320\n",
      "Batch 752, Loss: 1.4635\n",
      "Batch 753, Loss: 1.4673\n",
      "Batch 754, Loss: 1.4530\n",
      "Batch 755, Loss: 1.4464\n",
      "Batch 756, Loss: 1.4302\n",
      "Batch 757, Loss: 1.4376\n",
      "Batch 758, Loss: 1.4348\n",
      "Batch 759, Loss: 1.4346\n",
      "Batch 760, Loss: 1.4282\n",
      "Batch 761, Loss: 1.4243\n",
      "Batch 762, Loss: 1.4274\n",
      "Batch 763, Loss: 1.4555\n",
      "Batch 764, Loss: 1.4382\n",
      "Batch 765, Loss: 1.4332\n",
      "Batch 766, Loss: 1.3997\n",
      "Batch 767, Loss: 1.4086\n",
      "Batch 768, Loss: 1.4277\n",
      "Batch 769, Loss: 1.4620\n",
      "Batch 770, Loss: 1.4189\n",
      "Batch 771, Loss: 1.4223\n",
      "Batch 772, Loss: 1.3990\n",
      "Batch 773, Loss: 1.4283\n",
      "Batch 774, Loss: 1.4249\n",
      "Batch 775, Loss: 1.4523\n",
      "Batch 776, Loss: 1.4473\n",
      "Batch 777, Loss: 1.4248\n",
      "Batch 778, Loss: 1.4260\n",
      "Batch 779, Loss: 1.4655\n",
      "Batch 780, Loss: 1.4112\n",
      "Batch 781, Loss: 1.4418\n",
      "Batch 782, Loss: 1.4261\n",
      "Batch 783, Loss: 1.4392\n",
      "Batch 784, Loss: 1.4242\n",
      "Batch 785, Loss: 1.4531\n",
      "Batch 786, Loss: 1.4229\n",
      "Batch 787, Loss: 1.4540\n",
      "Batch 788, Loss: 1.4449\n",
      "Batch 789, Loss: 1.3925\n",
      "Batch 790, Loss: 1.4126\n",
      "Batch 791, Loss: 1.4295\n",
      "Batch 792, Loss: 1.4468\n",
      "Batch 793, Loss: 1.4255\n",
      "Batch 794, Loss: 1.4572\n",
      "Batch 795, Loss: 1.4095\n",
      "Batch 796, Loss: 1.4284\n",
      "Batch 797, Loss: 1.4173\n",
      "Batch 798, Loss: 1.4291\n",
      "Batch 799, Loss: 1.4191\n",
      "Batch 800, Loss: 1.4387\n",
      "Batch 801, Loss: 1.4197\n",
      "Batch 802, Loss: 1.4199\n",
      "Batch 803, Loss: 1.4605\n",
      "Batch 804, Loss: 1.4518\n",
      "Batch 805, Loss: 1.4150\n",
      "Batch 806, Loss: 1.4512\n",
      "Batch 807, Loss: 1.4561\n",
      "Batch 808, Loss: 1.4543\n",
      "Batch 809, Loss: 1.4095\n",
      "Batch 810, Loss: 1.4433\n",
      "Batch 811, Loss: 1.4500\n",
      "Batch 812, Loss: 1.4431\n",
      "Batch 813, Loss: 1.4456\n",
      "Batch 814, Loss: 1.4391\n",
      "Batch 815, Loss: 1.4125\n",
      "Batch 816, Loss: 1.4617\n",
      "Batch 817, Loss: 1.4571\n",
      "Batch 818, Loss: 1.4441\n",
      "Batch 819, Loss: 1.4525\n",
      "Batch 820, Loss: 1.4419\n",
      "Batch 821, Loss: 1.4263\n",
      "Batch 822, Loss: 1.4175\n",
      "Batch 823, Loss: 1.4505\n",
      "Batch 824, Loss: 1.4331\n",
      "Batch 825, Loss: 1.4217\n",
      "Batch 826, Loss: 1.4422\n",
      "Batch 827, Loss: 1.4126\n",
      "Batch 828, Loss: 1.4478\n",
      "Batch 829, Loss: 1.4155\n",
      "Batch 830, Loss: 1.4169\n",
      "Batch 831, Loss: 1.4085\n",
      "Batch 832, Loss: 1.4551\n",
      "Batch 833, Loss: 1.4404\n",
      "Batch 834, Loss: 1.4249\n",
      "Batch 835, Loss: 1.4393\n",
      "Batch 836, Loss: 1.4413\n",
      "Batch 837, Loss: 1.4192\n",
      "Batch 838, Loss: 1.4252\n",
      "Batch 839, Loss: 1.4242\n",
      "Batch 840, Loss: 1.4253\n",
      "Batch 841, Loss: 1.4205\n",
      "Batch 842, Loss: 1.4114\n",
      "Batch 843, Loss: 1.4456\n",
      "Batch 844, Loss: 1.4322\n",
      "Batch 845, Loss: 1.4108\n",
      "Batch 846, Loss: 1.4365\n",
      "Batch 847, Loss: 1.4395\n",
      "Batch 848, Loss: 1.4491\n",
      "Batch 849, Loss: 1.4204\n",
      "Batch 850, Loss: 1.4257\n",
      "Batch 851, Loss: 1.4435\n",
      "Batch 852, Loss: 1.4313\n",
      "Batch 853, Loss: 1.4382\n",
      "Batch 854, Loss: 1.4367\n",
      "Batch 855, Loss: 1.4345\n",
      "Batch 856, Loss: 1.4362\n",
      "Batch 857, Loss: 1.4274\n",
      "Batch 858, Loss: 1.4414\n",
      "Batch 859, Loss: 1.4233\n",
      "Batch 860, Loss: 1.4367\n",
      "Batch 861, Loss: 1.4443\n",
      "Batch 862, Loss: 1.4477\n",
      "Batch 863, Loss: 1.4325\n",
      "Batch 864, Loss: 1.4129\n",
      "Batch 865, Loss: 1.4174\n",
      "Batch 866, Loss: 1.4429\n",
      "Batch 867, Loss: 1.4452\n",
      "Batch 868, Loss: 1.4461\n",
      "Batch 869, Loss: 1.4501\n",
      "Batch 870, Loss: 1.4270\n",
      "Batch 871, Loss: 1.4153\n",
      "Batch 872, Loss: 1.4156\n",
      "Batch 873, Loss: 1.4213\n",
      "Batch 874, Loss: 1.4272\n",
      "Batch 875, Loss: 1.4510\n",
      "Batch 876, Loss: 1.4332\n",
      "Batch 877, Loss: 1.4361\n",
      "Batch 878, Loss: 1.4402\n",
      "Batch 879, Loss: 1.4634\n",
      "Batch 880, Loss: 1.4200\n",
      "Batch 881, Loss: 1.4437\n",
      "Batch 882, Loss: 1.4213\n",
      "Batch 883, Loss: 1.4245\n",
      "Batch 884, Loss: 1.4201\n",
      "Batch 885, Loss: 1.4506\n",
      "Batch 886, Loss: 1.4323\n",
      "Batch 887, Loss: 1.4117\n",
      "Batch 888, Loss: 1.4460\n",
      "Batch 889, Loss: 1.4220\n",
      "Batch 890, Loss: 1.4285\n",
      "Batch 891, Loss: 1.4238\n",
      "Batch 892, Loss: 1.4376\n",
      "Batch 893, Loss: 1.4313\n",
      "Batch 894, Loss: 1.4421\n",
      "Batch 895, Loss: 1.4292\n",
      "Batch 896, Loss: 1.4259\n",
      "Batch 897, Loss: 1.4169\n",
      "Batch 898, Loss: 1.4614\n",
      "Batch 899, Loss: 1.4488\n",
      "Batch 900, Loss: 1.4406\n",
      "Batch 901, Loss: 1.4436\n",
      "Batch 902, Loss: 1.4406\n",
      "Batch 903, Loss: 1.4346\n",
      "Batch 904, Loss: 1.4163\n",
      "Batch 905, Loss: 1.4396\n",
      "Batch 906, Loss: 1.4220\n",
      "Batch 907, Loss: 1.4526\n",
      "Batch 908, Loss: 1.4235\n",
      "Batch 909, Loss: 1.4333\n",
      "Batch 910, Loss: 1.4225\n",
      "Batch 911, Loss: 1.3930\n",
      "Batch 912, Loss: 1.4391\n",
      "Batch 913, Loss: 1.4458\n",
      "Batch 914, Loss: 1.4017\n",
      "Batch 915, Loss: 1.4400\n",
      "Batch 916, Loss: 1.4334\n",
      "Batch 917, Loss: 1.4524\n",
      "Batch 918, Loss: 1.4485\n",
      "Batch 919, Loss: 1.4311\n",
      "Batch 920, Loss: 1.4360\n",
      "Batch 921, Loss: 1.4507\n",
      "Batch 922, Loss: 1.4337\n",
      "Batch 923, Loss: 1.4473\n",
      "Batch 924, Loss: 1.4350\n",
      "Batch 925, Loss: 1.4581\n",
      "Batch 926, Loss: 1.4471\n",
      "Batch 927, Loss: 1.4475\n",
      "Batch 928, Loss: 1.4249\n",
      "Batch 929, Loss: 1.4550\n",
      "Batch 930, Loss: 1.4182\n",
      "Batch 931, Loss: 1.4166\n",
      "Batch 932, Loss: 1.4410\n",
      "Batch 933, Loss: 1.4556\n",
      "Batch 934, Loss: 1.4237\n",
      "Batch 935, Loss: 1.4594\n",
      "Batch 936, Loss: 1.4416\n",
      "Batch 937, Loss: 1.4207\n",
      "Batch 938, Loss: 1.4195\n",
      "Batch 939, Loss: 1.4596\n",
      "Batch 940, Loss: 1.4356\n",
      "Batch 941, Loss: 1.4257\n",
      "Batch 942, Loss: 1.4714\n",
      "Batch 943, Loss: 1.4535\n",
      "Batch 944, Loss: 1.4321\n",
      "Batch 945, Loss: 1.4316\n",
      "Batch 946, Loss: 1.4483\n",
      "Batch 947, Loss: 1.4128\n",
      "Batch 948, Loss: 1.4271\n",
      "Batch 949, Loss: 1.4351\n",
      "Batch 950, Loss: 1.4421\n",
      "Batch 951, Loss: 1.4341\n",
      "Batch 952, Loss: 1.4357\n",
      "Batch 953, Loss: 1.4220\n",
      "Batch 954, Loss: 1.4311\n",
      "Batch 955, Loss: 1.4278\n",
      "Batch 956, Loss: 1.4305\n",
      "Batch 957, Loss: 1.4429\n",
      "Batch 958, Loss: 1.4100\n",
      "Batch 959, Loss: 1.3861\n",
      "Batch 960, Loss: 1.4268\n",
      "Batch 961, Loss: 1.4437\n",
      "Batch 962, Loss: 1.4169\n",
      "Batch 963, Loss: 1.4496\n",
      "Batch 964, Loss: 1.4282\n",
      "Batch 965, Loss: 1.4461\n",
      "Epoch 7, Average Loss: 1.4377\n",
      "Once upon a time, there was a little girl named Lily. She was playing with her toys and having lots of fun. Sunday, she saw \n",
      "a modern on a box with long, broken toys. Suddenly, she accidentrually burned her fingerce and Lucky came up to it. She was so frightened \n",
      "and she started to cry. Lily started to cry, and the modern toy trapped and bit him down. Just missed her, her stomach wound when \n",
      "she made the band feeling miserabing. She was an ignorant lorge, and that it wasn't stuck! The storm clouded and it was accidentally knocking his \n",
      "finger. She got frustrated and started to cry. Her stomet go to the back of adment, and Lucky went around and went back to the \n",
      "nearby's house. Lily still loved her perfume and felt safe and happy. \n",
      "\n",
      "--------------------\n",
      "Batch 0, Loss: 1.4248\n",
      "Batch 1, Loss: 1.4111\n",
      "Batch 2, Loss: 1.4167\n",
      "Batch 3, Loss: 1.4007\n",
      "Batch 4, Loss: 1.3960\n",
      "Batch 5, Loss: 1.4073\n",
      "Batch 6, Loss: 1.4212\n",
      "Batch 7, Loss: 1.4023\n",
      "Batch 8, Loss: 1.4245\n",
      "Batch 9, Loss: 1.4248\n",
      "Batch 10, Loss: 1.4222\n",
      "Batch 11, Loss: 1.4116\n",
      "Batch 12, Loss: 1.3902\n",
      "Batch 13, Loss: 1.4115\n",
      "Batch 14, Loss: 1.4184\n",
      "Batch 15, Loss: 1.4491\n",
      "Batch 16, Loss: 1.3923\n",
      "Batch 17, Loss: 1.4102\n",
      "Batch 18, Loss: 1.4125\n",
      "Batch 19, Loss: 1.4448\n",
      "Batch 20, Loss: 1.4143\n",
      "Batch 21, Loss: 1.4016\n",
      "Batch 22, Loss: 1.4106\n",
      "Batch 23, Loss: 1.4412\n",
      "Batch 24, Loss: 1.4078\n",
      "Batch 25, Loss: 1.4496\n",
      "Batch 26, Loss: 1.4127\n",
      "Batch 27, Loss: 1.4230\n",
      "Batch 28, Loss: 1.3942\n",
      "Batch 29, Loss: 1.4273\n",
      "Batch 30, Loss: 1.4456\n",
      "Batch 31, Loss: 1.4298\n",
      "Batch 32, Loss: 1.4018\n",
      "Batch 33, Loss: 1.3846\n",
      "Batch 34, Loss: 1.4398\n",
      "Batch 35, Loss: 1.4205\n",
      "Batch 36, Loss: 1.4364\n",
      "Batch 37, Loss: 1.4203\n",
      "Batch 38, Loss: 1.4244\n",
      "Batch 39, Loss: 1.4253\n",
      "Batch 40, Loss: 1.4205\n",
      "Batch 41, Loss: 1.4341\n",
      "Batch 42, Loss: 1.4417\n",
      "Batch 43, Loss: 1.4375\n",
      "Batch 44, Loss: 1.4471\n",
      "Batch 45, Loss: 1.4330\n",
      "Batch 46, Loss: 1.4283\n",
      "Batch 47, Loss: 1.4003\n",
      "Batch 48, Loss: 1.4193\n",
      "Batch 49, Loss: 1.4215\n",
      "Batch 50, Loss: 1.3821\n",
      "Batch 51, Loss: 1.4178\n",
      "Batch 52, Loss: 1.4488\n",
      "Batch 53, Loss: 1.4026\n",
      "Batch 54, Loss: 1.4290\n",
      "Batch 55, Loss: 1.4250\n",
      "Batch 56, Loss: 1.3943\n",
      "Batch 57, Loss: 1.4070\n",
      "Batch 58, Loss: 1.4060\n",
      "Batch 59, Loss: 1.4433\n",
      "Batch 60, Loss: 1.4127\n",
      "Batch 61, Loss: 1.4122\n",
      "Batch 62, Loss: 1.4454\n",
      "Batch 63, Loss: 1.3787\n",
      "Batch 64, Loss: 1.4269\n",
      "Batch 65, Loss: 1.4137\n",
      "Batch 66, Loss: 1.4276\n",
      "Batch 67, Loss: 1.4487\n",
      "Batch 68, Loss: 1.4039\n",
      "Batch 69, Loss: 1.4131\n",
      "Batch 70, Loss: 1.4199\n",
      "Batch 71, Loss: 1.4148\n",
      "Batch 72, Loss: 1.4262\n",
      "Batch 73, Loss: 1.4320\n",
      "Batch 74, Loss: 1.4586\n",
      "Batch 75, Loss: 1.4411\n",
      "Batch 76, Loss: 1.4043\n",
      "Batch 77, Loss: 1.4245\n",
      "Batch 78, Loss: 1.4359\n",
      "Batch 79, Loss: 1.4289\n",
      "Batch 80, Loss: 1.4250\n",
      "Batch 81, Loss: 1.4559\n",
      "Batch 82, Loss: 1.4294\n",
      "Batch 83, Loss: 1.4035\n",
      "Batch 84, Loss: 1.4168\n",
      "Batch 85, Loss: 1.4023\n",
      "Batch 86, Loss: 1.4101\n",
      "Batch 87, Loss: 1.4295\n",
      "Batch 88, Loss: 1.4582\n",
      "Batch 89, Loss: 1.4216\n",
      "Batch 90, Loss: 1.4299\n",
      "Batch 91, Loss: 1.4400\n",
      "Batch 92, Loss: 1.4501\n",
      "Batch 93, Loss: 1.4113\n",
      "Batch 94, Loss: 1.4487\n",
      "Batch 95, Loss: 1.4152\n",
      "Batch 96, Loss: 1.4347\n",
      "Batch 97, Loss: 1.4212\n",
      "Batch 98, Loss: 1.4329\n",
      "Batch 99, Loss: 1.4489\n",
      "Batch 100, Loss: 1.4168\n",
      "Batch 101, Loss: 1.4241\n",
      "Batch 102, Loss: 1.4064\n",
      "Batch 103, Loss: 1.4130\n",
      "Batch 104, Loss: 1.4169\n",
      "Batch 105, Loss: 1.4117\n",
      "Batch 106, Loss: 1.4401\n",
      "Batch 107, Loss: 1.4252\n",
      "Batch 108, Loss: 1.4196\n",
      "Batch 109, Loss: 1.3937\n",
      "Batch 110, Loss: 1.4704\n",
      "Batch 111, Loss: 1.4356\n",
      "Batch 112, Loss: 1.4346\n",
      "Batch 113, Loss: 1.4495\n",
      "Batch 114, Loss: 1.3821\n",
      "Batch 115, Loss: 1.4332\n",
      "Batch 116, Loss: 1.4192\n",
      "Batch 117, Loss: 1.4342\n",
      "Batch 118, Loss: 1.4090\n",
      "Batch 119, Loss: 1.4209\n",
      "Batch 120, Loss: 1.4313\n",
      "Batch 121, Loss: 1.4450\n",
      "Batch 122, Loss: 1.4471\n",
      "Batch 123, Loss: 1.4356\n",
      "Batch 124, Loss: 1.4371\n",
      "Batch 125, Loss: 1.4373\n",
      "Batch 126, Loss: 1.4155\n",
      "Batch 127, Loss: 1.4123\n",
      "Batch 128, Loss: 1.4374\n",
      "Batch 129, Loss: 1.4214\n",
      "Batch 130, Loss: 1.4317\n",
      "Batch 131, Loss: 1.4031\n",
      "Batch 132, Loss: 1.3913\n",
      "Batch 133, Loss: 1.4198\n",
      "Batch 134, Loss: 1.4133\n",
      "Batch 135, Loss: 1.4268\n",
      "Batch 136, Loss: 1.4440\n",
      "Batch 137, Loss: 1.4050\n",
      "Batch 138, Loss: 1.4111\n",
      "Batch 139, Loss: 1.4324\n",
      "Batch 140, Loss: 1.4315\n",
      "Batch 141, Loss: 1.3953\n",
      "Batch 142, Loss: 1.4210\n",
      "Batch 143, Loss: 1.4342\n",
      "Batch 144, Loss: 1.4162\n",
      "Batch 145, Loss: 1.3926\n",
      "Batch 146, Loss: 1.4348\n",
      "Batch 147, Loss: 1.4124\n",
      "Batch 148, Loss: 1.4020\n",
      "Batch 149, Loss: 1.4106\n",
      "Batch 150, Loss: 1.4271\n",
      "Batch 151, Loss: 1.4164\n",
      "Batch 152, Loss: 1.4098\n",
      "Batch 153, Loss: 1.4553\n",
      "Batch 154, Loss: 1.4017\n",
      "Batch 155, Loss: 1.4181\n",
      "Batch 156, Loss: 1.4241\n",
      "Batch 157, Loss: 1.4327\n",
      "Batch 158, Loss: 1.4134\n",
      "Batch 159, Loss: 1.4136\n",
      "Batch 160, Loss: 1.4379\n",
      "Batch 161, Loss: 1.4091\n",
      "Batch 162, Loss: 1.4507\n",
      "Batch 163, Loss: 1.4189\n",
      "Batch 164, Loss: 1.4001\n",
      "Batch 165, Loss: 1.4152\n",
      "Batch 166, Loss: 1.4268\n",
      "Batch 167, Loss: 1.4446\n",
      "Batch 168, Loss: 1.4495\n",
      "Batch 169, Loss: 1.4327\n",
      "Batch 170, Loss: 1.4189\n",
      "Batch 171, Loss: 1.4367\n",
      "Batch 172, Loss: 1.4433\n",
      "Batch 173, Loss: 1.4400\n",
      "Batch 174, Loss: 1.4366\n",
      "Batch 175, Loss: 1.4166\n",
      "Batch 176, Loss: 1.4259\n",
      "Batch 177, Loss: 1.4450\n",
      "Batch 178, Loss: 1.4220\n",
      "Batch 179, Loss: 1.4146\n",
      "Batch 180, Loss: 1.4172\n",
      "Batch 181, Loss: 1.4255\n",
      "Batch 182, Loss: 1.4247\n",
      "Batch 183, Loss: 1.4100\n",
      "Batch 184, Loss: 1.4368\n",
      "Batch 185, Loss: 1.4444\n",
      "Batch 186, Loss: 1.4174\n",
      "Batch 187, Loss: 1.4388\n",
      "Batch 188, Loss: 1.4016\n",
      "Batch 189, Loss: 1.4197\n",
      "Batch 190, Loss: 1.4189\n",
      "Batch 191, Loss: 1.4005\n",
      "Batch 192, Loss: 1.4477\n",
      "Batch 193, Loss: 1.4199\n",
      "Batch 194, Loss: 1.4454\n",
      "Batch 195, Loss: 1.4500\n",
      "Batch 196, Loss: 1.4370\n",
      "Batch 197, Loss: 1.4243\n",
      "Batch 198, Loss: 1.4124\n",
      "Batch 199, Loss: 1.4500\n",
      "Batch 200, Loss: 1.4183\n",
      "Batch 201, Loss: 1.4109\n",
      "Batch 202, Loss: 1.4246\n",
      "Batch 203, Loss: 1.4314\n",
      "Batch 204, Loss: 1.4212\n",
      "Batch 205, Loss: 1.4301\n",
      "Batch 206, Loss: 1.4307\n",
      "Batch 207, Loss: 1.4405\n",
      "Batch 208, Loss: 1.4091\n",
      "Batch 209, Loss: 1.4342\n",
      "Batch 210, Loss: 1.3994\n",
      "Batch 211, Loss: 1.4313\n",
      "Batch 212, Loss: 1.4241\n",
      "Batch 213, Loss: 1.4578\n",
      "Batch 214, Loss: 1.4055\n",
      "Batch 215, Loss: 1.4052\n",
      "Batch 216, Loss: 1.4353\n",
      "Batch 217, Loss: 1.4193\n",
      "Batch 218, Loss: 1.4425\n",
      "Batch 219, Loss: 1.4097\n",
      "Batch 220, Loss: 1.4441\n",
      "Batch 221, Loss: 1.4213\n",
      "Batch 222, Loss: 1.4070\n",
      "Batch 223, Loss: 1.4302\n",
      "Batch 224, Loss: 1.4249\n",
      "Batch 225, Loss: 1.3933\n",
      "Batch 226, Loss: 1.4190\n",
      "Batch 227, Loss: 1.4068\n",
      "Batch 228, Loss: 1.4203\n",
      "Batch 229, Loss: 1.4219\n",
      "Batch 230, Loss: 1.4462\n",
      "Batch 231, Loss: 1.4468\n",
      "Batch 232, Loss: 1.4058\n",
      "Batch 233, Loss: 1.4098\n",
      "Batch 234, Loss: 1.4271\n",
      "Batch 235, Loss: 1.4398\n",
      "Batch 236, Loss: 1.4315\n",
      "Batch 237, Loss: 1.4355\n",
      "Batch 238, Loss: 1.4536\n",
      "Batch 239, Loss: 1.4229\n",
      "Batch 240, Loss: 1.4395\n",
      "Batch 241, Loss: 1.4345\n",
      "Batch 242, Loss: 1.4259\n",
      "Batch 243, Loss: 1.4195\n",
      "Batch 244, Loss: 1.4335\n",
      "Batch 245, Loss: 1.4274\n",
      "Batch 246, Loss: 1.3977\n",
      "Batch 247, Loss: 1.4195\n",
      "Batch 248, Loss: 1.4379\n",
      "Batch 249, Loss: 1.4103\n",
      "Batch 250, Loss: 1.4378\n",
      "Batch 251, Loss: 1.4366\n",
      "Batch 252, Loss: 1.4198\n",
      "Batch 253, Loss: 1.4192\n",
      "Batch 254, Loss: 1.4192\n",
      "Batch 255, Loss: 1.4263\n",
      "Batch 256, Loss: 1.4243\n",
      "Batch 257, Loss: 1.4153\n",
      "Batch 258, Loss: 1.4170\n",
      "Batch 259, Loss: 1.4219\n",
      "Batch 260, Loss: 1.4452\n",
      "Batch 261, Loss: 1.4085\n",
      "Batch 262, Loss: 1.4144\n",
      "Batch 263, Loss: 1.3889\n",
      "Batch 264, Loss: 1.4267\n",
      "Batch 265, Loss: 1.4245\n",
      "Batch 266, Loss: 1.4329\n",
      "Batch 267, Loss: 1.4364\n",
      "Batch 268, Loss: 1.4343\n",
      "Batch 269, Loss: 1.4170\n",
      "Batch 270, Loss: 1.4365\n",
      "Batch 271, Loss: 1.3939\n",
      "Batch 272, Loss: 1.4140\n",
      "Batch 273, Loss: 1.4156\n",
      "Batch 274, Loss: 1.3981\n",
      "Batch 275, Loss: 1.4320\n",
      "Batch 276, Loss: 1.4330\n",
      "Batch 277, Loss: 1.4393\n",
      "Batch 278, Loss: 1.4312\n",
      "Batch 279, Loss: 1.4075\n",
      "Batch 280, Loss: 1.4039\n",
      "Batch 281, Loss: 1.4190\n",
      "Batch 282, Loss: 1.4212\n",
      "Batch 283, Loss: 1.4116\n",
      "Batch 284, Loss: 1.3943\n",
      "Batch 285, Loss: 1.4350\n",
      "Batch 286, Loss: 1.4146\n",
      "Batch 287, Loss: 1.4430\n",
      "Batch 288, Loss: 1.4077\n",
      "Batch 289, Loss: 1.4251\n",
      "Batch 290, Loss: 1.4221\n",
      "Batch 291, Loss: 1.4644\n",
      "Batch 292, Loss: 1.3839\n",
      "Batch 293, Loss: 1.4356\n",
      "Batch 294, Loss: 1.4272\n",
      "Batch 295, Loss: 1.4167\n",
      "Batch 296, Loss: 1.4360\n",
      "Batch 297, Loss: 1.3924\n",
      "Batch 298, Loss: 1.4483\n",
      "Batch 299, Loss: 1.4099\n",
      "Batch 300, Loss: 1.4309\n",
      "Batch 301, Loss: 1.4239\n",
      "Batch 302, Loss: 1.4307\n",
      "Batch 303, Loss: 1.4219\n",
      "Batch 304, Loss: 1.4194\n",
      "Batch 305, Loss: 1.3984\n",
      "Batch 306, Loss: 1.4405\n",
      "Batch 307, Loss: 1.3935\n",
      "Batch 308, Loss: 1.4064\n",
      "Batch 309, Loss: 1.4329\n",
      "Batch 310, Loss: 1.4274\n",
      "Batch 311, Loss: 1.4130\n",
      "Batch 312, Loss: 1.4196\n",
      "Batch 313, Loss: 1.4217\n",
      "Batch 314, Loss: 1.4044\n",
      "Batch 315, Loss: 1.4133\n",
      "Batch 316, Loss: 1.4118\n",
      "Batch 317, Loss: 1.4285\n",
      "Batch 318, Loss: 1.4202\n",
      "Batch 319, Loss: 1.4179\n",
      "Batch 320, Loss: 1.4220\n",
      "Batch 321, Loss: 1.4133\n",
      "Batch 322, Loss: 1.4349\n",
      "Batch 323, Loss: 1.4477\n",
      "Batch 324, Loss: 1.4182\n",
      "Batch 325, Loss: 1.4105\n",
      "Batch 326, Loss: 1.4252\n",
      "Batch 327, Loss: 1.4050\n",
      "Batch 328, Loss: 1.3988\n",
      "Batch 329, Loss: 1.4367\n",
      "Batch 330, Loss: 1.4260\n",
      "Batch 331, Loss: 1.4384\n",
      "Batch 332, Loss: 1.4307\n",
      "Batch 333, Loss: 1.4208\n",
      "Batch 334, Loss: 1.4094\n",
      "Batch 335, Loss: 1.4272\n",
      "Batch 336, Loss: 1.4203\n",
      "Batch 337, Loss: 1.4166\n",
      "Batch 338, Loss: 1.4199\n",
      "Batch 339, Loss: 1.4194\n",
      "Batch 340, Loss: 1.4151\n",
      "Batch 341, Loss: 1.4020\n",
      "Batch 342, Loss: 1.4353\n",
      "Batch 343, Loss: 1.4145\n",
      "Batch 344, Loss: 1.4259\n",
      "Batch 345, Loss: 1.4356\n",
      "Batch 346, Loss: 1.4126\n",
      "Batch 347, Loss: 1.4325\n",
      "Batch 348, Loss: 1.4273\n",
      "Batch 349, Loss: 1.4359\n",
      "Batch 350, Loss: 1.4246\n",
      "Batch 351, Loss: 1.4460\n",
      "Batch 352, Loss: 1.4174\n",
      "Batch 353, Loss: 1.4625\n",
      "Batch 354, Loss: 1.4354\n",
      "Batch 355, Loss: 1.4015\n",
      "Batch 356, Loss: 1.4082\n",
      "Batch 357, Loss: 1.4304\n",
      "Batch 358, Loss: 1.4225\n",
      "Batch 359, Loss: 1.4391\n",
      "Batch 360, Loss: 1.4423\n",
      "Batch 361, Loss: 1.4432\n",
      "Batch 362, Loss: 1.4347\n",
      "Batch 363, Loss: 1.4338\n",
      "Batch 364, Loss: 1.4128\n",
      "Batch 365, Loss: 1.4306\n",
      "Batch 366, Loss: 1.4254\n",
      "Batch 367, Loss: 1.4156\n",
      "Batch 368, Loss: 1.4098\n",
      "Batch 369, Loss: 1.4151\n",
      "Batch 370, Loss: 1.4241\n",
      "Batch 371, Loss: 1.4257\n",
      "Batch 372, Loss: 1.4543\n",
      "Batch 373, Loss: 1.3982\n",
      "Batch 374, Loss: 1.4265\n",
      "Batch 375, Loss: 1.4146\n",
      "Batch 376, Loss: 1.4125\n",
      "Batch 377, Loss: 1.4329\n",
      "Batch 378, Loss: 1.4248\n",
      "Batch 379, Loss: 1.4153\n",
      "Batch 380, Loss: 1.4451\n",
      "Batch 381, Loss: 1.4031\n",
      "Batch 382, Loss: 1.4058\n",
      "Batch 383, Loss: 1.4369\n",
      "Batch 384, Loss: 1.4493\n",
      "Batch 385, Loss: 1.4568\n",
      "Batch 386, Loss: 1.4324\n",
      "Batch 387, Loss: 1.4419\n",
      "Batch 388, Loss: 1.4248\n",
      "Batch 389, Loss: 1.4435\n",
      "Batch 390, Loss: 1.4219\n",
      "Batch 391, Loss: 1.4443\n",
      "Batch 392, Loss: 1.4224\n",
      "Batch 393, Loss: 1.4313\n",
      "Batch 394, Loss: 1.4352\n",
      "Batch 395, Loss: 1.4373\n",
      "Batch 396, Loss: 1.4472\n",
      "Batch 397, Loss: 1.4270\n",
      "Batch 398, Loss: 1.4215\n",
      "Batch 399, Loss: 1.4033\n",
      "Batch 400, Loss: 1.4087\n",
      "Batch 401, Loss: 1.4291\n",
      "Batch 402, Loss: 1.4062\n",
      "Batch 403, Loss: 1.3922\n",
      "Batch 404, Loss: 1.4338\n",
      "Batch 405, Loss: 1.4483\n",
      "Batch 406, Loss: 1.4500\n",
      "Batch 407, Loss: 1.4452\n",
      "Batch 408, Loss: 1.4116\n",
      "Batch 409, Loss: 1.4272\n",
      "Batch 410, Loss: 1.4408\n",
      "Batch 411, Loss: 1.4255\n",
      "Batch 412, Loss: 1.4324\n",
      "Batch 413, Loss: 1.4215\n",
      "Batch 414, Loss: 1.4236\n",
      "Batch 415, Loss: 1.4373\n",
      "Batch 416, Loss: 1.3905\n",
      "Batch 417, Loss: 1.4404\n",
      "Batch 418, Loss: 1.4049\n",
      "Batch 419, Loss: 1.4287\n",
      "Batch 420, Loss: 1.4372\n",
      "Batch 421, Loss: 1.4162\n",
      "Batch 422, Loss: 1.4247\n",
      "Batch 423, Loss: 1.4350\n",
      "Batch 424, Loss: 1.3964\n",
      "Batch 425, Loss: 1.4062\n",
      "Batch 426, Loss: 1.4395\n",
      "Batch 427, Loss: 1.4094\n",
      "Batch 428, Loss: 1.4082\n",
      "Batch 429, Loss: 1.4119\n",
      "Batch 430, Loss: 1.4351\n",
      "Batch 431, Loss: 1.4184\n",
      "Batch 432, Loss: 1.4577\n",
      "Batch 433, Loss: 1.4046\n",
      "Batch 434, Loss: 1.4250\n",
      "Batch 435, Loss: 1.3960\n",
      "Batch 436, Loss: 1.4163\n",
      "Batch 437, Loss: 1.4141\n",
      "Batch 438, Loss: 1.4367\n",
      "Batch 439, Loss: 1.4288\n",
      "Batch 440, Loss: 1.4169\n",
      "Batch 441, Loss: 1.4118\n",
      "Batch 442, Loss: 1.4278\n",
      "Batch 443, Loss: 1.4125\n",
      "Batch 444, Loss: 1.4182\n",
      "Batch 445, Loss: 1.4292\n",
      "Batch 446, Loss: 1.4560\n",
      "Batch 447, Loss: 1.4390\n",
      "Batch 448, Loss: 1.4484\n",
      "Batch 449, Loss: 1.4107\n",
      "Batch 450, Loss: 1.4327\n",
      "Batch 451, Loss: 1.3983\n",
      "Batch 452, Loss: 1.4194\n",
      "Batch 453, Loss: 1.3891\n",
      "Batch 454, Loss: 1.4437\n",
      "Batch 455, Loss: 1.4307\n",
      "Batch 456, Loss: 1.4057\n",
      "Batch 457, Loss: 1.4633\n",
      "Batch 458, Loss: 1.4034\n",
      "Batch 459, Loss: 1.4185\n",
      "Batch 460, Loss: 1.3986\n",
      "Batch 461, Loss: 1.4060\n",
      "Batch 462, Loss: 1.4244\n",
      "Batch 463, Loss: 1.4128\n",
      "Batch 464, Loss: 1.4141\n",
      "Batch 465, Loss: 1.4225\n",
      "Batch 466, Loss: 1.4439\n",
      "Batch 467, Loss: 1.4226\n",
      "Batch 468, Loss: 1.4291\n",
      "Batch 469, Loss: 1.4422\n",
      "Batch 470, Loss: 1.4113\n",
      "Batch 471, Loss: 1.4159\n",
      "Batch 472, Loss: 1.4214\n",
      "Batch 473, Loss: 1.3914\n",
      "Batch 474, Loss: 1.4156\n",
      "Batch 475, Loss: 1.4023\n",
      "Batch 476, Loss: 1.3934\n",
      "Batch 477, Loss: 1.4247\n",
      "Batch 478, Loss: 1.4235\n",
      "Batch 479, Loss: 1.4561\n",
      "Batch 480, Loss: 1.4083\n",
      "Batch 481, Loss: 1.4129\n",
      "Batch 482, Loss: 1.4076\n",
      "Batch 483, Loss: 1.3884\n",
      "Mama was sitting on the couch with a spoon in it. The two others in the houses started crawling on the couch and Mama saw \n",
      "lots of animals playing lilelina speed. Mama and Mama smiled at each other and cheered. Mama had gain some high and scarve. She did not \n",
      "want to take a taste. She said, \"No! You need is hurt like nothing else Daddy! Then we can share things for you.\" Mama scrunched \n",
      "her nose and handed her to the couch. The two of them at a time, and Mama made both of them out of the couch, \n",
      "and Mama's snuggle together was opened with starting to roll the chans and syrup. Mama said, \"Yes, we did it! First, mommy give me another \n",
      "box of hurt! How do you want to play?\" \n",
      "\n",
      "--------------------\n",
      "Batch 484, Loss: 1.4393\n",
      "Batch 485, Loss: 1.4116\n",
      "Batch 486, Loss: 1.4478\n",
      "Batch 487, Loss: 1.4360\n",
      "Batch 488, Loss: 1.4293\n",
      "Batch 489, Loss: 1.4204\n",
      "Batch 490, Loss: 1.4212\n",
      "Batch 491, Loss: 1.4161\n",
      "Batch 492, Loss: 1.4411\n",
      "Batch 493, Loss: 1.4234\n",
      "Batch 494, Loss: 1.4367\n",
      "Batch 495, Loss: 1.4191\n",
      "Batch 496, Loss: 1.4226\n",
      "Batch 497, Loss: 1.4390\n",
      "Batch 498, Loss: 1.4029\n",
      "Batch 499, Loss: 1.4220\n",
      "Batch 500, Loss: 1.4292\n",
      "Batch 501, Loss: 1.4159\n",
      "Batch 502, Loss: 1.4203\n",
      "Batch 503, Loss: 1.4051\n",
      "Batch 504, Loss: 1.4010\n",
      "Batch 505, Loss: 1.4186\n",
      "Batch 506, Loss: 1.4011\n",
      "Batch 507, Loss: 1.4282\n",
      "Batch 508, Loss: 1.4442\n",
      "Batch 509, Loss: 1.4192\n",
      "Batch 510, Loss: 1.4456\n",
      "Batch 511, Loss: 1.4179\n",
      "Batch 512, Loss: 1.4469\n",
      "Batch 513, Loss: 1.4104\n",
      "Batch 514, Loss: 1.4083\n",
      "Batch 515, Loss: 1.4038\n",
      "Batch 516, Loss: 1.4095\n",
      "Batch 517, Loss: 1.4280\n",
      "Batch 518, Loss: 1.4010\n",
      "Batch 519, Loss: 1.4227\n",
      "Batch 520, Loss: 1.4115\n",
      "Batch 521, Loss: 1.4020\n",
      "Batch 522, Loss: 1.4133\n",
      "Batch 523, Loss: 1.3947\n",
      "Batch 524, Loss: 1.4418\n",
      "Batch 525, Loss: 1.4279\n",
      "Batch 526, Loss: 1.4234\n",
      "Batch 527, Loss: 1.4139\n",
      "Batch 528, Loss: 1.4331\n",
      "Batch 529, Loss: 1.4296\n",
      "Batch 530, Loss: 1.4172\n",
      "Batch 531, Loss: 1.4072\n",
      "Batch 532, Loss: 1.4035\n",
      "Batch 533, Loss: 1.4127\n",
      "Batch 534, Loss: 1.4326\n",
      "Batch 535, Loss: 1.4201\n",
      "Batch 536, Loss: 1.4129\n",
      "Batch 537, Loss: 1.4166\n",
      "Batch 538, Loss: 1.4357\n",
      "Batch 539, Loss: 1.4066\n",
      "Batch 540, Loss: 1.4064\n",
      "Batch 541, Loss: 1.4118\n",
      "Batch 542, Loss: 1.3961\n",
      "Batch 543, Loss: 1.4061\n",
      "Batch 544, Loss: 1.4298\n",
      "Batch 545, Loss: 1.4049\n",
      "Batch 546, Loss: 1.4082\n",
      "Batch 547, Loss: 1.4330\n",
      "Batch 548, Loss: 1.4305\n",
      "Batch 549, Loss: 1.4072\n",
      "Batch 550, Loss: 1.4243\n",
      "Batch 551, Loss: 1.4519\n",
      "Batch 552, Loss: 1.4226\n",
      "Batch 553, Loss: 1.3995\n",
      "Batch 554, Loss: 1.4075\n",
      "Batch 555, Loss: 1.4149\n",
      "Batch 556, Loss: 1.4426\n",
      "Batch 557, Loss: 1.4283\n",
      "Batch 558, Loss: 1.4338\n",
      "Batch 559, Loss: 1.4112\n",
      "Batch 560, Loss: 1.4093\n",
      "Batch 561, Loss: 1.4313\n",
      "Batch 562, Loss: 1.4623\n",
      "Batch 563, Loss: 1.4249\n",
      "Batch 564, Loss: 1.4254\n",
      "Batch 565, Loss: 1.4324\n",
      "Batch 566, Loss: 1.4210\n",
      "Batch 567, Loss: 1.4429\n",
      "Batch 568, Loss: 1.3961\n",
      "Batch 569, Loss: 1.4363\n",
      "Batch 570, Loss: 1.4506\n",
      "Batch 571, Loss: 1.4024\n",
      "Batch 572, Loss: 1.4366\n",
      "Batch 573, Loss: 1.4067\n",
      "Batch 574, Loss: 1.4248\n",
      "Batch 575, Loss: 1.3957\n",
      "Batch 576, Loss: 1.4338\n",
      "Batch 577, Loss: 1.4256\n",
      "Batch 578, Loss: 1.4045\n",
      "Batch 579, Loss: 1.4100\n",
      "Batch 580, Loss: 1.4003\n",
      "Batch 581, Loss: 1.4198\n",
      "Batch 582, Loss: 1.4211\n",
      "Batch 583, Loss: 1.4282\n",
      "Batch 584, Loss: 1.4035\n",
      "Batch 585, Loss: 1.4237\n",
      "Batch 586, Loss: 1.4442\n",
      "Batch 587, Loss: 1.4251\n",
      "Batch 588, Loss: 1.4364\n",
      "Batch 589, Loss: 1.4392\n",
      "Batch 590, Loss: 1.4210\n",
      "Batch 591, Loss: 1.4415\n",
      "Batch 592, Loss: 1.4252\n",
      "Batch 593, Loss: 1.3820\n",
      "Batch 594, Loss: 1.4203\n",
      "Batch 595, Loss: 1.4025\n",
      "Batch 596, Loss: 1.4059\n",
      "Batch 597, Loss: 1.4121\n",
      "Batch 598, Loss: 1.4345\n",
      "Batch 599, Loss: 1.4277\n",
      "Batch 600, Loss: 1.4112\n",
      "Batch 601, Loss: 1.4081\n",
      "Batch 602, Loss: 1.4019\n",
      "Batch 603, Loss: 1.4338\n",
      "Batch 604, Loss: 1.4443\n",
      "Batch 605, Loss: 1.4148\n",
      "Batch 606, Loss: 1.4237\n",
      "Batch 607, Loss: 1.4215\n",
      "Batch 608, Loss: 1.4174\n",
      "Batch 609, Loss: 1.4111\n",
      "Batch 610, Loss: 1.4119\n",
      "Batch 611, Loss: 1.4159\n",
      "Batch 612, Loss: 1.4236\n",
      "Batch 613, Loss: 1.4213\n",
      "Batch 614, Loss: 1.4116\n",
      "Batch 615, Loss: 1.4367\n",
      "Batch 616, Loss: 1.4048\n",
      "Batch 617, Loss: 1.4099\n",
      "Batch 618, Loss: 1.4178\n",
      "Batch 619, Loss: 1.3967\n",
      "Batch 620, Loss: 1.4011\n",
      "Batch 621, Loss: 1.4064\n",
      "Batch 622, Loss: 1.4145\n",
      "Batch 623, Loss: 1.4249\n",
      "Batch 624, Loss: 1.4284\n",
      "Batch 625, Loss: 1.4023\n",
      "Batch 626, Loss: 1.4163\n",
      "Batch 627, Loss: 1.4222\n",
      "Batch 628, Loss: 1.4001\n",
      "Batch 629, Loss: 1.4175\n",
      "Batch 630, Loss: 1.4359\n",
      "Batch 631, Loss: 1.4492\n",
      "Batch 632, Loss: 1.4065\n",
      "Batch 633, Loss: 1.4070\n",
      "Batch 634, Loss: 1.4268\n",
      "Batch 635, Loss: 1.4205\n",
      "Batch 636, Loss: 1.3974\n",
      "Batch 637, Loss: 1.4546\n",
      "Batch 638, Loss: 1.4099\n",
      "Batch 639, Loss: 1.4119\n",
      "Batch 640, Loss: 1.3869\n",
      "Batch 641, Loss: 1.4203\n",
      "Batch 642, Loss: 1.4193\n",
      "Batch 643, Loss: 1.4280\n",
      "Batch 644, Loss: 1.4206\n",
      "Batch 645, Loss: 1.4258\n",
      "Batch 646, Loss: 1.4133\n",
      "Batch 647, Loss: 1.4353\n",
      "Batch 648, Loss: 1.4304\n",
      "Batch 649, Loss: 1.3910\n",
      "Batch 650, Loss: 1.4129\n",
      "Batch 651, Loss: 1.4131\n",
      "Batch 652, Loss: 1.4255\n",
      "Batch 653, Loss: 1.4187\n",
      "Batch 654, Loss: 1.4195\n",
      "Batch 655, Loss: 1.3899\n",
      "Batch 656, Loss: 1.4077\n",
      "Batch 657, Loss: 1.4343\n",
      "Batch 658, Loss: 1.4355\n",
      "Batch 659, Loss: 1.4328\n",
      "Batch 660, Loss: 1.3913\n",
      "Batch 661, Loss: 1.4232\n",
      "Batch 662, Loss: 1.4489\n",
      "Batch 663, Loss: 1.4349\n",
      "Batch 664, Loss: 1.4357\n",
      "Batch 665, Loss: 1.4146\n",
      "Batch 666, Loss: 1.4148\n",
      "Batch 667, Loss: 1.4472\n",
      "Batch 668, Loss: 1.4235\n",
      "Batch 669, Loss: 1.3903\n",
      "Batch 670, Loss: 1.4284\n",
      "Batch 671, Loss: 1.4166\n",
      "Batch 672, Loss: 1.4268\n",
      "Batch 673, Loss: 1.4144\n",
      "Batch 674, Loss: 1.4248\n",
      "Batch 675, Loss: 1.3974\n",
      "Batch 676, Loss: 1.4087\n",
      "Batch 677, Loss: 1.4170\n",
      "Batch 678, Loss: 1.4432\n",
      "Batch 679, Loss: 1.4162\n",
      "Batch 680, Loss: 1.4100\n",
      "Batch 681, Loss: 1.4269\n",
      "Batch 682, Loss: 1.4447\n",
      "Batch 683, Loss: 1.4028\n",
      "Batch 684, Loss: 1.4147\n",
      "Batch 685, Loss: 1.4059\n",
      "Batch 686, Loss: 1.4370\n",
      "Batch 687, Loss: 1.4195\n",
      "Batch 688, Loss: 1.4035\n",
      "Batch 689, Loss: 1.4189\n",
      "Batch 690, Loss: 1.4263\n",
      "Batch 691, Loss: 1.4173\n",
      "Batch 692, Loss: 1.4230\n",
      "Batch 693, Loss: 1.4121\n",
      "Batch 694, Loss: 1.4319\n",
      "Batch 695, Loss: 1.4259\n",
      "Batch 696, Loss: 1.4144\n",
      "Batch 697, Loss: 1.4050\n",
      "Batch 698, Loss: 1.3722\n",
      "Batch 699, Loss: 1.4171\n",
      "Batch 700, Loss: 1.4216\n",
      "Batch 701, Loss: 1.4108\n",
      "Batch 702, Loss: 1.4028\n",
      "Batch 703, Loss: 1.4194\n",
      "Batch 704, Loss: 1.4027\n",
      "Batch 705, Loss: 1.4215\n",
      "Batch 706, Loss: 1.4567\n",
      "Batch 707, Loss: 1.4299\n",
      "Batch 708, Loss: 1.4187\n",
      "Batch 709, Loss: 1.4586\n",
      "Batch 710, Loss: 1.4403\n",
      "Batch 711, Loss: 1.4326\n",
      "Batch 712, Loss: 1.4444\n",
      "Batch 713, Loss: 1.4122\n",
      "Batch 714, Loss: 1.4219\n",
      "Batch 715, Loss: 1.4488\n",
      "Batch 716, Loss: 1.4335\n",
      "Batch 717, Loss: 1.4331\n",
      "Batch 718, Loss: 1.4205\n",
      "Batch 719, Loss: 1.4290\n",
      "Batch 720, Loss: 1.4015\n",
      "Batch 721, Loss: 1.3887\n",
      "Batch 722, Loss: 1.4167\n",
      "Batch 723, Loss: 1.4408\n",
      "Batch 724, Loss: 1.4186\n",
      "Batch 725, Loss: 1.4210\n",
      "Batch 726, Loss: 1.4216\n",
      "Batch 727, Loss: 1.4071\n",
      "Batch 728, Loss: 1.4438\n",
      "Batch 729, Loss: 1.4278\n",
      "Batch 730, Loss: 1.4061\n",
      "Batch 731, Loss: 1.3935\n",
      "Batch 732, Loss: 1.4075\n",
      "Batch 733, Loss: 1.4114\n",
      "Batch 734, Loss: 1.4384\n",
      "Batch 735, Loss: 1.3774\n",
      "Batch 736, Loss: 1.4017\n",
      "Batch 737, Loss: 1.4211\n",
      "Batch 738, Loss: 1.4419\n",
      "Batch 739, Loss: 1.3986\n",
      "Batch 740, Loss: 1.4232\n",
      "Batch 741, Loss: 1.4208\n",
      "Batch 742, Loss: 1.4062\n",
      "Batch 743, Loss: 1.4114\n",
      "Batch 744, Loss: 1.4362\n",
      "Batch 745, Loss: 1.4265\n",
      "Batch 746, Loss: 1.4264\n",
      "Batch 747, Loss: 1.4162\n",
      "Batch 748, Loss: 1.3857\n",
      "Batch 749, Loss: 1.4008\n",
      "Batch 750, Loss: 1.4207\n",
      "Batch 751, Loss: 1.4230\n",
      "Batch 752, Loss: 1.4245\n",
      "Batch 753, Loss: 1.3995\n",
      "Batch 754, Loss: 1.4227\n",
      "Batch 755, Loss: 1.4336\n",
      "Batch 756, Loss: 1.3877\n",
      "Batch 757, Loss: 1.3997\n",
      "Batch 758, Loss: 1.4314\n",
      "Batch 759, Loss: 1.3949\n",
      "Batch 760, Loss: 1.4281\n",
      "Batch 761, Loss: 1.4277\n",
      "Batch 762, Loss: 1.4319\n",
      "Batch 763, Loss: 1.4514\n",
      "Batch 764, Loss: 1.3781\n",
      "Batch 765, Loss: 1.4029\n",
      "Batch 766, Loss: 1.3999\n",
      "Batch 767, Loss: 1.4231\n",
      "Batch 768, Loss: 1.4166\n",
      "Batch 769, Loss: 1.4073\n",
      "Batch 770, Loss: 1.4314\n",
      "Batch 771, Loss: 1.3993\n",
      "Batch 772, Loss: 1.4280\n",
      "Batch 773, Loss: 1.4008\n",
      "Batch 774, Loss: 1.4101\n",
      "Batch 775, Loss: 1.4530\n",
      "Batch 776, Loss: 1.4199\n",
      "Batch 777, Loss: 1.4440\n",
      "Batch 778, Loss: 1.4331\n",
      "Batch 779, Loss: 1.4163\n",
      "Batch 780, Loss: 1.4430\n",
      "Batch 781, Loss: 1.4067\n",
      "Batch 782, Loss: 1.4382\n",
      "Batch 783, Loss: 1.4182\n",
      "Batch 784, Loss: 1.3961\n",
      "Batch 785, Loss: 1.4122\n",
      "Batch 786, Loss: 1.4309\n",
      "Batch 787, Loss: 1.4055\n",
      "Batch 788, Loss: 1.3998\n",
      "Batch 789, Loss: 1.4286\n",
      "Batch 790, Loss: 1.3988\n",
      "Batch 791, Loss: 1.4305\n",
      "Batch 792, Loss: 1.4308\n",
      "Batch 793, Loss: 1.4155\n",
      "Batch 794, Loss: 1.4208\n",
      "Batch 795, Loss: 1.4265\n",
      "Batch 796, Loss: 1.4051\n",
      "Batch 797, Loss: 1.4029\n",
      "Batch 798, Loss: 1.4109\n",
      "Batch 799, Loss: 1.4298\n",
      "Batch 800, Loss: 1.4280\n",
      "Batch 801, Loss: 1.4335\n",
      "Batch 802, Loss: 1.4420\n",
      "Batch 803, Loss: 1.4030\n",
      "Batch 804, Loss: 1.4132\n",
      "Batch 805, Loss: 1.4297\n",
      "Batch 806, Loss: 1.4222\n",
      "Batch 807, Loss: 1.4268\n",
      "Batch 808, Loss: 1.4315\n",
      "Batch 809, Loss: 1.4200\n",
      "Batch 810, Loss: 1.4441\n",
      "Batch 811, Loss: 1.4190\n",
      "Batch 812, Loss: 1.4139\n",
      "Batch 813, Loss: 1.4217\n",
      "Batch 814, Loss: 1.3726\n",
      "Batch 815, Loss: 1.4111\n",
      "Batch 816, Loss: 1.3922\n",
      "Batch 817, Loss: 1.4211\n",
      "Batch 818, Loss: 1.4235\n",
      "Batch 819, Loss: 1.4101\n",
      "Batch 820, Loss: 1.4267\n",
      "Batch 821, Loss: 1.4014\n",
      "Batch 822, Loss: 1.4268\n",
      "Batch 823, Loss: 1.4335\n",
      "Batch 824, Loss: 1.4126\n",
      "Batch 825, Loss: 1.4286\n",
      "Batch 826, Loss: 1.4224\n",
      "Batch 827, Loss: 1.4099\n",
      "Batch 828, Loss: 1.4196\n",
      "Batch 829, Loss: 1.4039\n",
      "Batch 830, Loss: 1.4253\n",
      "Batch 831, Loss: 1.4042\n",
      "Batch 832, Loss: 1.4183\n",
      "Batch 833, Loss: 1.4096\n",
      "Batch 834, Loss: 1.3853\n",
      "Batch 835, Loss: 1.4086\n",
      "Batch 836, Loss: 1.4230\n",
      "Batch 837, Loss: 1.4337\n",
      "Batch 838, Loss: 1.4243\n",
      "Batch 839, Loss: 1.4177\n",
      "Batch 840, Loss: 1.4373\n",
      "Batch 841, Loss: 1.4149\n",
      "Batch 842, Loss: 1.4155\n",
      "Batch 843, Loss: 1.4270\n",
      "Batch 844, Loss: 1.4351\n",
      "Batch 845, Loss: 1.4180\n",
      "Batch 846, Loss: 1.4313\n",
      "Batch 847, Loss: 1.4016\n",
      "Batch 848, Loss: 1.4188\n",
      "Batch 849, Loss: 1.4189\n",
      "Batch 850, Loss: 1.4072\n",
      "Batch 851, Loss: 1.4198\n",
      "Batch 852, Loss: 1.3983\n",
      "Batch 853, Loss: 1.4237\n",
      "Batch 854, Loss: 1.4200\n",
      "Batch 855, Loss: 1.3918\n",
      "Batch 856, Loss: 1.4215\n",
      "Batch 857, Loss: 1.4256\n",
      "Batch 858, Loss: 1.4148\n",
      "Batch 859, Loss: 1.4218\n",
      "Batch 860, Loss: 1.4157\n",
      "Batch 861, Loss: 1.4044\n",
      "Batch 862, Loss: 1.4365\n",
      "Batch 863, Loss: 1.3893\n",
      "Batch 864, Loss: 1.3981\n",
      "Batch 865, Loss: 1.4067\n",
      "Batch 866, Loss: 1.4312\n",
      "Batch 867, Loss: 1.4344\n",
      "Batch 868, Loss: 1.4212\n",
      "Batch 869, Loss: 1.4028\n",
      "Batch 870, Loss: 1.4525\n",
      "Batch 871, Loss: 1.4344\n",
      "Batch 872, Loss: 1.3944\n",
      "Batch 873, Loss: 1.4185\n",
      "Batch 874, Loss: 1.4087\n",
      "Batch 875, Loss: 1.4251\n",
      "Batch 876, Loss: 1.4398\n",
      "Batch 877, Loss: 1.4016\n",
      "Batch 878, Loss: 1.4095\n",
      "Batch 879, Loss: 1.4309\n",
      "Batch 880, Loss: 1.3885\n",
      "Batch 881, Loss: 1.4125\n",
      "Batch 882, Loss: 1.4034\n",
      "Batch 883, Loss: 1.4485\n",
      "Batch 884, Loss: 1.4338\n",
      "Batch 885, Loss: 1.3943\n",
      "Batch 886, Loss: 1.4328\n",
      "Batch 887, Loss: 1.4446\n",
      "Batch 888, Loss: 1.4249\n",
      "Batch 889, Loss: 1.4127\n",
      "Batch 890, Loss: 1.4428\n",
      "Batch 891, Loss: 1.4104\n",
      "Batch 892, Loss: 1.4032\n",
      "Batch 893, Loss: 1.4401\n",
      "Batch 894, Loss: 1.4370\n",
      "Batch 895, Loss: 1.4208\n",
      "Batch 896, Loss: 1.4160\n",
      "Batch 897, Loss: 1.3961\n",
      "Batch 898, Loss: 1.4113\n",
      "Batch 899, Loss: 1.4209\n",
      "Batch 900, Loss: 1.4055\n",
      "Batch 901, Loss: 1.3883\n",
      "Batch 902, Loss: 1.4281\n",
      "Batch 903, Loss: 1.4397\n",
      "Batch 904, Loss: 1.4110\n",
      "Batch 905, Loss: 1.4247\n",
      "Batch 906, Loss: 1.3836\n",
      "Batch 907, Loss: 1.4094\n",
      "Batch 908, Loss: 1.3995\n",
      "Batch 909, Loss: 1.4043\n",
      "Batch 910, Loss: 1.4234\n",
      "Batch 911, Loss: 1.3890\n",
      "Batch 912, Loss: 1.4024\n",
      "Batch 913, Loss: 1.4149\n",
      "Batch 914, Loss: 1.3942\n",
      "Batch 915, Loss: 1.4166\n",
      "Batch 916, Loss: 1.4311\n",
      "Batch 917, Loss: 1.3870\n",
      "Batch 918, Loss: 1.4162\n",
      "Batch 919, Loss: 1.4205\n",
      "Batch 920, Loss: 1.4187\n",
      "Batch 921, Loss: 1.4308\n",
      "Batch 922, Loss: 1.3963\n",
      "Batch 923, Loss: 1.4215\n",
      "Batch 924, Loss: 1.4263\n",
      "Batch 925, Loss: 1.4300\n",
      "Batch 926, Loss: 1.4021\n",
      "Batch 927, Loss: 1.4032\n",
      "Batch 928, Loss: 1.4124\n",
      "Batch 929, Loss: 1.4077\n",
      "Batch 930, Loss: 1.4415\n",
      "Batch 931, Loss: 1.4275\n",
      "Batch 932, Loss: 1.4291\n",
      "Batch 933, Loss: 1.4159\n",
      "Batch 934, Loss: 1.4278\n",
      "Batch 935, Loss: 1.4181\n",
      "Batch 936, Loss: 1.4040\n",
      "Batch 937, Loss: 1.4279\n",
      "Batch 938, Loss: 1.4043\n",
      "Batch 939, Loss: 1.4139\n",
      "Batch 940, Loss: 1.4382\n",
      "Batch 941, Loss: 1.4041\n",
      "Batch 942, Loss: 1.4337\n",
      "Batch 943, Loss: 1.4012\n",
      "Batch 944, Loss: 1.4075\n",
      "Batch 945, Loss: 1.4343\n",
      "Batch 946, Loss: 1.4121\n",
      "Batch 947, Loss: 1.3939\n",
      "Batch 948, Loss: 1.4240\n",
      "Batch 949, Loss: 1.4071\n",
      "Batch 950, Loss: 1.4440\n",
      "Batch 951, Loss: 1.4256\n",
      "Batch 952, Loss: 1.4140\n",
      "Batch 953, Loss: 1.4434\n",
      "Batch 954, Loss: 1.4208\n",
      "Batch 955, Loss: 1.3836\n",
      "Batch 956, Loss: 1.4149\n",
      "Batch 957, Loss: 1.4221\n",
      "Batch 958, Loss: 1.4090\n",
      "Batch 959, Loss: 1.4104\n",
      "Batch 960, Loss: 1.4365\n",
      "Batch 961, Loss: 1.4024\n",
      "Batch 962, Loss: 1.3966\n",
      "Batch 963, Loss: 1.3908\n",
      "Batch 964, Loss: 1.4196\n",
      "Batch 965, Loss: 1.4427\n",
      "Epoch 8, Average Loss: 1.4208\n",
      "Once upon a time, there was a little girl named Lily. She had a subway, it was a pink full of pretty pictures. She liked \n",
      "to water it, but they didn't like it. One day, her mom told her they were walking inside. Lily was very excited and started to \n",
      "quarrel. Lily loved to look around and try to see the moon animals. Then, she saw lots of animals. They were there to see cast \n",
      "in the middle, like some cheers and candy. Lily had never seen animal before. She looked at her subjan and backed for him inside. The \n",
      "moon said to Lily, \"We should both like it. It's the moon!\" Lily was so excited that she thought about it for a moment. Suddenly, \n",
      "they heard a loud noise. Lily started to cry. Her mom came out and saw the quarrel. She said, \"There moon is a fake fake \n",
      "castle!\" Lily laughed and said, \"We watch a moon!\" The quarrel tried to score open the moon from the moon. The fake were scared and \n",
      "snapped its neck. Lily was very happy and hugged her mom. From that day on, she told her mommy's advice every day. \n",
      "\n",
      "--------------------\n",
      "Batch 0, Loss: 1.4000\n",
      "Batch 1, Loss: 1.3829\n",
      "Batch 2, Loss: 1.3871\n",
      "Batch 3, Loss: 1.3933\n",
      "Batch 4, Loss: 1.4023\n",
      "Batch 5, Loss: 1.4016\n",
      "Batch 6, Loss: 1.4433\n",
      "Batch 7, Loss: 1.4193\n",
      "Batch 8, Loss: 1.3897\n",
      "Batch 9, Loss: 1.4310\n",
      "Batch 10, Loss: 1.4158\n",
      "Batch 11, Loss: 1.3934\n",
      "Batch 12, Loss: 1.4368\n",
      "Batch 13, Loss: 1.4251\n",
      "Batch 14, Loss: 1.3862\n",
      "Batch 15, Loss: 1.4134\n",
      "Batch 16, Loss: 1.3938\n",
      "Batch 17, Loss: 1.3881\n",
      "Batch 18, Loss: 1.3867\n",
      "Batch 19, Loss: 1.4186\n",
      "Batch 20, Loss: 1.3987\n",
      "Batch 21, Loss: 1.4077\n",
      "Batch 22, Loss: 1.4361\n",
      "Batch 23, Loss: 1.4169\n",
      "Batch 24, Loss: 1.3896\n",
      "Batch 25, Loss: 1.3917\n",
      "Batch 26, Loss: 1.4456\n",
      "Batch 27, Loss: 1.3866\n",
      "Batch 28, Loss: 1.4131\n",
      "Batch 29, Loss: 1.4235\n",
      "Batch 30, Loss: 1.4218\n",
      "Batch 31, Loss: 1.4107\n",
      "Batch 32, Loss: 1.4112\n",
      "Batch 33, Loss: 1.4037\n",
      "Batch 34, Loss: 1.4040\n",
      "Batch 35, Loss: 1.4110\n",
      "Batch 36, Loss: 1.4221\n",
      "Batch 37, Loss: 1.3775\n",
      "Batch 38, Loss: 1.4030\n",
      "Batch 39, Loss: 1.4211\n",
      "Batch 40, Loss: 1.4229\n",
      "Batch 41, Loss: 1.4013\n",
      "Batch 42, Loss: 1.3812\n",
      "Batch 43, Loss: 1.4194\n",
      "Batch 44, Loss: 1.4325\n",
      "Batch 45, Loss: 1.3818\n",
      "Batch 46, Loss: 1.4042\n",
      "Batch 47, Loss: 1.3872\n",
      "Batch 48, Loss: 1.3997\n",
      "Batch 49, Loss: 1.3775\n",
      "Batch 50, Loss: 1.4080\n",
      "Batch 51, Loss: 1.4040\n",
      "Batch 52, Loss: 1.4050\n",
      "Batch 53, Loss: 1.4153\n",
      "Batch 54, Loss: 1.3919\n",
      "Batch 55, Loss: 1.4049\n",
      "Batch 56, Loss: 1.3762\n",
      "Batch 57, Loss: 1.4211\n",
      "Batch 58, Loss: 1.4033\n",
      "Batch 59, Loss: 1.3992\n",
      "Batch 60, Loss: 1.4023\n",
      "Batch 61, Loss: 1.4179\n",
      "Batch 62, Loss: 1.3995\n",
      "Batch 63, Loss: 1.3820\n",
      "Batch 64, Loss: 1.4214\n",
      "Batch 65, Loss: 1.4152\n",
      "Batch 66, Loss: 1.4048\n",
      "Batch 67, Loss: 1.4260\n",
      "Batch 68, Loss: 1.3901\n",
      "Batch 69, Loss: 1.4242\n",
      "Batch 70, Loss: 1.4414\n",
      "Batch 71, Loss: 1.4122\n",
      "Batch 72, Loss: 1.3780\n",
      "Batch 73, Loss: 1.4312\n",
      "Batch 74, Loss: 1.3846\n",
      "Batch 75, Loss: 1.4089\n",
      "Batch 76, Loss: 1.4182\n",
      "Batch 77, Loss: 1.4324\n",
      "Batch 78, Loss: 1.4071\n",
      "Batch 79, Loss: 1.3955\n",
      "Batch 80, Loss: 1.4146\n",
      "Batch 81, Loss: 1.3793\n",
      "Batch 82, Loss: 1.4169\n",
      "Batch 83, Loss: 1.4235\n",
      "Batch 84, Loss: 1.3866\n",
      "Batch 85, Loss: 1.3930\n",
      "Batch 86, Loss: 1.3935\n",
      "Batch 87, Loss: 1.4094\n",
      "Batch 88, Loss: 1.4391\n",
      "Batch 89, Loss: 1.3934\n",
      "Batch 90, Loss: 1.4458\n",
      "Batch 91, Loss: 1.3978\n",
      "Batch 92, Loss: 1.4297\n",
      "Batch 93, Loss: 1.3959\n",
      "Batch 94, Loss: 1.4051\n",
      "Batch 95, Loss: 1.3920\n",
      "Batch 96, Loss: 1.4226\n",
      "Batch 97, Loss: 1.4066\n",
      "Batch 98, Loss: 1.4244\n",
      "Batch 99, Loss: 1.3964\n",
      "Batch 100, Loss: 1.4094\n",
      "Batch 101, Loss: 1.4236\n",
      "Batch 102, Loss: 1.3986\n",
      "Batch 103, Loss: 1.3833\n",
      "Batch 104, Loss: 1.4175\n",
      "Batch 105, Loss: 1.4069\n",
      "Batch 106, Loss: 1.4515\n",
      "Batch 107, Loss: 1.4240\n",
      "Batch 108, Loss: 1.3955\n",
      "Batch 109, Loss: 1.3958\n",
      "Batch 110, Loss: 1.4134\n",
      "Batch 111, Loss: 1.4034\n",
      "Batch 112, Loss: 1.4059\n",
      "Batch 113, Loss: 1.3983\n",
      "Batch 114, Loss: 1.4427\n",
      "Batch 115, Loss: 1.4181\n",
      "Batch 116, Loss: 1.3944\n",
      "Batch 117, Loss: 1.4325\n",
      "Batch 118, Loss: 1.3913\n",
      "Batch 119, Loss: 1.3857\n",
      "Batch 120, Loss: 1.4480\n",
      "Batch 121, Loss: 1.4065\n",
      "Batch 122, Loss: 1.4136\n",
      "Batch 123, Loss: 1.3934\n",
      "Batch 124, Loss: 1.4015\n",
      "Batch 125, Loss: 1.4134\n",
      "Batch 126, Loss: 1.4130\n",
      "Batch 127, Loss: 1.4231\n",
      "Batch 128, Loss: 1.3778\n",
      "Batch 129, Loss: 1.4094\n",
      "Batch 130, Loss: 1.4250\n",
      "Batch 131, Loss: 1.4000\n",
      "Batch 132, Loss: 1.3952\n",
      "Batch 133, Loss: 1.4270\n",
      "Batch 134, Loss: 1.3881\n",
      "Batch 135, Loss: 1.4164\n",
      "Batch 136, Loss: 1.4064\n",
      "Batch 137, Loss: 1.4007\n",
      "Batch 138, Loss: 1.4073\n",
      "Batch 139, Loss: 1.4075\n",
      "Batch 140, Loss: 1.4026\n",
      "Batch 141, Loss: 1.4107\n",
      "Batch 142, Loss: 1.4060\n",
      "Batch 143, Loss: 1.3877\n",
      "Batch 144, Loss: 1.4309\n",
      "Batch 145, Loss: 1.3745\n",
      "Batch 146, Loss: 1.3825\n",
      "Batch 147, Loss: 1.4182\n",
      "Batch 148, Loss: 1.3827\n",
      "Batch 149, Loss: 1.4011\n",
      "Batch 150, Loss: 1.4150\n",
      "Batch 151, Loss: 1.3950\n",
      "Batch 152, Loss: 1.4098\n",
      "Batch 153, Loss: 1.4139\n",
      "Batch 154, Loss: 1.4114\n",
      "Batch 155, Loss: 1.4080\n",
      "Batch 156, Loss: 1.4152\n",
      "Batch 157, Loss: 1.4042\n",
      "Batch 158, Loss: 1.4098\n",
      "Batch 159, Loss: 1.4117\n",
      "Batch 160, Loss: 1.4203\n",
      "Batch 161, Loss: 1.3939\n",
      "Batch 162, Loss: 1.4018\n",
      "Batch 163, Loss: 1.4192\n",
      "Batch 164, Loss: 1.4056\n",
      "Batch 165, Loss: 1.4229\n",
      "Batch 166, Loss: 1.4085\n",
      "Batch 167, Loss: 1.3965\n",
      "Batch 168, Loss: 1.4335\n",
      "Batch 169, Loss: 1.4244\n",
      "Batch 170, Loss: 1.4004\n",
      "Batch 171, Loss: 1.4432\n",
      "Batch 172, Loss: 1.4288\n",
      "Batch 173, Loss: 1.4074\n",
      "Batch 174, Loss: 1.4271\n",
      "Batch 175, Loss: 1.4278\n",
      "Batch 176, Loss: 1.3979\n",
      "Batch 177, Loss: 1.3885\n",
      "Batch 178, Loss: 1.3985\n",
      "Batch 179, Loss: 1.4068\n",
      "Batch 180, Loss: 1.4016\n",
      "Batch 181, Loss: 1.3928\n",
      "Batch 182, Loss: 1.4211\n",
      "Batch 183, Loss: 1.4239\n",
      "Batch 184, Loss: 1.3943\n",
      "Batch 185, Loss: 1.4239\n",
      "Batch 186, Loss: 1.3784\n",
      "Batch 187, Loss: 1.3999\n",
      "Batch 188, Loss: 1.4306\n",
      "Batch 189, Loss: 1.4070\n",
      "Batch 190, Loss: 1.4164\n",
      "Batch 191, Loss: 1.3718\n",
      "Batch 192, Loss: 1.4218\n",
      "Batch 193, Loss: 1.4029\n",
      "Batch 194, Loss: 1.4130\n",
      "Batch 195, Loss: 1.4300\n",
      "Batch 196, Loss: 1.4093\n",
      "Batch 197, Loss: 1.4271\n",
      "Batch 198, Loss: 1.4157\n",
      "Batch 199, Loss: 1.4029\n",
      "Batch 200, Loss: 1.3955\n",
      "Batch 201, Loss: 1.4013\n",
      "Batch 202, Loss: 1.4106\n",
      "Batch 203, Loss: 1.3961\n",
      "Batch 204, Loss: 1.4033\n",
      "Batch 205, Loss: 1.4052\n",
      "Batch 206, Loss: 1.4038\n",
      "Batch 207, Loss: 1.4013\n",
      "Batch 208, Loss: 1.3944\n",
      "Batch 209, Loss: 1.4055\n",
      "Batch 210, Loss: 1.3929\n",
      "Batch 211, Loss: 1.4066\n",
      "Batch 212, Loss: 1.4008\n",
      "Batch 213, Loss: 1.4013\n",
      "Batch 214, Loss: 1.4145\n",
      "Batch 215, Loss: 1.4060\n",
      "Batch 216, Loss: 1.4258\n",
      "Batch 217, Loss: 1.4174\n",
      "Batch 218, Loss: 1.3907\n",
      "Batch 219, Loss: 1.4191\n",
      "Batch 220, Loss: 1.3990\n",
      "Batch 221, Loss: 1.3975\n",
      "Batch 222, Loss: 1.3966\n",
      "Batch 223, Loss: 1.3827\n",
      "Batch 224, Loss: 1.4157\n",
      "Batch 225, Loss: 1.3949\n",
      "Batch 226, Loss: 1.4217\n",
      "Batch 227, Loss: 1.4232\n",
      "Batch 228, Loss: 1.4044\n",
      "Batch 229, Loss: 1.3918\n",
      "Batch 230, Loss: 1.4318\n",
      "Batch 231, Loss: 1.3838\n",
      "Batch 232, Loss: 1.3996\n",
      "Batch 233, Loss: 1.3939\n",
      "Batch 234, Loss: 1.4170\n",
      "Batch 235, Loss: 1.4067\n",
      "Batch 236, Loss: 1.3848\n",
      "Batch 237, Loss: 1.4042\n",
      "Batch 238, Loss: 1.4070\n",
      "Batch 239, Loss: 1.4222\n",
      "Batch 240, Loss: 1.4048\n",
      "Batch 241, Loss: 1.3754\n",
      "Batch 242, Loss: 1.3967\n",
      "Batch 243, Loss: 1.4126\n",
      "Batch 244, Loss: 1.4252\n",
      "Batch 245, Loss: 1.4003\n",
      "Batch 246, Loss: 1.4188\n",
      "Batch 247, Loss: 1.3908\n",
      "Batch 248, Loss: 1.4171\n",
      "Batch 249, Loss: 1.4040\n",
      "Batch 250, Loss: 1.4029\n",
      "Batch 251, Loss: 1.3919\n",
      "Batch 252, Loss: 1.3812\n",
      "Batch 253, Loss: 1.3890\n",
      "Batch 254, Loss: 1.4116\n",
      "Batch 255, Loss: 1.3976\n",
      "Batch 256, Loss: 1.4189\n",
      "Batch 257, Loss: 1.3927\n",
      "Batch 258, Loss: 1.4171\n",
      "Batch 259, Loss: 1.4191\n",
      "Batch 260, Loss: 1.4086\n",
      "Batch 261, Loss: 1.4050\n",
      "Batch 262, Loss: 1.4097\n",
      "Batch 263, Loss: 1.3975\n",
      "Batch 264, Loss: 1.4090\n",
      "Batch 265, Loss: 1.3925\n",
      "Batch 266, Loss: 1.4501\n",
      "Batch 267, Loss: 1.4182\n",
      "Batch 268, Loss: 1.4395\n",
      "Batch 269, Loss: 1.4213\n",
      "Batch 270, Loss: 1.4144\n",
      "Batch 271, Loss: 1.4221\n",
      "Batch 272, Loss: 1.4009\n",
      "Batch 273, Loss: 1.4236\n",
      "Batch 274, Loss: 1.3873\n",
      "Batch 275, Loss: 1.3961\n",
      "Batch 276, Loss: 1.4206\n",
      "Batch 277, Loss: 1.4223\n",
      "Batch 278, Loss: 1.4001\n",
      "Batch 279, Loss: 1.4063\n",
      "Batch 280, Loss: 1.4015\n",
      "Batch 281, Loss: 1.4317\n",
      "Batch 282, Loss: 1.4544\n",
      "Batch 283, Loss: 1.4337\n",
      "Batch 284, Loss: 1.3994\n",
      "Batch 285, Loss: 1.4081\n",
      "Batch 286, Loss: 1.4146\n",
      "Batch 287, Loss: 1.4217\n",
      "Batch 288, Loss: 1.4085\n",
      "Batch 289, Loss: 1.3728\n",
      "Batch 290, Loss: 1.3947\n",
      "Batch 291, Loss: 1.4175\n",
      "Batch 292, Loss: 1.4352\n",
      "Batch 293, Loss: 1.4063\n",
      "Batch 294, Loss: 1.4030\n",
      "Batch 295, Loss: 1.4076\n",
      "Batch 296, Loss: 1.4127\n",
      "Batch 297, Loss: 1.3879\n",
      "Batch 298, Loss: 1.3989\n",
      "Batch 299, Loss: 1.4073\n",
      "Batch 300, Loss: 1.4129\n",
      "Batch 301, Loss: 1.3752\n",
      "Batch 302, Loss: 1.3994\n",
      "Batch 303, Loss: 1.4252\n",
      "Batch 304, Loss: 1.4164\n",
      "Batch 305, Loss: 1.4503\n",
      "Batch 306, Loss: 1.4313\n",
      "Batch 307, Loss: 1.3911\n",
      "Batch 308, Loss: 1.3893\n",
      "Batch 309, Loss: 1.4114\n",
      "Batch 310, Loss: 1.4175\n",
      "Batch 311, Loss: 1.4130\n",
      "Batch 312, Loss: 1.4111\n",
      "Batch 313, Loss: 1.4228\n",
      "Batch 314, Loss: 1.4115\n",
      "Batch 315, Loss: 1.3985\n",
      "Batch 316, Loss: 1.4377\n",
      "Batch 317, Loss: 1.3946\n",
      "Batch 318, Loss: 1.3877\n",
      "Batch 319, Loss: 1.4444\n",
      "Batch 320, Loss: 1.4344\n",
      "Batch 321, Loss: 1.4030\n",
      "Batch 322, Loss: 1.3979\n",
      "Batch 323, Loss: 1.4237\n",
      "Batch 324, Loss: 1.4309\n",
      "Batch 325, Loss: 1.4155\n",
      "Batch 326, Loss: 1.3806\n",
      "Batch 327, Loss: 1.3937\n",
      "Batch 328, Loss: 1.3770\n",
      "Batch 329, Loss: 1.4057\n",
      "Batch 330, Loss: 1.4212\n",
      "Batch 331, Loss: 1.4055\n",
      "Batch 332, Loss: 1.4002\n",
      "Batch 333, Loss: 1.3572\n",
      "Batch 334, Loss: 1.4216\n",
      "Batch 335, Loss: 1.4218\n",
      "Batch 336, Loss: 1.4285\n",
      "Batch 337, Loss: 1.3669\n",
      "Batch 338, Loss: 1.4044\n",
      "Batch 339, Loss: 1.4078\n",
      "Batch 340, Loss: 1.4046\n",
      "Batch 341, Loss: 1.4235\n",
      "Batch 342, Loss: 1.3967\n",
      "Batch 343, Loss: 1.4126\n",
      "Batch 344, Loss: 1.4039\n",
      "Batch 345, Loss: 1.4003\n",
      "Batch 346, Loss: 1.4080\n",
      "Batch 347, Loss: 1.4136\n",
      "Batch 348, Loss: 1.3828\n",
      "Batch 349, Loss: 1.4054\n",
      "Batch 350, Loss: 1.4123\n",
      "Batch 351, Loss: 1.3902\n",
      "Batch 352, Loss: 1.4128\n",
      "Batch 353, Loss: 1.4151\n",
      "Batch 354, Loss: 1.4075\n",
      "Batch 355, Loss: 1.4299\n",
      "Batch 356, Loss: 1.3817\n",
      "Batch 357, Loss: 1.4353\n",
      "Batch 358, Loss: 1.4124\n",
      "Batch 359, Loss: 1.4023\n",
      "Batch 360, Loss: 1.4005\n",
      "Batch 361, Loss: 1.4367\n",
      "Batch 362, Loss: 1.3939\n",
      "Batch 363, Loss: 1.4142\n",
      "Batch 364, Loss: 1.3976\n",
      "Batch 365, Loss: 1.4059\n",
      "Batch 366, Loss: 1.4081\n",
      "Batch 367, Loss: 1.4243\n",
      "Batch 368, Loss: 1.3984\n",
      "Batch 369, Loss: 1.4160\n",
      "Batch 370, Loss: 1.4290\n",
      "Batch 371, Loss: 1.4053\n",
      "Batch 372, Loss: 1.4382\n",
      "Batch 373, Loss: 1.4035\n",
      "Batch 374, Loss: 1.4072\n",
      "Batch 375, Loss: 1.4072\n",
      "Batch 376, Loss: 1.3986\n",
      "Batch 377, Loss: 1.3760\n",
      "Batch 378, Loss: 1.4106\n",
      "Batch 379, Loss: 1.4144\n",
      "Batch 380, Loss: 1.3979\n",
      "Batch 381, Loss: 1.4025\n",
      "Batch 382, Loss: 1.3870\n",
      "Batch 383, Loss: 1.3952\n",
      "Batch 384, Loss: 1.4185\n",
      "Batch 385, Loss: 1.4237\n",
      "Batch 386, Loss: 1.3731\n",
      "Batch 387, Loss: 1.4094\n",
      "Batch 388, Loss: 1.3962\n",
      "Batch 389, Loss: 1.4259\n",
      "Batch 390, Loss: 1.3906\n",
      "Batch 391, Loss: 1.4337\n",
      "Batch 392, Loss: 1.3937\n",
      "Batch 393, Loss: 1.4278\n",
      "Batch 394, Loss: 1.4243\n",
      "Batch 395, Loss: 1.4261\n",
      "Batch 396, Loss: 1.3957\n",
      "Batch 397, Loss: 1.3956\n",
      "Batch 398, Loss: 1.3855\n",
      "Batch 399, Loss: 1.4218\n",
      "Batch 400, Loss: 1.4290\n",
      "Batch 401, Loss: 1.4052\n",
      "Batch 402, Loss: 1.4173\n",
      "Batch 403, Loss: 1.3999\n",
      "Batch 404, Loss: 1.4015\n",
      "Batch 405, Loss: 1.4128\n",
      "Batch 406, Loss: 1.3847\n",
      "Batch 407, Loss: 1.4192\n",
      "Batch 408, Loss: 1.4141\n",
      "Batch 409, Loss: 1.4144\n",
      "Batch 410, Loss: 1.3951\n",
      "Batch 411, Loss: 1.4060\n",
      "Batch 412, Loss: 1.3820\n",
      "Batch 413, Loss: 1.4236\n",
      "Batch 414, Loss: 1.4244\n",
      "Batch 415, Loss: 1.4202\n",
      "Batch 416, Loss: 1.4503\n",
      "Batch 417, Loss: 1.3963\n",
      "Batch 418, Loss: 1.3922\n",
      "Batch 419, Loss: 1.4330\n",
      "Batch 420, Loss: 1.4362\n",
      "Batch 421, Loss: 1.4246\n",
      "Batch 422, Loss: 1.4207\n",
      "Batch 423, Loss: 1.4174\n",
      "Batch 424, Loss: 1.4172\n",
      "Batch 425, Loss: 1.3947\n",
      "Batch 426, Loss: 1.4062\n",
      "Batch 427, Loss: 1.3951\n",
      "Batch 428, Loss: 1.3866\n",
      "Batch 429, Loss: 1.3960\n",
      "Batch 430, Loss: 1.4048\n",
      "Batch 431, Loss: 1.4188\n",
      "Batch 432, Loss: 1.4262\n",
      "Batch 433, Loss: 1.4233\n",
      "Batch 434, Loss: 1.3979\n",
      "Batch 435, Loss: 1.4200\n",
      "Batch 436, Loss: 1.4137\n",
      "Batch 437, Loss: 1.3895\n",
      "Batch 438, Loss: 1.4046\n",
      "Batch 439, Loss: 1.4215\n",
      "Batch 440, Loss: 1.3889\n",
      "Batch 441, Loss: 1.4230\n",
      "Batch 442, Loss: 1.4248\n",
      "Batch 443, Loss: 1.3897\n",
      "Batch 444, Loss: 1.3899\n",
      "Batch 445, Loss: 1.4159\n",
      "Batch 446, Loss: 1.4139\n",
      "Batch 447, Loss: 1.4117\n",
      "Batch 448, Loss: 1.4173\n",
      "Batch 449, Loss: 1.4063\n",
      "Batch 450, Loss: 1.4198\n",
      "Batch 451, Loss: 1.3948\n",
      "Batch 452, Loss: 1.4297\n",
      "Batch 453, Loss: 1.4131\n",
      "Batch 454, Loss: 1.3789\n",
      "Batch 455, Loss: 1.4175\n",
      "Batch 456, Loss: 1.4195\n",
      "Batch 457, Loss: 1.4098\n",
      "Batch 458, Loss: 1.4067\n",
      "Batch 459, Loss: 1.4165\n",
      "Batch 460, Loss: 1.4038\n",
      "Batch 461, Loss: 1.4183\n",
      "Batch 462, Loss: 1.4036\n",
      "Batch 463, Loss: 1.4445\n",
      "Batch 464, Loss: 1.4101\n",
      "Batch 465, Loss: 1.4173\n",
      "Batch 466, Loss: 1.4105\n",
      "Batch 467, Loss: 1.4038\n",
      "Batch 468, Loss: 1.3973\n",
      "Batch 469, Loss: 1.4151\n",
      "Batch 470, Loss: 1.3945\n",
      "Batch 471, Loss: 1.4166\n",
      "Batch 472, Loss: 1.4191\n",
      "Batch 473, Loss: 1.4170\n",
      "Batch 474, Loss: 1.4105\n",
      "Batch 475, Loss: 1.4141\n",
      "Batch 476, Loss: 1.3937\n",
      "Batch 477, Loss: 1.4216\n",
      "Batch 478, Loss: 1.4138\n",
      "Batch 479, Loss: 1.4418\n",
      "Batch 480, Loss: 1.4075\n",
      "Batch 481, Loss: 1.4018\n",
      "Batch 482, Loss: 1.3882\n",
      "Batch 483, Loss: 1.4054\n",
      "Once upon a time, in a hungry, there was a little boy named Timmy. Timmy had a big blanket that he loved to fill with \n",
      "pictures. One day, Timmy went for a walk in the park. He saw a drain near stream and wanted to fill it. Suddenly, a little \n",
      "boy named John appeared. John was left behind and rang Timmy's look inside without the drainner. Timmy thought the drain was fix and thought the \n",
      "drain ever looked for his needday. So, he went back out and found his grandk to take it with him. The drain had a big \n",
      "quiet house and the drain went off to play. They threw head it and filled the house. John was not happy when Timmy saw the \n",
      "drain shouted to him. But when the drain came out of the house, they started to fill the huge house. Timmy knew he had to \n",
      "tooar up the drain, so he made even more fun to the park. From that day on, whenever John went, he would see the drain \n",
      "see every year. Timmy was happy he filled with more drainner to fill with it. He thanked his mom for making him fill his amazing \n",
      "lush. Timmy listened to his home and made funny faces. And soon as they filled the stream, the drainner was gone. And they lived happily \n",
      "ever after. \n",
      "\n",
      "--------------------\n",
      "Batch 484, Loss: 1.4069\n",
      "Batch 485, Loss: 1.4282\n",
      "Batch 486, Loss: 1.4213\n",
      "Batch 487, Loss: 1.3997\n",
      "Batch 488, Loss: 1.4063\n",
      "Batch 489, Loss: 1.4135\n",
      "Batch 490, Loss: 1.4115\n",
      "Batch 491, Loss: 1.4002\n",
      "Batch 492, Loss: 1.4198\n",
      "Batch 493, Loss: 1.4041\n",
      "Batch 494, Loss: 1.3990\n",
      "Batch 495, Loss: 1.4012\n",
      "Batch 496, Loss: 1.4115\n",
      "Batch 497, Loss: 1.3792\n",
      "Batch 498, Loss: 1.4247\n",
      "Batch 499, Loss: 1.3986\n",
      "Batch 500, Loss: 1.4161\n",
      "Batch 501, Loss: 1.3975\n",
      "Batch 502, Loss: 1.4004\n",
      "Batch 503, Loss: 1.4048\n",
      "Batch 504, Loss: 1.4098\n",
      "Batch 505, Loss: 1.4060\n",
      "Batch 506, Loss: 1.3941\n",
      "Batch 507, Loss: 1.4129\n",
      "Batch 508, Loss: 1.4438\n",
      "Batch 509, Loss: 1.3804\n",
      "Batch 510, Loss: 1.3784\n",
      "Batch 511, Loss: 1.4062\n",
      "Batch 512, Loss: 1.4358\n",
      "Batch 513, Loss: 1.4158\n",
      "Batch 514, Loss: 1.4103\n",
      "Batch 515, Loss: 1.4213\n",
      "Batch 516, Loss: 1.3719\n",
      "Batch 517, Loss: 1.3888\n",
      "Batch 518, Loss: 1.4079\n",
      "Batch 519, Loss: 1.4029\n",
      "Batch 520, Loss: 1.4197\n",
      "Batch 521, Loss: 1.3969\n",
      "Batch 522, Loss: 1.4042\n",
      "Batch 523, Loss: 1.4192\n",
      "Batch 524, Loss: 1.4248\n",
      "Batch 525, Loss: 1.4363\n",
      "Batch 526, Loss: 1.3878\n",
      "Batch 527, Loss: 1.4322\n",
      "Batch 528, Loss: 1.3959\n",
      "Batch 529, Loss: 1.3695\n",
      "Batch 530, Loss: 1.4425\n",
      "Batch 531, Loss: 1.3853\n",
      "Batch 532, Loss: 1.4181\n",
      "Batch 533, Loss: 1.3958\n",
      "Batch 534, Loss: 1.3995\n",
      "Batch 535, Loss: 1.3909\n",
      "Batch 536, Loss: 1.4145\n",
      "Batch 537, Loss: 1.4211\n",
      "Batch 538, Loss: 1.3898\n",
      "Batch 539, Loss: 1.4103\n",
      "Batch 540, Loss: 1.4136\n",
      "Batch 541, Loss: 1.4114\n",
      "Batch 542, Loss: 1.4099\n",
      "Batch 543, Loss: 1.3897\n",
      "Batch 544, Loss: 1.4141\n",
      "Batch 545, Loss: 1.4333\n",
      "Batch 546, Loss: 1.4081\n",
      "Batch 547, Loss: 1.3907\n",
      "Batch 548, Loss: 1.3891\n",
      "Batch 549, Loss: 1.4057\n",
      "Batch 550, Loss: 1.3997\n",
      "Batch 551, Loss: 1.4186\n",
      "Batch 552, Loss: 1.3874\n",
      "Batch 553, Loss: 1.4050\n",
      "Batch 554, Loss: 1.4282\n",
      "Batch 555, Loss: 1.3979\n",
      "Batch 556, Loss: 1.4116\n",
      "Batch 557, Loss: 1.3990\n",
      "Batch 558, Loss: 1.3908\n",
      "Batch 559, Loss: 1.4146\n",
      "Batch 560, Loss: 1.3931\n",
      "Batch 561, Loss: 1.3827\n",
      "Batch 562, Loss: 1.4206\n",
      "Batch 563, Loss: 1.4202\n",
      "Batch 564, Loss: 1.4126\n",
      "Batch 565, Loss: 1.3869\n",
      "Batch 566, Loss: 1.4228\n",
      "Batch 567, Loss: 1.3803\n",
      "Batch 568, Loss: 1.3798\n",
      "Batch 569, Loss: 1.4079\n",
      "Batch 570, Loss: 1.4041\n",
      "Batch 571, Loss: 1.4412\n",
      "Batch 572, Loss: 1.3866\n",
      "Batch 573, Loss: 1.3909\n",
      "Batch 574, Loss: 1.4294\n",
      "Batch 575, Loss: 1.4157\n",
      "Batch 576, Loss: 1.4220\n",
      "Batch 577, Loss: 1.4086\n",
      "Batch 578, Loss: 1.4355\n",
      "Batch 579, Loss: 1.3812\n",
      "Batch 580, Loss: 1.3929\n",
      "Batch 581, Loss: 1.3911\n",
      "Batch 582, Loss: 1.3713\n",
      "Batch 583, Loss: 1.4082\n",
      "Batch 584, Loss: 1.4213\n",
      "Batch 585, Loss: 1.3906\n",
      "Batch 586, Loss: 1.4094\n",
      "Batch 587, Loss: 1.4298\n",
      "Batch 588, Loss: 1.4201\n",
      "Batch 589, Loss: 1.3980\n",
      "Batch 590, Loss: 1.4227\n",
      "Batch 591, Loss: 1.4278\n",
      "Batch 592, Loss: 1.4049\n",
      "Batch 593, Loss: 1.3984\n",
      "Batch 594, Loss: 1.4171\n",
      "Batch 595, Loss: 1.4046\n",
      "Batch 596, Loss: 1.3943\n",
      "Batch 597, Loss: 1.4185\n",
      "Batch 598, Loss: 1.4195\n",
      "Batch 599, Loss: 1.4279\n",
      "Batch 600, Loss: 1.4175\n",
      "Batch 601, Loss: 1.4086\n",
      "Batch 602, Loss: 1.4200\n",
      "Batch 603, Loss: 1.4116\n",
      "Batch 604, Loss: 1.4111\n",
      "Batch 605, Loss: 1.4288\n",
      "Batch 606, Loss: 1.4082\n",
      "Batch 607, Loss: 1.4081\n",
      "Batch 608, Loss: 1.4419\n",
      "Batch 609, Loss: 1.4022\n",
      "Batch 610, Loss: 1.3985\n",
      "Batch 611, Loss: 1.4234\n",
      "Batch 612, Loss: 1.4401\n",
      "Batch 613, Loss: 1.4073\n",
      "Batch 614, Loss: 1.3982\n",
      "Batch 615, Loss: 1.3977\n",
      "Batch 616, Loss: 1.3760\n",
      "Batch 617, Loss: 1.3814\n",
      "Batch 618, Loss: 1.4121\n",
      "Batch 619, Loss: 1.4050\n",
      "Batch 620, Loss: 1.3754\n",
      "Batch 621, Loss: 1.3999\n",
      "Batch 622, Loss: 1.4124\n",
      "Batch 623, Loss: 1.4388\n",
      "Batch 624, Loss: 1.4057\n",
      "Batch 625, Loss: 1.4251\n",
      "Batch 626, Loss: 1.3968\n",
      "Batch 627, Loss: 1.4065\n",
      "Batch 628, Loss: 1.3899\n",
      "Batch 629, Loss: 1.4039\n",
      "Batch 630, Loss: 1.3869\n",
      "Batch 631, Loss: 1.4150\n",
      "Batch 632, Loss: 1.3709\n",
      "Batch 633, Loss: 1.3880\n",
      "Batch 634, Loss: 1.4133\n",
      "Batch 635, Loss: 1.4350\n",
      "Batch 636, Loss: 1.3892\n",
      "Batch 637, Loss: 1.4169\n",
      "Batch 638, Loss: 1.4162\n",
      "Batch 639, Loss: 1.4183\n",
      "Batch 640, Loss: 1.4054\n",
      "Batch 641, Loss: 1.4217\n",
      "Batch 642, Loss: 1.3989\n",
      "Batch 643, Loss: 1.4024\n",
      "Batch 644, Loss: 1.3778\n",
      "Batch 645, Loss: 1.3973\n",
      "Batch 646, Loss: 1.4419\n",
      "Batch 647, Loss: 1.3989\n",
      "Batch 648, Loss: 1.4293\n",
      "Batch 649, Loss: 1.3969\n",
      "Batch 650, Loss: 1.4085\n",
      "Batch 651, Loss: 1.4082\n",
      "Batch 652, Loss: 1.4291\n",
      "Batch 653, Loss: 1.4005\n",
      "Batch 654, Loss: 1.3580\n",
      "Batch 655, Loss: 1.4065\n",
      "Batch 656, Loss: 1.4086\n",
      "Batch 657, Loss: 1.3984\n",
      "Batch 658, Loss: 1.4041\n",
      "Batch 659, Loss: 1.4092\n",
      "Batch 660, Loss: 1.4053\n",
      "Batch 661, Loss: 1.4126\n",
      "Batch 662, Loss: 1.4408\n",
      "Batch 663, Loss: 1.4277\n",
      "Batch 664, Loss: 1.3979\n",
      "Batch 665, Loss: 1.3774\n",
      "Batch 666, Loss: 1.4063\n",
      "Batch 667, Loss: 1.4196\n",
      "Batch 668, Loss: 1.4060\n",
      "Batch 669, Loss: 1.3891\n",
      "Batch 670, Loss: 1.3963\n",
      "Batch 671, Loss: 1.4101\n",
      "Batch 672, Loss: 1.3821\n",
      "Batch 673, Loss: 1.4248\n",
      "Batch 674, Loss: 1.3958\n",
      "Batch 675, Loss: 1.3796\n",
      "Batch 676, Loss: 1.4134\n",
      "Batch 677, Loss: 1.3926\n",
      "Batch 678, Loss: 1.4015\n",
      "Batch 679, Loss: 1.4022\n",
      "Batch 680, Loss: 1.4206\n",
      "Batch 681, Loss: 1.4131\n",
      "Batch 682, Loss: 1.4053\n",
      "Batch 683, Loss: 1.3849\n",
      "Batch 684, Loss: 1.4529\n",
      "Batch 685, Loss: 1.4206\n",
      "Batch 686, Loss: 1.3994\n",
      "Batch 687, Loss: 1.4119\n",
      "Batch 688, Loss: 1.4363\n",
      "Batch 689, Loss: 1.4121\n",
      "Batch 690, Loss: 1.4161\n",
      "Batch 691, Loss: 1.4124\n",
      "Batch 692, Loss: 1.4032\n",
      "Batch 693, Loss: 1.4338\n",
      "Batch 694, Loss: 1.4185\n",
      "Batch 695, Loss: 1.3932\n",
      "Batch 696, Loss: 1.3961\n",
      "Batch 697, Loss: 1.4181\n",
      "Batch 698, Loss: 1.4220\n",
      "Batch 699, Loss: 1.4014\n",
      "Batch 700, Loss: 1.4053\n",
      "Batch 701, Loss: 1.3919\n",
      "Batch 702, Loss: 1.4086\n",
      "Batch 703, Loss: 1.3984\n",
      "Batch 704, Loss: 1.3922\n",
      "Batch 705, Loss: 1.3840\n",
      "Batch 706, Loss: 1.4044\n",
      "Batch 707, Loss: 1.4078\n",
      "Batch 708, Loss: 1.4095\n",
      "Batch 709, Loss: 1.3937\n",
      "Batch 710, Loss: 1.4081\n",
      "Batch 711, Loss: 1.4087\n",
      "Batch 712, Loss: 1.3882\n",
      "Batch 713, Loss: 1.4068\n",
      "Batch 714, Loss: 1.4069\n",
      "Batch 715, Loss: 1.4027\n",
      "Batch 716, Loss: 1.4054\n",
      "Batch 717, Loss: 1.4180\n",
      "Batch 718, Loss: 1.4227\n",
      "Batch 719, Loss: 1.3971\n",
      "Batch 720, Loss: 1.4197\n",
      "Batch 721, Loss: 1.4325\n",
      "Batch 722, Loss: 1.4068\n",
      "Batch 723, Loss: 1.3977\n",
      "Batch 724, Loss: 1.3889\n",
      "Batch 725, Loss: 1.4057\n",
      "Batch 726, Loss: 1.3929\n",
      "Batch 727, Loss: 1.3929\n",
      "Batch 728, Loss: 1.3985\n",
      "Batch 729, Loss: 1.3978\n",
      "Batch 730, Loss: 1.4137\n",
      "Batch 731, Loss: 1.3916\n",
      "Batch 732, Loss: 1.3818\n",
      "Batch 733, Loss: 1.3804\n",
      "Batch 734, Loss: 1.4301\n",
      "Batch 735, Loss: 1.3828\n",
      "Batch 736, Loss: 1.3842\n",
      "Batch 737, Loss: 1.4003\n",
      "Batch 738, Loss: 1.3949\n",
      "Batch 739, Loss: 1.3916\n",
      "Batch 740, Loss: 1.4231\n",
      "Batch 741, Loss: 1.3898\n",
      "Batch 742, Loss: 1.3999\n",
      "Batch 743, Loss: 1.3975\n",
      "Batch 744, Loss: 1.4004\n",
      "Batch 745, Loss: 1.4013\n",
      "Batch 746, Loss: 1.4142\n",
      "Batch 747, Loss: 1.4069\n",
      "Batch 748, Loss: 1.4051\n",
      "Batch 749, Loss: 1.4183\n",
      "Batch 750, Loss: 1.4139\n",
      "Batch 751, Loss: 1.3897\n",
      "Batch 752, Loss: 1.4139\n",
      "Batch 753, Loss: 1.3884\n",
      "Batch 754, Loss: 1.3863\n",
      "Batch 755, Loss: 1.4016\n",
      "Batch 756, Loss: 1.4106\n",
      "Batch 757, Loss: 1.3897\n",
      "Batch 758, Loss: 1.4201\n",
      "Batch 759, Loss: 1.3963\n",
      "Batch 760, Loss: 1.4169\n",
      "Batch 761, Loss: 1.4212\n",
      "Batch 762, Loss: 1.4013\n",
      "Batch 763, Loss: 1.4128\n",
      "Batch 764, Loss: 1.4250\n",
      "Batch 765, Loss: 1.4349\n",
      "Batch 766, Loss: 1.3830\n",
      "Batch 767, Loss: 1.3919\n",
      "Batch 768, Loss: 1.3777\n",
      "Batch 769, Loss: 1.3854\n",
      "Batch 770, Loss: 1.3913\n",
      "Batch 771, Loss: 1.3956\n",
      "Batch 772, Loss: 1.3841\n",
      "Batch 773, Loss: 1.4263\n",
      "Batch 774, Loss: 1.4115\n",
      "Batch 775, Loss: 1.4112\n",
      "Batch 776, Loss: 1.4125\n",
      "Batch 777, Loss: 1.4004\n",
      "Batch 778, Loss: 1.3973\n",
      "Batch 779, Loss: 1.4233\n",
      "Batch 780, Loss: 1.4324\n",
      "Batch 781, Loss: 1.4087\n",
      "Batch 782, Loss: 1.4104\n",
      "Batch 783, Loss: 1.4089\n",
      "Batch 784, Loss: 1.4029\n",
      "Batch 785, Loss: 1.4078\n",
      "Batch 786, Loss: 1.4163\n",
      "Batch 787, Loss: 1.4125\n",
      "Batch 788, Loss: 1.4000\n",
      "Batch 789, Loss: 1.4083\n",
      "Batch 790, Loss: 1.4343\n",
      "Batch 791, Loss: 1.3914\n",
      "Batch 792, Loss: 1.4254\n",
      "Batch 793, Loss: 1.4259\n",
      "Batch 794, Loss: 1.4066\n",
      "Batch 795, Loss: 1.4243\n",
      "Batch 796, Loss: 1.4060\n",
      "Batch 797, Loss: 1.4288\n",
      "Batch 798, Loss: 1.4370\n",
      "Batch 799, Loss: 1.3914\n",
      "Batch 800, Loss: 1.4305\n",
      "Batch 801, Loss: 1.4090\n",
      "Batch 802, Loss: 1.4133\n",
      "Batch 803, Loss: 1.4106\n",
      "Batch 804, Loss: 1.4170\n",
      "Batch 805, Loss: 1.4058\n",
      "Batch 806, Loss: 1.3825\n",
      "Batch 807, Loss: 1.4057\n",
      "Batch 808, Loss: 1.3996\n",
      "Batch 809, Loss: 1.4065\n",
      "Batch 810, Loss: 1.4089\n",
      "Batch 811, Loss: 1.3744\n",
      "Batch 812, Loss: 1.4258\n",
      "Batch 813, Loss: 1.4315\n",
      "Batch 814, Loss: 1.3886\n",
      "Batch 815, Loss: 1.3882\n",
      "Batch 816, Loss: 1.4067\n",
      "Batch 817, Loss: 1.3838\n",
      "Batch 818, Loss: 1.4291\n",
      "Batch 819, Loss: 1.4061\n",
      "Batch 820, Loss: 1.4026\n",
      "Batch 821, Loss: 1.3967\n",
      "Batch 822, Loss: 1.4108\n",
      "Batch 823, Loss: 1.4290\n",
      "Batch 824, Loss: 1.3817\n",
      "Batch 825, Loss: 1.3949\n",
      "Batch 826, Loss: 1.4025\n",
      "Batch 827, Loss: 1.4064\n",
      "Batch 828, Loss: 1.3981\n",
      "Batch 829, Loss: 1.4142\n",
      "Batch 830, Loss: 1.4020\n",
      "Batch 831, Loss: 1.3863\n",
      "Batch 832, Loss: 1.3948\n",
      "Batch 833, Loss: 1.4115\n",
      "Batch 834, Loss: 1.4154\n",
      "Batch 835, Loss: 1.3829\n",
      "Batch 836, Loss: 1.3959\n",
      "Batch 837, Loss: 1.3833\n",
      "Batch 838, Loss: 1.3686\n",
      "Batch 839, Loss: 1.4038\n",
      "Batch 840, Loss: 1.4097\n",
      "Batch 841, Loss: 1.3985\n",
      "Batch 842, Loss: 1.3950\n",
      "Batch 843, Loss: 1.4273\n",
      "Batch 844, Loss: 1.3870\n",
      "Batch 845, Loss: 1.3999\n",
      "Batch 846, Loss: 1.3996\n",
      "Batch 847, Loss: 1.4070\n",
      "Batch 848, Loss: 1.3868\n",
      "Batch 849, Loss: 1.4170\n",
      "Batch 850, Loss: 1.3994\n",
      "Batch 851, Loss: 1.4070\n",
      "Batch 852, Loss: 1.3831\n",
      "Batch 853, Loss: 1.3883\n",
      "Batch 854, Loss: 1.4175\n",
      "Batch 855, Loss: 1.4041\n",
      "Batch 856, Loss: 1.4167\n",
      "Batch 857, Loss: 1.4183\n",
      "Batch 858, Loss: 1.4132\n",
      "Batch 859, Loss: 1.3792\n",
      "Batch 860, Loss: 1.3990\n",
      "Batch 861, Loss: 1.4339\n",
      "Batch 862, Loss: 1.3969\n",
      "Batch 863, Loss: 1.4174\n",
      "Batch 864, Loss: 1.3914\n",
      "Batch 865, Loss: 1.4155\n",
      "Batch 866, Loss: 1.3685\n",
      "Batch 867, Loss: 1.3874\n",
      "Batch 868, Loss: 1.3680\n",
      "Batch 869, Loss: 1.4026\n",
      "Batch 870, Loss: 1.4042\n",
      "Batch 871, Loss: 1.4115\n",
      "Batch 872, Loss: 1.4038\n",
      "Batch 873, Loss: 1.4341\n",
      "Batch 874, Loss: 1.4003\n",
      "Batch 875, Loss: 1.4063\n",
      "Batch 876, Loss: 1.4206\n",
      "Batch 877, Loss: 1.3828\n",
      "Batch 878, Loss: 1.3949\n",
      "Batch 879, Loss: 1.4252\n",
      "Batch 880, Loss: 1.3892\n",
      "Batch 881, Loss: 1.4283\n",
      "Batch 882, Loss: 1.4133\n",
      "Batch 883, Loss: 1.3867\n",
      "Batch 884, Loss: 1.4224\n",
      "Batch 885, Loss: 1.4054\n",
      "Batch 886, Loss: 1.3894\n",
      "Batch 887, Loss: 1.4054\n",
      "Batch 888, Loss: 1.4114\n",
      "Batch 889, Loss: 1.3714\n",
      "Batch 890, Loss: 1.4127\n",
      "Batch 891, Loss: 1.4290\n",
      "Batch 892, Loss: 1.4013\n",
      "Batch 893, Loss: 1.3896\n",
      "Batch 894, Loss: 1.4360\n",
      "Batch 895, Loss: 1.4344\n",
      "Batch 896, Loss: 1.3951\n",
      "Batch 897, Loss: 1.4317\n",
      "Batch 898, Loss: 1.3796\n",
      "Batch 899, Loss: 1.4122\n",
      "Batch 900, Loss: 1.4204\n",
      "Batch 901, Loss: 1.4107\n",
      "Batch 902, Loss: 1.3956\n",
      "Batch 903, Loss: 1.4191\n",
      "Batch 904, Loss: 1.4074\n",
      "Batch 905, Loss: 1.4298\n",
      "Batch 906, Loss: 1.3899\n",
      "Batch 907, Loss: 1.4071\n",
      "Batch 908, Loss: 1.4169\n",
      "Batch 909, Loss: 1.4440\n",
      "Batch 910, Loss: 1.4288\n",
      "Batch 911, Loss: 1.4011\n",
      "Batch 912, Loss: 1.4206\n",
      "Batch 913, Loss: 1.4038\n",
      "Batch 914, Loss: 1.3861\n",
      "Batch 915, Loss: 1.3958\n",
      "Batch 916, Loss: 1.3841\n",
      "Batch 917, Loss: 1.3982\n",
      "Batch 918, Loss: 1.3861\n",
      "Batch 919, Loss: 1.4263\n",
      "Batch 920, Loss: 1.3899\n",
      "Batch 921, Loss: 1.4095\n",
      "Batch 922, Loss: 1.3804\n",
      "Batch 923, Loss: 1.4078\n",
      "Batch 924, Loss: 1.4087\n",
      "Batch 925, Loss: 1.4175\n",
      "Batch 926, Loss: 1.4014\n",
      "Batch 927, Loss: 1.4042\n",
      "Batch 928, Loss: 1.3585\n",
      "Batch 929, Loss: 1.4268\n",
      "Batch 930, Loss: 1.4085\n",
      "Batch 931, Loss: 1.3848\n",
      "Batch 932, Loss: 1.3810\n",
      "Batch 933, Loss: 1.4002\n",
      "Batch 934, Loss: 1.4132\n",
      "Batch 935, Loss: 1.3901\n",
      "Batch 936, Loss: 1.4283\n",
      "Batch 937, Loss: 1.3783\n",
      "Batch 938, Loss: 1.4244\n",
      "Batch 939, Loss: 1.3675\n",
      "Batch 940, Loss: 1.4197\n",
      "Batch 941, Loss: 1.4049\n",
      "Batch 942, Loss: 1.4121\n",
      "Batch 943, Loss: 1.4074\n",
      "Batch 944, Loss: 1.3860\n",
      "Batch 945, Loss: 1.4123\n",
      "Batch 946, Loss: 1.4163\n",
      "Batch 947, Loss: 1.3876\n",
      "Batch 948, Loss: 1.4185\n",
      "Batch 949, Loss: 1.3922\n",
      "Batch 950, Loss: 1.4418\n",
      "Batch 951, Loss: 1.4008\n",
      "Batch 952, Loss: 1.3912\n",
      "Batch 953, Loss: 1.4163\n",
      "Batch 954, Loss: 1.4077\n",
      "Batch 955, Loss: 1.4126\n",
      "Batch 956, Loss: 1.4109\n",
      "Batch 957, Loss: 1.3911\n",
      "Batch 958, Loss: 1.3987\n",
      "Batch 959, Loss: 1.3965\n",
      "Batch 960, Loss: 1.4211\n",
      "Batch 961, Loss: 1.3830\n",
      "Batch 962, Loss: 1.4080\n",
      "Batch 963, Loss: 1.4201\n",
      "Batch 964, Loss: 1.3985\n",
      "Batch 965, Loss: 1.3894\n",
      "Epoch 9, Average Loss: 1.4069\n",
      "Once upon a time there was a modern road. It was in a street to get a chin. But the road was confused. The road \n",
      "worked again, but it wanted to change and cry. But it was a bad thing to put in the chin. It trusted the road, but \n",
      "it remembered something. She didn't mind believe to wait. While the road was waiting for people \"Don't forget what feel grown-ups can't be so nice!\" \n",
      "the other road had an idea. She asked the other road stored for the road nearby. The li the road made the road kept throwing \n",
      "in an oppok. Soon the road and the road said goodbye originally enough. With a smile, they had not minded. The road told all the \n",
      "people of the modern road, when they noticed that there were nothing they had seen. The road was comples usually the blue chins. \n",
      "\n",
      "--------------------\n",
      "Batch 0, Loss: 1.3776\n",
      "Batch 1, Loss: 1.3878\n",
      "Batch 2, Loss: 1.3848\n",
      "Batch 3, Loss: 1.3871\n",
      "Batch 4, Loss: 1.3835\n",
      "Batch 5, Loss: 1.3794\n",
      "Batch 6, Loss: 1.4011\n",
      "Batch 7, Loss: 1.4020\n",
      "Batch 8, Loss: 1.3991\n",
      "Batch 9, Loss: 1.3943\n",
      "Batch 10, Loss: 1.3675\n",
      "Batch 11, Loss: 1.4096\n",
      "Batch 12, Loss: 1.4109\n",
      "Batch 13, Loss: 1.4393\n",
      "Batch 14, Loss: 1.4075\n",
      "Batch 15, Loss: 1.3941\n",
      "Batch 16, Loss: 1.3972\n",
      "Batch 17, Loss: 1.3942\n",
      "Batch 18, Loss: 1.3778\n",
      "Batch 19, Loss: 1.3934\n",
      "Batch 20, Loss: 1.4162\n",
      "Batch 21, Loss: 1.3802\n",
      "Batch 22, Loss: 1.3927\n",
      "Batch 23, Loss: 1.4039\n",
      "Batch 24, Loss: 1.3922\n",
      "Batch 25, Loss: 1.4282\n",
      "Batch 26, Loss: 1.4037\n",
      "Batch 27, Loss: 1.3960\n",
      "Batch 28, Loss: 1.3733\n",
      "Batch 29, Loss: 1.4004\n",
      "Batch 30, Loss: 1.3742\n",
      "Batch 31, Loss: 1.4298\n",
      "Batch 32, Loss: 1.3554\n",
      "Batch 33, Loss: 1.3746\n",
      "Batch 34, Loss: 1.4360\n",
      "Batch 35, Loss: 1.3909\n",
      "Batch 36, Loss: 1.3989\n",
      "Batch 37, Loss: 1.3819\n",
      "Batch 38, Loss: 1.3646\n",
      "Batch 39, Loss: 1.3785\n",
      "Batch 40, Loss: 1.4012\n",
      "Batch 41, Loss: 1.3901\n",
      "Batch 42, Loss: 1.4227\n",
      "Batch 43, Loss: 1.4072\n",
      "Batch 44, Loss: 1.4019\n",
      "Batch 45, Loss: 1.4011\n",
      "Batch 46, Loss: 1.4053\n",
      "Batch 47, Loss: 1.3840\n",
      "Batch 48, Loss: 1.4103\n",
      "Batch 49, Loss: 1.3895\n",
      "Batch 50, Loss: 1.4171\n",
      "Batch 51, Loss: 1.4083\n",
      "Batch 52, Loss: 1.3627\n",
      "Batch 53, Loss: 1.4069\n",
      "Batch 54, Loss: 1.3942\n",
      "Batch 55, Loss: 1.3799\n",
      "Batch 56, Loss: 1.4133\n",
      "Batch 57, Loss: 1.3674\n",
      "Batch 58, Loss: 1.3755\n",
      "Batch 59, Loss: 1.3879\n",
      "Batch 60, Loss: 1.4060\n",
      "Batch 61, Loss: 1.3914\n",
      "Batch 62, Loss: 1.3742\n",
      "Batch 63, Loss: 1.3776\n",
      "Batch 64, Loss: 1.3825\n",
      "Batch 65, Loss: 1.4095\n",
      "Batch 66, Loss: 1.3625\n",
      "Batch 67, Loss: 1.3826\n",
      "Batch 68, Loss: 1.3785\n",
      "Batch 69, Loss: 1.3845\n",
      "Batch 70, Loss: 1.3780\n",
      "Batch 71, Loss: 1.3882\n",
      "Batch 72, Loss: 1.4093\n",
      "Batch 73, Loss: 1.3904\n",
      "Batch 74, Loss: 1.3789\n",
      "Batch 75, Loss: 1.3768\n",
      "Batch 76, Loss: 1.3720\n",
      "Batch 77, Loss: 1.4340\n",
      "Batch 78, Loss: 1.4015\n",
      "Batch 79, Loss: 1.3696\n",
      "Batch 80, Loss: 1.3954\n",
      "Batch 81, Loss: 1.4002\n",
      "Batch 82, Loss: 1.4097\n",
      "Batch 83, Loss: 1.4183\n",
      "Batch 84, Loss: 1.4011\n",
      "Batch 85, Loss: 1.3641\n",
      "Batch 86, Loss: 1.3799\n",
      "Batch 87, Loss: 1.3844\n",
      "Batch 88, Loss: 1.3929\n",
      "Batch 89, Loss: 1.4054\n",
      "Batch 90, Loss: 1.3666\n",
      "Batch 91, Loss: 1.3836\n",
      "Batch 92, Loss: 1.4025\n",
      "Batch 93, Loss: 1.3996\n",
      "Batch 94, Loss: 1.3787\n",
      "Batch 95, Loss: 1.4079\n",
      "Batch 96, Loss: 1.4142\n",
      "Batch 97, Loss: 1.4273\n",
      "Batch 98, Loss: 1.4094\n",
      "Batch 99, Loss: 1.4091\n",
      "Batch 100, Loss: 1.3975\n",
      "Batch 101, Loss: 1.3928\n",
      "Batch 102, Loss: 1.3702\n",
      "Batch 103, Loss: 1.3945\n",
      "Batch 104, Loss: 1.4296\n",
      "Batch 105, Loss: 1.3656\n",
      "Batch 106, Loss: 1.4068\n",
      "Batch 107, Loss: 1.4235\n",
      "Batch 108, Loss: 1.3974\n",
      "Batch 109, Loss: 1.4055\n",
      "Batch 110, Loss: 1.3826\n",
      "Batch 111, Loss: 1.3908\n",
      "Batch 112, Loss: 1.4089\n",
      "Batch 113, Loss: 1.4089\n",
      "Batch 114, Loss: 1.4293\n",
      "Batch 115, Loss: 1.3923\n",
      "Batch 116, Loss: 1.3920\n",
      "Batch 117, Loss: 1.4341\n",
      "Batch 118, Loss: 1.3681\n",
      "Batch 119, Loss: 1.3919\n",
      "Batch 120, Loss: 1.4264\n",
      "Batch 121, Loss: 1.4008\n",
      "Batch 122, Loss: 1.4022\n",
      "Batch 123, Loss: 1.4175\n",
      "Batch 124, Loss: 1.4105\n",
      "Batch 125, Loss: 1.3844\n",
      "Batch 126, Loss: 1.3892\n",
      "Batch 127, Loss: 1.4224\n",
      "Batch 128, Loss: 1.4249\n",
      "Batch 129, Loss: 1.3883\n",
      "Batch 130, Loss: 1.3956\n",
      "Batch 131, Loss: 1.3989\n",
      "Batch 132, Loss: 1.4007\n",
      "Batch 133, Loss: 1.4037\n",
      "Batch 134, Loss: 1.4149\n",
      "Batch 135, Loss: 1.4007\n",
      "Batch 136, Loss: 1.4126\n",
      "Batch 137, Loss: 1.4021\n",
      "Batch 138, Loss: 1.3875\n",
      "Batch 139, Loss: 1.3994\n",
      "Batch 140, Loss: 1.4103\n",
      "Batch 141, Loss: 1.3788\n",
      "Batch 142, Loss: 1.3978\n",
      "Batch 143, Loss: 1.3924\n",
      "Batch 144, Loss: 1.3771\n",
      "Batch 145, Loss: 1.4021\n",
      "Batch 146, Loss: 1.4126\n",
      "Batch 147, Loss: 1.4049\n",
      "Batch 148, Loss: 1.3961\n",
      "Batch 149, Loss: 1.3821\n",
      "Batch 150, Loss: 1.4023\n",
      "Batch 151, Loss: 1.3912\n",
      "Batch 152, Loss: 1.3763\n",
      "Batch 153, Loss: 1.3747\n",
      "Batch 154, Loss: 1.4063\n",
      "Batch 155, Loss: 1.3875\n",
      "Batch 156, Loss: 1.3900\n",
      "Batch 157, Loss: 1.3853\n",
      "Batch 158, Loss: 1.3938\n",
      "Batch 159, Loss: 1.3998\n",
      "Batch 160, Loss: 1.4189\n",
      "Batch 161, Loss: 1.4009\n",
      "Batch 162, Loss: 1.3937\n",
      "Batch 163, Loss: 1.3822\n",
      "Batch 164, Loss: 1.3735\n",
      "Batch 165, Loss: 1.4238\n",
      "Batch 166, Loss: 1.3888\n",
      "Batch 167, Loss: 1.3851\n",
      "Batch 168, Loss: 1.4125\n",
      "Batch 169, Loss: 1.4252\n",
      "Batch 170, Loss: 1.3890\n",
      "Batch 171, Loss: 1.4017\n",
      "Batch 172, Loss: 1.3954\n",
      "Batch 173, Loss: 1.4051\n",
      "Batch 174, Loss: 1.3828\n",
      "Batch 175, Loss: 1.3849\n",
      "Batch 176, Loss: 1.3891\n",
      "Batch 177, Loss: 1.4125\n",
      "Batch 178, Loss: 1.3895\n",
      "Batch 179, Loss: 1.3805\n",
      "Batch 180, Loss: 1.3925\n",
      "Batch 181, Loss: 1.3975\n",
      "Batch 182, Loss: 1.4161\n",
      "Batch 183, Loss: 1.3990\n",
      "Batch 184, Loss: 1.4168\n",
      "Batch 185, Loss: 1.3799\n",
      "Batch 186, Loss: 1.4196\n",
      "Batch 187, Loss: 1.3890\n",
      "Batch 188, Loss: 1.4222\n",
      "Batch 189, Loss: 1.3948\n",
      "Batch 190, Loss: 1.3781\n",
      "Batch 191, Loss: 1.3867\n",
      "Batch 192, Loss: 1.4050\n",
      "Batch 193, Loss: 1.3943\n",
      "Batch 194, Loss: 1.3827\n",
      "Batch 195, Loss: 1.3658\n",
      "Batch 196, Loss: 1.3918\n",
      "Batch 197, Loss: 1.3570\n",
      "Batch 198, Loss: 1.4019\n",
      "Batch 199, Loss: 1.3993\n",
      "Batch 200, Loss: 1.3900\n",
      "Batch 201, Loss: 1.4009\n",
      "Batch 202, Loss: 1.3778\n",
      "Batch 203, Loss: 1.3923\n",
      "Batch 204, Loss: 1.3759\n",
      "Batch 205, Loss: 1.3925\n",
      "Batch 206, Loss: 1.3999\n",
      "Batch 207, Loss: 1.3883\n",
      "Batch 208, Loss: 1.4027\n",
      "Batch 209, Loss: 1.4035\n",
      "Batch 210, Loss: 1.4034\n",
      "Batch 211, Loss: 1.4064\n",
      "Batch 212, Loss: 1.3730\n",
      "Batch 213, Loss: 1.3870\n",
      "Batch 214, Loss: 1.4033\n",
      "Batch 215, Loss: 1.3912\n",
      "Batch 216, Loss: 1.4096\n",
      "Batch 217, Loss: 1.4267\n",
      "Batch 218, Loss: 1.3905\n",
      "Batch 219, Loss: 1.3713\n",
      "Batch 220, Loss: 1.4011\n",
      "Batch 221, Loss: 1.4074\n",
      "Batch 222, Loss: 1.4089\n",
      "Batch 223, Loss: 1.3995\n",
      "Batch 224, Loss: 1.3934\n",
      "Batch 225, Loss: 1.4181\n",
      "Batch 226, Loss: 1.4010\n",
      "Batch 227, Loss: 1.3943\n",
      "Batch 228, Loss: 1.4086\n",
      "Batch 229, Loss: 1.4087\n",
      "Batch 230, Loss: 1.3962\n",
      "Batch 231, Loss: 1.4390\n",
      "Batch 232, Loss: 1.3685\n",
      "Batch 233, Loss: 1.4044\n",
      "Batch 234, Loss: 1.3917\n",
      "Batch 235, Loss: 1.3855\n",
      "Batch 236, Loss: 1.4116\n",
      "Batch 237, Loss: 1.3940\n",
      "Batch 238, Loss: 1.4183\n",
      "Batch 239, Loss: 1.4025\n",
      "Batch 240, Loss: 1.4149\n",
      "Batch 241, Loss: 1.3951\n",
      "Batch 242, Loss: 1.3735\n",
      "Batch 243, Loss: 1.3853\n",
      "Batch 244, Loss: 1.4037\n",
      "Batch 245, Loss: 1.4030\n",
      "Batch 246, Loss: 1.3952\n",
      "Batch 247, Loss: 1.4050\n",
      "Batch 248, Loss: 1.3850\n",
      "Batch 249, Loss: 1.3954\n",
      "Batch 250, Loss: 1.4011\n",
      "Batch 251, Loss: 1.3871\n",
      "Batch 252, Loss: 1.4100\n",
      "Batch 253, Loss: 1.3957\n",
      "Batch 254, Loss: 1.3783\n",
      "Batch 255, Loss: 1.3992\n",
      "Batch 256, Loss: 1.3924\n",
      "Batch 257, Loss: 1.3988\n",
      "Batch 258, Loss: 1.4201\n",
      "Batch 259, Loss: 1.3834\n",
      "Batch 260, Loss: 1.4010\n",
      "Batch 261, Loss: 1.3566\n",
      "Batch 262, Loss: 1.3657\n",
      "Batch 263, Loss: 1.4105\n",
      "Batch 264, Loss: 1.3906\n",
      "Batch 265, Loss: 1.3646\n",
      "Batch 266, Loss: 1.3715\n",
      "Batch 267, Loss: 1.4182\n",
      "Batch 268, Loss: 1.4189\n",
      "Batch 269, Loss: 1.3866\n",
      "Batch 270, Loss: 1.3706\n",
      "Batch 271, Loss: 1.3851\n",
      "Batch 272, Loss: 1.4163\n",
      "Batch 273, Loss: 1.4114\n",
      "Batch 274, Loss: 1.4044\n",
      "Batch 275, Loss: 1.4156\n",
      "Batch 276, Loss: 1.4268\n",
      "Batch 277, Loss: 1.3835\n",
      "Batch 278, Loss: 1.3969\n",
      "Batch 279, Loss: 1.3810\n",
      "Batch 280, Loss: 1.3839\n",
      "Batch 281, Loss: 1.4029\n",
      "Batch 282, Loss: 1.4117\n",
      "Batch 283, Loss: 1.3701\n",
      "Batch 284, Loss: 1.4004\n",
      "Batch 285, Loss: 1.4126\n",
      "Batch 286, Loss: 1.4082\n",
      "Batch 287, Loss: 1.3765\n",
      "Batch 288, Loss: 1.3877\n",
      "Batch 289, Loss: 1.3768\n",
      "Batch 290, Loss: 1.4212\n",
      "Batch 291, Loss: 1.4084\n",
      "Batch 292, Loss: 1.3804\n",
      "Batch 293, Loss: 1.3972\n",
      "Batch 294, Loss: 1.3702\n",
      "Batch 295, Loss: 1.3922\n",
      "Batch 296, Loss: 1.3859\n",
      "Batch 297, Loss: 1.4095\n",
      "Batch 298, Loss: 1.3810\n",
      "Batch 299, Loss: 1.3906\n",
      "Batch 300, Loss: 1.4300\n",
      "Batch 301, Loss: 1.3821\n",
      "Batch 302, Loss: 1.3985\n",
      "Batch 303, Loss: 1.4053\n",
      "Batch 304, Loss: 1.3958\n",
      "Batch 305, Loss: 1.4037\n",
      "Batch 306, Loss: 1.4057\n",
      "Batch 307, Loss: 1.3980\n",
      "Batch 308, Loss: 1.4155\n",
      "Batch 309, Loss: 1.3885\n",
      "Batch 310, Loss: 1.3729\n",
      "Batch 311, Loss: 1.3942\n",
      "Batch 312, Loss: 1.4053\n",
      "Batch 313, Loss: 1.3731\n",
      "Batch 314, Loss: 1.4128\n",
      "Batch 315, Loss: 1.4019\n",
      "Batch 316, Loss: 1.3984\n",
      "Batch 317, Loss: 1.3848\n",
      "Batch 318, Loss: 1.3982\n",
      "Batch 319, Loss: 1.3902\n",
      "Batch 320, Loss: 1.4154\n",
      "Batch 321, Loss: 1.4139\n",
      "Batch 322, Loss: 1.3776\n",
      "Batch 323, Loss: 1.3854\n",
      "Batch 324, Loss: 1.4268\n",
      "Batch 325, Loss: 1.3960\n",
      "Batch 326, Loss: 1.3847\n",
      "Batch 327, Loss: 1.3921\n",
      "Batch 328, Loss: 1.3827\n",
      "Batch 329, Loss: 1.3902\n",
      "Batch 330, Loss: 1.4109\n",
      "Batch 331, Loss: 1.4145\n",
      "Batch 332, Loss: 1.3931\n",
      "Batch 333, Loss: 1.3921\n",
      "Batch 334, Loss: 1.4100\n",
      "Batch 335, Loss: 1.3979\n",
      "Batch 336, Loss: 1.3895\n",
      "Batch 337, Loss: 1.4280\n",
      "Batch 338, Loss: 1.3840\n",
      "Batch 339, Loss: 1.3840\n",
      "Batch 340, Loss: 1.3845\n",
      "Batch 341, Loss: 1.4011\n",
      "Batch 342, Loss: 1.3667\n",
      "Batch 343, Loss: 1.3878\n",
      "Batch 344, Loss: 1.4153\n",
      "Batch 345, Loss: 1.4073\n",
      "Batch 346, Loss: 1.4073\n",
      "Batch 347, Loss: 1.4077\n",
      "Batch 348, Loss: 1.4399\n",
      "Batch 349, Loss: 1.4017\n",
      "Batch 350, Loss: 1.3802\n",
      "Batch 351, Loss: 1.3707\n",
      "Batch 352, Loss: 1.4363\n",
      "Batch 353, Loss: 1.3897\n",
      "Batch 354, Loss: 1.3911\n",
      "Batch 355, Loss: 1.3836\n",
      "Batch 356, Loss: 1.3645\n",
      "Batch 357, Loss: 1.4020\n",
      "Batch 358, Loss: 1.3751\n",
      "Batch 359, Loss: 1.3934\n",
      "Batch 360, Loss: 1.4183\n",
      "Batch 361, Loss: 1.3901\n",
      "Batch 362, Loss: 1.4100\n",
      "Batch 363, Loss: 1.3788\n",
      "Batch 364, Loss: 1.3745\n",
      "Batch 365, Loss: 1.4070\n",
      "Batch 366, Loss: 1.3872\n",
      "Batch 367, Loss: 1.4316\n",
      "Batch 368, Loss: 1.4102\n",
      "Batch 369, Loss: 1.3747\n",
      "Batch 370, Loss: 1.4083\n",
      "Batch 371, Loss: 1.3978\n",
      "Batch 372, Loss: 1.3799\n",
      "Batch 373, Loss: 1.4110\n",
      "Batch 374, Loss: 1.3784\n",
      "Batch 375, Loss: 1.3920\n",
      "Batch 376, Loss: 1.3907\n",
      "Batch 377, Loss: 1.4072\n",
      "Batch 378, Loss: 1.3980\n",
      "Batch 379, Loss: 1.3824\n",
      "Batch 380, Loss: 1.4035\n",
      "Batch 381, Loss: 1.4147\n",
      "Batch 382, Loss: 1.3827\n",
      "Batch 383, Loss: 1.3941\n",
      "Batch 384, Loss: 1.3889\n",
      "Batch 385, Loss: 1.3905\n",
      "Batch 386, Loss: 1.4135\n",
      "Batch 387, Loss: 1.3996\n",
      "Batch 388, Loss: 1.3781\n",
      "Batch 389, Loss: 1.3999\n",
      "Batch 390, Loss: 1.3887\n",
      "Batch 391, Loss: 1.3852\n",
      "Batch 392, Loss: 1.4041\n",
      "Batch 393, Loss: 1.4400\n",
      "Batch 394, Loss: 1.3745\n",
      "Batch 395, Loss: 1.3996\n",
      "Batch 396, Loss: 1.4210\n",
      "Batch 397, Loss: 1.4012\n",
      "Batch 398, Loss: 1.3920\n",
      "Batch 399, Loss: 1.3716\n",
      "Batch 400, Loss: 1.3969\n",
      "Batch 401, Loss: 1.3881\n",
      "Batch 402, Loss: 1.3854\n",
      "Batch 403, Loss: 1.4004\n",
      "Batch 404, Loss: 1.4125\n",
      "Batch 405, Loss: 1.3923\n",
      "Batch 406, Loss: 1.3689\n",
      "Batch 407, Loss: 1.4194\n",
      "Batch 408, Loss: 1.3849\n",
      "Batch 409, Loss: 1.3841\n",
      "Batch 410, Loss: 1.4027\n",
      "Batch 411, Loss: 1.4122\n",
      "Batch 412, Loss: 1.4223\n",
      "Batch 413, Loss: 1.4072\n",
      "Batch 414, Loss: 1.3935\n",
      "Batch 415, Loss: 1.4004\n",
      "Batch 416, Loss: 1.4137\n",
      "Batch 417, Loss: 1.3974\n",
      "Batch 418, Loss: 1.4119\n",
      "Batch 419, Loss: 1.3935\n",
      "Batch 420, Loss: 1.3636\n",
      "Batch 421, Loss: 1.3927\n",
      "Batch 422, Loss: 1.3990\n",
      "Batch 423, Loss: 1.4052\n",
      "Batch 424, Loss: 1.3909\n",
      "Batch 425, Loss: 1.3892\n",
      "Batch 426, Loss: 1.4203\n",
      "Batch 427, Loss: 1.3621\n",
      "Batch 428, Loss: 1.4013\n",
      "Batch 429, Loss: 1.3918\n",
      "Batch 430, Loss: 1.4017\n",
      "Batch 431, Loss: 1.4209\n",
      "Batch 432, Loss: 1.4122\n",
      "Batch 433, Loss: 1.3806\n",
      "Batch 434, Loss: 1.4045\n",
      "Batch 435, Loss: 1.3885\n",
      "Batch 436, Loss: 1.4030\n",
      "Batch 437, Loss: 1.4151\n",
      "Batch 438, Loss: 1.3897\n",
      "Batch 439, Loss: 1.3857\n",
      "Batch 440, Loss: 1.3785\n",
      "Batch 441, Loss: 1.3926\n",
      "Batch 442, Loss: 1.3921\n",
      "Batch 443, Loss: 1.3738\n",
      "Batch 444, Loss: 1.3950\n",
      "Batch 445, Loss: 1.3843\n",
      "Batch 446, Loss: 1.3819\n",
      "Batch 447, Loss: 1.3668\n",
      "Batch 448, Loss: 1.3810\n",
      "Batch 449, Loss: 1.3829\n",
      "Batch 450, Loss: 1.3844\n",
      "Batch 451, Loss: 1.4011\n",
      "Batch 452, Loss: 1.3757\n",
      "Batch 453, Loss: 1.4097\n",
      "Batch 454, Loss: 1.4028\n",
      "Batch 455, Loss: 1.4521\n",
      "Batch 456, Loss: 1.4015\n",
      "Batch 457, Loss: 1.4029\n",
      "Batch 458, Loss: 1.3859\n",
      "Batch 459, Loss: 1.4078\n",
      "Batch 460, Loss: 1.4001\n",
      "Batch 461, Loss: 1.3953\n",
      "Batch 462, Loss: 1.3848\n",
      "Batch 463, Loss: 1.4101\n",
      "Batch 464, Loss: 1.3632\n",
      "Batch 465, Loss: 1.3964\n",
      "Batch 466, Loss: 1.3649\n",
      "Batch 467, Loss: 1.3988\n",
      "Batch 468, Loss: 1.4034\n",
      "Batch 469, Loss: 1.4244\n",
      "Batch 470, Loss: 1.4173\n",
      "Batch 471, Loss: 1.4054\n",
      "Batch 472, Loss: 1.3968\n",
      "Batch 473, Loss: 1.4096\n",
      "Batch 474, Loss: 1.4080\n",
      "Batch 475, Loss: 1.4062\n",
      "Batch 476, Loss: 1.3793\n",
      "Batch 477, Loss: 1.4297\n",
      "Batch 478, Loss: 1.4042\n",
      "Batch 479, Loss: 1.3893\n",
      "Batch 480, Loss: 1.3836\n",
      "Batch 481, Loss: 1.3989\n",
      "Batch 482, Loss: 1.4026\n",
      "Batch 483, Loss: 1.4071\n",
      "Once upon a time, there was a woman. She had a powerful sock, but she never wanted to split on the wall. The sock had \n",
      "a big hand, with forks to watch it every day. But one day, she got a magic hand and went into a cupboard. Inside the \n",
      "handle were little puliable town, the little girl and the woman were away! She was surprised and worried. Finally, the little girl saw a factory \n",
      "into the hippo's handle. As she rebbled one more, one more time it was all tall! She made a beautiful butterfly taught the little girl \n",
      "about the magic handle. She was glad to follow it. From that day on, the woman was like the room. She spent hours playing and \n",
      "eating the phap. She didn't want to split the magical group anymore, not to enjoy it. \n",
      "\n",
      "--------------------\n",
      "Batch 484, Loss: 1.3844\n",
      "Batch 485, Loss: 1.3858\n",
      "Batch 486, Loss: 1.4076\n",
      "Batch 487, Loss: 1.3893\n",
      "Batch 488, Loss: 1.4110\n",
      "Batch 489, Loss: 1.3919\n",
      "Batch 490, Loss: 1.4076\n",
      "Batch 491, Loss: 1.3991\n",
      "Batch 492, Loss: 1.3842\n",
      "Batch 493, Loss: 1.4131\n",
      "Batch 494, Loss: 1.3767\n",
      "Batch 495, Loss: 1.3784\n",
      "Batch 496, Loss: 1.4112\n",
      "Batch 497, Loss: 1.4164\n",
      "Batch 498, Loss: 1.4063\n",
      "Batch 499, Loss: 1.3965\n",
      "Batch 500, Loss: 1.4147\n",
      "Batch 501, Loss: 1.4214\n",
      "Batch 502, Loss: 1.3988\n",
      "Batch 503, Loss: 1.4102\n",
      "Batch 504, Loss: 1.4037\n",
      "Batch 505, Loss: 1.3998\n",
      "Batch 506, Loss: 1.3787\n",
      "Batch 507, Loss: 1.4071\n",
      "Batch 508, Loss: 1.3795\n",
      "Batch 509, Loss: 1.4207\n",
      "Batch 510, Loss: 1.4315\n",
      "Batch 511, Loss: 1.4047\n",
      "Batch 512, Loss: 1.4008\n",
      "Batch 513, Loss: 1.3785\n",
      "Batch 514, Loss: 1.3999\n",
      "Batch 515, Loss: 1.3442\n",
      "Batch 516, Loss: 1.3925\n",
      "Batch 517, Loss: 1.3789\n",
      "Batch 518, Loss: 1.3668\n",
      "Batch 519, Loss: 1.4222\n",
      "Batch 520, Loss: 1.4325\n",
      "Batch 521, Loss: 1.3923\n",
      "Batch 522, Loss: 1.4126\n",
      "Batch 523, Loss: 1.3906\n",
      "Batch 524, Loss: 1.4081\n",
      "Batch 525, Loss: 1.4020\n",
      "Batch 526, Loss: 1.3971\n",
      "Batch 527, Loss: 1.4009\n",
      "Batch 528, Loss: 1.3865\n",
      "Batch 529, Loss: 1.3628\n",
      "Batch 530, Loss: 1.4164\n",
      "Batch 531, Loss: 1.4057\n",
      "Batch 532, Loss: 1.3948\n",
      "Batch 533, Loss: 1.3849\n",
      "Batch 534, Loss: 1.4209\n",
      "Batch 535, Loss: 1.3723\n",
      "Batch 536, Loss: 1.3910\n",
      "Batch 537, Loss: 1.3888\n",
      "Batch 538, Loss: 1.3546\n",
      "Batch 539, Loss: 1.3793\n",
      "Batch 540, Loss: 1.3877\n",
      "Batch 541, Loss: 1.3853\n",
      "Batch 542, Loss: 1.3896\n",
      "Batch 543, Loss: 1.4172\n",
      "Batch 544, Loss: 1.3894\n",
      "Batch 545, Loss: 1.3965\n",
      "Batch 546, Loss: 1.3934\n",
      "Batch 547, Loss: 1.3763\n",
      "Batch 548, Loss: 1.3785\n",
      "Batch 549, Loss: 1.4023\n",
      "Batch 550, Loss: 1.4092\n",
      "Batch 551, Loss: 1.3820\n",
      "Batch 552, Loss: 1.3942\n",
      "Batch 553, Loss: 1.4058\n",
      "Batch 554, Loss: 1.4085\n",
      "Batch 555, Loss: 1.4072\n",
      "Batch 556, Loss: 1.3956\n",
      "Batch 557, Loss: 1.3953\n",
      "Batch 558, Loss: 1.3815\n",
      "Batch 559, Loss: 1.3870\n",
      "Batch 560, Loss: 1.4086\n",
      "Batch 561, Loss: 1.3913\n",
      "Batch 562, Loss: 1.4067\n",
      "Batch 563, Loss: 1.4004\n",
      "Batch 564, Loss: 1.3740\n",
      "Batch 565, Loss: 1.3966\n",
      "Batch 566, Loss: 1.4092\n",
      "Batch 567, Loss: 1.3619\n",
      "Batch 568, Loss: 1.4077\n",
      "Batch 569, Loss: 1.3759\n",
      "Batch 570, Loss: 1.3982\n",
      "Batch 571, Loss: 1.3908\n",
      "Batch 572, Loss: 1.3837\n",
      "Batch 573, Loss: 1.3852\n",
      "Batch 574, Loss: 1.4037\n",
      "Batch 575, Loss: 1.3979\n",
      "Batch 576, Loss: 1.3838\n",
      "Batch 577, Loss: 1.4139\n",
      "Batch 578, Loss: 1.3889\n",
      "Batch 579, Loss: 1.4188\n",
      "Batch 580, Loss: 1.4019\n",
      "Batch 581, Loss: 1.3938\n",
      "Batch 582, Loss: 1.4094\n",
      "Batch 583, Loss: 1.3921\n",
      "Batch 584, Loss: 1.3767\n",
      "Batch 585, Loss: 1.3966\n",
      "Batch 586, Loss: 1.3941\n",
      "Batch 587, Loss: 1.3881\n",
      "Batch 588, Loss: 1.4177\n",
      "Batch 589, Loss: 1.3979\n",
      "Batch 590, Loss: 1.3505\n",
      "Batch 591, Loss: 1.3999\n",
      "Batch 592, Loss: 1.3859\n",
      "Batch 593, Loss: 1.3896\n",
      "Batch 594, Loss: 1.3859\n",
      "Batch 595, Loss: 1.3994\n",
      "Batch 596, Loss: 1.3776\n",
      "Batch 597, Loss: 1.3919\n",
      "Batch 598, Loss: 1.4011\n",
      "Batch 599, Loss: 1.3812\n",
      "Batch 600, Loss: 1.3681\n",
      "Batch 601, Loss: 1.3728\n",
      "Batch 602, Loss: 1.3918\n",
      "Batch 603, Loss: 1.4166\n",
      "Batch 604, Loss: 1.3790\n",
      "Batch 605, Loss: 1.4030\n",
      "Batch 606, Loss: 1.4132\n",
      "Batch 607, Loss: 1.3895\n",
      "Batch 608, Loss: 1.4340\n",
      "Batch 609, Loss: 1.4145\n",
      "Batch 610, Loss: 1.4000\n",
      "Batch 611, Loss: 1.4064\n",
      "Batch 612, Loss: 1.4005\n",
      "Batch 613, Loss: 1.4237\n",
      "Batch 614, Loss: 1.3963\n",
      "Batch 615, Loss: 1.3876\n",
      "Batch 616, Loss: 1.4114\n",
      "Batch 617, Loss: 1.4023\n",
      "Batch 618, Loss: 1.3992\n",
      "Batch 619, Loss: 1.3979\n",
      "Batch 620, Loss: 1.3886\n",
      "Batch 621, Loss: 1.3879\n",
      "Batch 622, Loss: 1.3948\n",
      "Batch 623, Loss: 1.4079\n",
      "Batch 624, Loss: 1.4025\n",
      "Batch 625, Loss: 1.3840\n",
      "Batch 626, Loss: 1.4032\n",
      "Batch 627, Loss: 1.3991\n",
      "Batch 628, Loss: 1.3881\n",
      "Batch 629, Loss: 1.4328\n",
      "Batch 630, Loss: 1.4352\n",
      "Batch 631, Loss: 1.3907\n",
      "Batch 632, Loss: 1.4184\n",
      "Batch 633, Loss: 1.3813\n",
      "Batch 634, Loss: 1.3897\n",
      "Batch 635, Loss: 1.3993\n",
      "Batch 636, Loss: 1.4170\n",
      "Batch 637, Loss: 1.4241\n",
      "Batch 638, Loss: 1.3914\n",
      "Batch 639, Loss: 1.3688\n",
      "Batch 640, Loss: 1.4077\n",
      "Batch 641, Loss: 1.3933\n",
      "Batch 642, Loss: 1.3875\n",
      "Batch 643, Loss: 1.4032\n",
      "Batch 644, Loss: 1.3524\n",
      "Batch 645, Loss: 1.4043\n",
      "Batch 646, Loss: 1.3860\n",
      "Batch 647, Loss: 1.4042\n",
      "Batch 648, Loss: 1.3634\n",
      "Batch 649, Loss: 1.3429\n",
      "Batch 650, Loss: 1.3926\n",
      "Batch 651, Loss: 1.3588\n",
      "Batch 652, Loss: 1.3797\n",
      "Batch 653, Loss: 1.3738\n",
      "Batch 654, Loss: 1.3943\n",
      "Batch 655, Loss: 1.3944\n",
      "Batch 656, Loss: 1.3991\n",
      "Batch 657, Loss: 1.4019\n",
      "Batch 658, Loss: 1.3764\n",
      "Batch 659, Loss: 1.3886\n",
      "Batch 660, Loss: 1.3697\n",
      "Batch 661, Loss: 1.3985\n",
      "Batch 662, Loss: 1.4195\n",
      "Batch 663, Loss: 1.3784\n",
      "Batch 664, Loss: 1.3994\n",
      "Batch 665, Loss: 1.3886\n",
      "Batch 666, Loss: 1.3750\n",
      "Batch 667, Loss: 1.3855\n",
      "Batch 668, Loss: 1.4086\n",
      "Batch 669, Loss: 1.4154\n",
      "Batch 670, Loss: 1.3957\n",
      "Batch 671, Loss: 1.3815\n",
      "Batch 672, Loss: 1.3882\n",
      "Batch 673, Loss: 1.4025\n",
      "Batch 674, Loss: 1.3825\n",
      "Batch 675, Loss: 1.3910\n",
      "Batch 676, Loss: 1.3919\n",
      "Batch 677, Loss: 1.3868\n",
      "Batch 678, Loss: 1.3928\n",
      "Batch 679, Loss: 1.3975\n",
      "Batch 680, Loss: 1.3738\n",
      "Batch 681, Loss: 1.4137\n",
      "Batch 682, Loss: 1.3980\n",
      "Batch 683, Loss: 1.3777\n",
      "Batch 684, Loss: 1.4122\n",
      "Batch 685, Loss: 1.3867\n",
      "Batch 686, Loss: 1.4098\n",
      "Batch 687, Loss: 1.3750\n",
      "Batch 688, Loss: 1.3897\n",
      "Batch 689, Loss: 1.3743\n",
      "Batch 690, Loss: 1.3962\n",
      "Batch 691, Loss: 1.4051\n",
      "Batch 692, Loss: 1.3940\n",
      "Batch 693, Loss: 1.3880\n",
      "Batch 694, Loss: 1.3815\n",
      "Batch 695, Loss: 1.3838\n",
      "Batch 696, Loss: 1.3864\n",
      "Batch 697, Loss: 1.3755\n",
      "Batch 698, Loss: 1.3950\n",
      "Batch 699, Loss: 1.3717\n",
      "Batch 700, Loss: 1.3993\n",
      "Batch 701, Loss: 1.4252\n",
      "Batch 702, Loss: 1.3912\n",
      "Batch 703, Loss: 1.3989\n",
      "Batch 704, Loss: 1.3831\n",
      "Batch 705, Loss: 1.4132\n",
      "Batch 706, Loss: 1.3820\n",
      "Batch 707, Loss: 1.3935\n",
      "Batch 708, Loss: 1.4025\n",
      "Batch 709, Loss: 1.4103\n",
      "Batch 710, Loss: 1.4029\n",
      "Batch 711, Loss: 1.3974\n",
      "Batch 712, Loss: 1.3626\n",
      "Batch 713, Loss: 1.3904\n",
      "Batch 714, Loss: 1.4062\n",
      "Batch 715, Loss: 1.4068\n",
      "Batch 716, Loss: 1.3791\n",
      "Batch 717, Loss: 1.4208\n",
      "Batch 718, Loss: 1.3971\n",
      "Batch 719, Loss: 1.4103\n",
      "Batch 720, Loss: 1.3733\n",
      "Batch 721, Loss: 1.3862\n",
      "Batch 722, Loss: 1.3773\n",
      "Batch 723, Loss: 1.4185\n",
      "Batch 724, Loss: 1.4084\n",
      "Batch 725, Loss: 1.4153\n",
      "Batch 726, Loss: 1.3855\n",
      "Batch 727, Loss: 1.3669\n",
      "Batch 728, Loss: 1.3848\n",
      "Batch 729, Loss: 1.3969\n",
      "Batch 730, Loss: 1.3885\n",
      "Batch 731, Loss: 1.4085\n",
      "Batch 732, Loss: 1.3865\n",
      "Batch 733, Loss: 1.3954\n",
      "Batch 734, Loss: 1.3919\n",
      "Batch 735, Loss: 1.3941\n",
      "Batch 736, Loss: 1.3719\n",
      "Batch 737, Loss: 1.3588\n",
      "Batch 738, Loss: 1.4030\n",
      "Batch 739, Loss: 1.3838\n",
      "Batch 740, Loss: 1.3860\n",
      "Batch 741, Loss: 1.3988\n",
      "Batch 742, Loss: 1.4167\n",
      "Batch 743, Loss: 1.3814\n",
      "Batch 744, Loss: 1.4256\n",
      "Batch 745, Loss: 1.3868\n",
      "Batch 746, Loss: 1.4228\n",
      "Batch 747, Loss: 1.4011\n",
      "Batch 748, Loss: 1.4011\n",
      "Batch 749, Loss: 1.3793\n",
      "Batch 750, Loss: 1.4171\n",
      "Batch 751, Loss: 1.3933\n",
      "Batch 752, Loss: 1.4286\n",
      "Batch 753, Loss: 1.3896\n",
      "Batch 754, Loss: 1.4079\n",
      "Batch 755, Loss: 1.4155\n",
      "Batch 756, Loss: 1.3971\n",
      "Batch 757, Loss: 1.4003\n",
      "Batch 758, Loss: 1.3819\n",
      "Batch 759, Loss: 1.3962\n",
      "Batch 760, Loss: 1.4020\n",
      "Batch 761, Loss: 1.3969\n",
      "Batch 762, Loss: 1.3750\n",
      "Batch 763, Loss: 1.3930\n",
      "Batch 764, Loss: 1.3915\n",
      "Batch 765, Loss: 1.3955\n",
      "Batch 766, Loss: 1.3987\n",
      "Batch 767, Loss: 1.3830\n",
      "Batch 768, Loss: 1.3851\n",
      "Batch 769, Loss: 1.3953\n",
      "Batch 770, Loss: 1.4066\n",
      "Batch 771, Loss: 1.4022\n",
      "Batch 772, Loss: 1.3731\n",
      "Batch 773, Loss: 1.3671\n",
      "Batch 774, Loss: 1.3919\n",
      "Batch 775, Loss: 1.4242\n",
      "Batch 776, Loss: 1.3736\n",
      "Batch 777, Loss: 1.3720\n",
      "Batch 778, Loss: 1.4057\n",
      "Batch 779, Loss: 1.4055\n",
      "Batch 780, Loss: 1.3871\n",
      "Batch 781, Loss: 1.3887\n",
      "Batch 782, Loss: 1.3652\n",
      "Batch 783, Loss: 1.3769\n",
      "Batch 784, Loss: 1.3900\n",
      "Batch 785, Loss: 1.3922\n",
      "Batch 786, Loss: 1.4000\n",
      "Batch 787, Loss: 1.3793\n",
      "Batch 788, Loss: 1.4062\n",
      "Batch 789, Loss: 1.4519\n",
      "Batch 790, Loss: 1.3958\n",
      "Batch 791, Loss: 1.3946\n",
      "Batch 792, Loss: 1.3611\n",
      "Batch 793, Loss: 1.3932\n",
      "Batch 794, Loss: 1.4041\n",
      "Batch 795, Loss: 1.3610\n",
      "Batch 796, Loss: 1.4109\n",
      "Batch 797, Loss: 1.4011\n",
      "Batch 798, Loss: 1.3835\n",
      "Batch 799, Loss: 1.3784\n",
      "Batch 800, Loss: 1.3970\n",
      "Batch 801, Loss: 1.3789\n",
      "Batch 802, Loss: 1.3926\n",
      "Batch 803, Loss: 1.3842\n",
      "Batch 804, Loss: 1.4120\n",
      "Batch 805, Loss: 1.3900\n",
      "Batch 806, Loss: 1.4067\n",
      "Batch 807, Loss: 1.3952\n",
      "Batch 808, Loss: 1.3921\n",
      "Batch 809, Loss: 1.3840\n",
      "Batch 810, Loss: 1.3712\n",
      "Batch 811, Loss: 1.3843\n",
      "Batch 812, Loss: 1.3987\n",
      "Batch 813, Loss: 1.3808\n",
      "Batch 814, Loss: 1.3841\n",
      "Batch 815, Loss: 1.3983\n",
      "Batch 816, Loss: 1.3959\n",
      "Batch 817, Loss: 1.3847\n",
      "Batch 818, Loss: 1.4185\n",
      "Batch 819, Loss: 1.3718\n",
      "Batch 820, Loss: 1.3560\n",
      "Batch 821, Loss: 1.4154\n",
      "Batch 822, Loss: 1.3790\n",
      "Batch 823, Loss: 1.3984\n",
      "Batch 824, Loss: 1.3944\n",
      "Batch 825, Loss: 1.3973\n",
      "Batch 826, Loss: 1.3943\n",
      "Batch 827, Loss: 1.4122\n",
      "Batch 828, Loss: 1.4052\n",
      "Batch 829, Loss: 1.4302\n",
      "Batch 830, Loss: 1.3885\n",
      "Batch 831, Loss: 1.3714\n",
      "Batch 832, Loss: 1.3996\n",
      "Batch 833, Loss: 1.4075\n",
      "Batch 834, Loss: 1.4009\n",
      "Batch 835, Loss: 1.3879\n",
      "Batch 836, Loss: 1.4306\n",
      "Batch 837, Loss: 1.4101\n",
      "Batch 838, Loss: 1.4021\n",
      "Batch 839, Loss: 1.3715\n",
      "Batch 840, Loss: 1.3700\n",
      "Batch 841, Loss: 1.3911\n",
      "Batch 842, Loss: 1.3770\n",
      "Batch 843, Loss: 1.4049\n",
      "Batch 844, Loss: 1.3963\n",
      "Batch 845, Loss: 1.4031\n",
      "Batch 846, Loss: 1.3861\n",
      "Batch 847, Loss: 1.4016\n",
      "Batch 848, Loss: 1.4075\n",
      "Batch 849, Loss: 1.3702\n",
      "Batch 850, Loss: 1.3755\n",
      "Batch 851, Loss: 1.4124\n",
      "Batch 852, Loss: 1.3883\n",
      "Batch 853, Loss: 1.3912\n",
      "Batch 854, Loss: 1.4012\n",
      "Batch 855, Loss: 1.4117\n",
      "Batch 856, Loss: 1.3767\n",
      "Batch 857, Loss: 1.4006\n",
      "Batch 858, Loss: 1.3674\n",
      "Batch 859, Loss: 1.3794\n",
      "Batch 860, Loss: 1.4091\n",
      "Batch 861, Loss: 1.3964\n",
      "Batch 862, Loss: 1.3656\n",
      "Batch 863, Loss: 1.3732\n",
      "Batch 864, Loss: 1.3787\n",
      "Batch 865, Loss: 1.3822\n",
      "Batch 866, Loss: 1.3710\n",
      "Batch 867, Loss: 1.3925\n",
      "Batch 868, Loss: 1.3842\n",
      "Batch 869, Loss: 1.3876\n",
      "Batch 870, Loss: 1.3740\n",
      "Batch 871, Loss: 1.4166\n",
      "Batch 872, Loss: 1.4162\n",
      "Batch 873, Loss: 1.4051\n",
      "Batch 874, Loss: 1.4199\n",
      "Batch 875, Loss: 1.3958\n",
      "Batch 876, Loss: 1.3975\n",
      "Batch 877, Loss: 1.3986\n",
      "Batch 878, Loss: 1.4077\n",
      "Batch 879, Loss: 1.3757\n",
      "Batch 880, Loss: 1.4052\n",
      "Batch 881, Loss: 1.3762\n",
      "Batch 882, Loss: 1.3887\n",
      "Batch 883, Loss: 1.3884\n",
      "Batch 884, Loss: 1.4107\n",
      "Batch 885, Loss: 1.3989\n",
      "Batch 886, Loss: 1.3661\n",
      "Batch 887, Loss: 1.3853\n",
      "Batch 888, Loss: 1.4348\n",
      "Batch 889, Loss: 1.3706\n",
      "Batch 890, Loss: 1.3804\n",
      "Batch 891, Loss: 1.3674\n",
      "Batch 892, Loss: 1.3793\n",
      "Batch 893, Loss: 1.4056\n",
      "Batch 894, Loss: 1.4193\n",
      "Batch 895, Loss: 1.4042\n",
      "Batch 896, Loss: 1.3944\n",
      "Batch 897, Loss: 1.4160\n",
      "Batch 898, Loss: 1.3879\n",
      "Batch 899, Loss: 1.3777\n",
      "Batch 900, Loss: 1.3935\n",
      "Batch 901, Loss: 1.3823\n",
      "Batch 902, Loss: 1.4044\n",
      "Batch 903, Loss: 1.4218\n",
      "Batch 904, Loss: 1.3930\n",
      "Batch 905, Loss: 1.3966\n",
      "Batch 906, Loss: 1.3774\n",
      "Batch 907, Loss: 1.3635\n",
      "Batch 908, Loss: 1.3910\n",
      "Batch 909, Loss: 1.4023\n",
      "Batch 910, Loss: 1.3924\n",
      "Batch 911, Loss: 1.3932\n",
      "Batch 912, Loss: 1.3900\n",
      "Batch 913, Loss: 1.4006\n",
      "Batch 914, Loss: 1.4175\n",
      "Batch 915, Loss: 1.3561\n",
      "Batch 916, Loss: 1.4059\n",
      "Batch 917, Loss: 1.3977\n",
      "Batch 918, Loss: 1.3848\n",
      "Batch 919, Loss: 1.4350\n",
      "Batch 920, Loss: 1.3905\n",
      "Batch 921, Loss: 1.3861\n",
      "Batch 922, Loss: 1.3844\n",
      "Batch 923, Loss: 1.4067\n",
      "Batch 924, Loss: 1.3916\n",
      "Batch 925, Loss: 1.3802\n",
      "Batch 926, Loss: 1.3976\n",
      "Batch 927, Loss: 1.3960\n",
      "Batch 928, Loss: 1.3960\n",
      "Batch 929, Loss: 1.3709\n",
      "Batch 930, Loss: 1.4174\n",
      "Batch 931, Loss: 1.3867\n",
      "Batch 932, Loss: 1.3829\n",
      "Batch 933, Loss: 1.3980\n",
      "Batch 934, Loss: 1.4042\n",
      "Batch 935, Loss: 1.4080\n",
      "Batch 936, Loss: 1.4046\n",
      "Batch 937, Loss: 1.3831\n",
      "Batch 938, Loss: 1.3801\n",
      "Batch 939, Loss: 1.3902\n",
      "Batch 940, Loss: 1.3961\n",
      "Batch 941, Loss: 1.3629\n",
      "Batch 942, Loss: 1.4160\n",
      "Batch 943, Loss: 1.4122\n",
      "Batch 944, Loss: 1.4311\n",
      "Batch 945, Loss: 1.3875\n",
      "Batch 946, Loss: 1.4083\n",
      "Batch 947, Loss: 1.4092\n",
      "Batch 948, Loss: 1.4010\n",
      "Batch 949, Loss: 1.4171\n",
      "Batch 950, Loss: 1.3638\n",
      "Batch 951, Loss: 1.4053\n",
      "Batch 952, Loss: 1.3911\n",
      "Batch 953, Loss: 1.3874\n",
      "Batch 954, Loss: 1.3796\n",
      "Batch 955, Loss: 1.3913\n",
      "Batch 956, Loss: 1.3950\n",
      "Batch 957, Loss: 1.3694\n",
      "Batch 958, Loss: 1.3990\n",
      "Batch 959, Loss: 1.4034\n",
      "Batch 960, Loss: 1.3999\n",
      "Batch 961, Loss: 1.3941\n",
      "Batch 962, Loss: 1.4009\n",
      "Batch 963, Loss: 1.3778\n",
      "Batch 964, Loss: 1.4055\n",
      "Batch 965, Loss: 1.3794\n",
      "Epoch 10, Average Loss: 1.3952\n",
      "Once upon a time there was a crab named Jack. Jack wanted to go to the farm where every morning path. He was curious, so \n",
      "he asked his family, \"Where can I go yield a house with many animals! Please don't have this barn, especially I can find there.\" Jack \n",
      "was very happy. He could hardly think of the noise and saw something. It was a big cloud! Jack shouted, \"Mommy, I'm crabing the cloud!\" \n",
      "his mom smiled, \"That, bad thing, I'm going to face. Stell to go out from be clear side of to grow, now to otherigares for \n",
      "things this foot for the sofa.\" Jack smiled and said, \"So Oppiously. That way was finally crack can! Maybe one more time can go to \n",
      "bed!\" Do smiled and said, \"Yes, Mall! I'm so pleased with the wonderful turn, I'm very proud of you!\" Jack smiled and said, \"That was \n",
      "fun!\" They all hugged each other and Leep said, \"What a great path, mommy! Can I leow it?\" \n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "generate_story_freq = np.ceil(num_batches / 2) + 1\n",
    "for epoch in range(start_epoch_from, EPOCHS):\n",
    "    losses = []\n",
    "    for i, seq in enumerate(dataloader):\n",
    "        tensor_seq = seq.to(device)\n",
    "        input_seq = tensor_seq[:, :-1]  # Exclude the last token for input\n",
    "        target_seq = tensor_seq[:, 1:]  # Exclude the first token for target\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(model, input_seq, target_seq, pad_token_id=pad_token_id if PADDING else None)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Batch {i}, Loss: {loss.item():.4f}\")\n",
    "        writer.add_scalar('Loss/train', loss.item(), epoch * num_batches + i)\n",
    "        if (i+1) % generate_story_freq == 0:\n",
    "            tokens = model.generate('[SOS]', tokenizer, max_length=CONTEXT_LENGTH, eos_token_id=eos_token_id, temp=1.0)\n",
    "            print_story(tokens, tokenizer)\n",
    "        losses.append(loss.item())\n",
    "    #     break\n",
    "    # break\n",
    "    avg_loss = np.mean(losses)\n",
    "    print(f\"Epoch {epoch + 1}, Average Loss: {avg_loss:.4f}\")\n",
    "    writer.add_scalar('Loss/epoch_train', avg_loss.item(), epoch)\n",
    "    tokens = model.generate('[SOS]', tokenizer, max_length=CONTEXT_LENGTH, eos_token_id=eos_token_id, temp=1.0)\n",
    "    print_story(tokens, tokenizer)\n",
    "    checkpoint = {\n",
    "        'start_epoch_from': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'rng_state': torch.get_rng_state(),\n",
    "        'loss': avg_loss,\n",
    "    }\n",
    "    torch.save(checkpoint, f'{LOG_DIR}/checkpoint.pt')\n",
    "writer.add_hparams(params, {'hparam/last_loss': avg_loss.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "647383e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a little girl named Lily. She loved to play with her toys and run around the house. One day, \n",
      "she saw a big, red balloon in the sky. She wanted to play with it, but she didn't know how. Lily asked her mom, \"Can \n",
      "I play with it?\" Her mom said, \"Sure, but be careful.\" Lily was happy to hear that. She ran to the balloon and started to \n",
      "play with it. As she played, she saw a big, red balloon. It was a big, red balloon! Lily was so happy to have her \n",
      "balloon. She ran to the balloon and started to play with it. She had so much fun playing with it all day. As she played \n",
      "with the balloon all day long, she noticed that it was time to go home. Lily was sad to leave the balloon behind her. She \n",
      "learned that it's important to listen to her mom and not be rude to her friends. \n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "tokens = model.generate('[SOS]', tokenizer, max_length=CONTEXT_LENGTH, eos_token_id=eos_token_id, temp=0.2)\n",
    "print_story(tokens, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
